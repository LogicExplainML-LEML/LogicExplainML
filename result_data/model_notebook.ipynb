{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "394f70f1",
   "metadata": {},
   "source": [
    "# Imports + class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "231f4500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from z3 import *\n",
    "from xgboost import XGBClassifier\n",
    "from pmlb import fetch_data\n",
    "set_option(rational_to_decimal=True)\n",
    "\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "from model import XGBoostExplainer, generate_results\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c38991a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoostExplainer:\n",
    "    def __init__(self, model, data):\n",
    "        self.model = model\n",
    "        self.data = data.values\n",
    "        self.columns = data.columns\n",
    "        self.max_categories = 2\n",
    "\n",
    "        set_option(rational_to_decimal=True)\n",
    "        self.categoric_features = self.get_categoric_features(self.data)\n",
    "        self.T_model = self.model_trees_expression(self.model)\n",
    "        self.T = self.T_model\n",
    "\n",
    "    def explain(self, instance, reorder=\"asc\"):\n",
    "        self.I = self.instance_expression(instance)\n",
    "        self.D, self.D_add = self.decision_function_expression(self.model, [instance])\n",
    "        return self.explain_expression(self.I, And(self.T, self.D_add), self.D, self.model, reorder)\n",
    "\n",
    "    def explain_prob(self, instance, reorder=\"asc\", threshold_margin=0, target_threshold=None):\n",
    "        self.I = self.instance_expression(instance)\n",
    "        self.D, self.D_add = self.decision_function_expression(self.model, [instance])\n",
    "        return self.explain_expression_prob(self.I, And(self.T, self.D_add), self.D, self.model, reorder, threshold_margin, target_threshold)\n",
    "\n",
    "    def get_categoric_features(self, data: np.ndarray):\n",
    "        categoric_features = []\n",
    "        for i in range(data.shape[1]):\n",
    "            feature_values = data[:, i]\n",
    "            unique_values = np.unique(feature_values)\n",
    "            if len(unique_values) <= self.max_categories:\n",
    "                categoric_features.append(self.columns[i])\n",
    "\n",
    "        return categoric_features\n",
    "\n",
    "    def feature_constraints(self, constraints=[]):\n",
    "        \"\"\"TODO\n",
    "        esperado receber limites das features pelo usuÃ¡rio\n",
    "        formato previso: matriz/dataframe [feaature, min/max, valor]\n",
    "        constraaint_expression = \"constraaint_df_to_feature()\"\n",
    "        \"\"\"\n",
    "        return\n",
    "\n",
    "    def model_trees_expression(self, model):\n",
    "        df = model.get_booster().trees_to_dataframe()\n",
    "        if model.get_booster().feature_names == None:\n",
    "            feature_map = {f\"f{i}\": col for i, col in enumerate(self.columns)}\n",
    "            df[\"Feature\"] = df[\"Feature\"].replace(feature_map)\n",
    "\n",
    "        df[\"Split\"] = df[\"Split\"].round(4)\n",
    "        self.booster_df = df\n",
    "        class_index = 0  # if model.n_classes_ == 2:\n",
    "        all_tree_formulas = []\n",
    "\n",
    "        for tree_index in df[\"Tree\"].unique():\n",
    "            tree_df = df[df[\"Tree\"] == tree_index]\n",
    "            o = Real(f\"o_{tree_index}_{class_index}\")\n",
    "\n",
    "            if len(tree_df) == 1 and tree_df.iloc[0][\"Feature\"] == \"Leaf\":\n",
    "                leaf_value = tree_df.iloc[0][\"Gain\"]\n",
    "                all_tree_formulas.append(And(o == leaf_value))\n",
    "                continue\n",
    "            path_formulas = []\n",
    "\n",
    "            def get_conditions(node_id):\n",
    "                conditions = []\n",
    "                current_node = tree_df[tree_df[\"ID\"] == node_id]\n",
    "                if current_node.empty:\n",
    "                    return conditions\n",
    "\n",
    "                parent_node = tree_df[\n",
    "                    (tree_df[\"Yes\"] == node_id) | (tree_df[\"No\"] == node_id)\n",
    "                ]\n",
    "                if not parent_node.empty:\n",
    "                    parent_data = parent_node.iloc[0]\n",
    "                    feature = parent_data[\"Feature\"]\n",
    "                    split_value = parent_data[\"Split\"]\n",
    "                    x = Real(feature)\n",
    "                    if parent_data[\"Yes\"] == node_id:\n",
    "                        conditions.append(x < split_value)\n",
    "                    else:\n",
    "                        conditions.append(x >= split_value)\n",
    "                    conditions = get_conditions(parent_data[\"ID\"]) + conditions\n",
    "\n",
    "                return conditions\n",
    "\n",
    "            for _, node in tree_df[tree_df[\"Feature\"] == \"Leaf\"].iterrows():\n",
    "                leaf_value = node[\"Gain\"]\n",
    "                leaf_id = node[\"ID\"]\n",
    "                conditions = get_conditions(leaf_id)\n",
    "                path_formula = And(*conditions)\n",
    "                implication = Implies(path_formula, o == leaf_value)\n",
    "                path_formulas.append(implication)\n",
    "\n",
    "            all_tree_formulas.append(And(*path_formulas))\n",
    "        return And(*all_tree_formulas)\n",
    "\n",
    "    def get_init_value(self, model, x, estimator_variables):\n",
    "        estimator_pred = Solver()\n",
    "        estimator_pred.add(self.I)\n",
    "        estimator_pred.add(self.T)\n",
    "        if estimator_pred.check() == sat:\n",
    "            solvermodel = estimator_pred.model()\n",
    "            total_sum = sum(\n",
    "                float(solvermodel.eval(var).as_fraction()) for var in estimator_variables\n",
    "            )\n",
    "        else:\n",
    "            total_sum = 0\n",
    "            print(\"estimator error\")\n",
    "        self.predicted_margin = model.predict(x, output_margin=True)[0]\n",
    "        init_value = self.predicted_margin - total_sum\n",
    "        self.init_value = init_value\n",
    "        return init_value\n",
    "\n",
    "    def decision_function_expression(self, model, x):\n",
    "        n_classes = 1 if model.n_classes_ <= 2 else model.n_classes_\n",
    "        predicted_class = model.predict(x)[0]\n",
    "        self.predicted_class = predicted_class\n",
    "        n_estimators = int(len(model.get_booster().get_dump()) / n_classes)\n",
    "        estimator_variables = [Real(f\"o_{i}_0\") for i in range(n_estimators)] # _0 only for binary classification\n",
    "        self.estimator_variables = estimator_variables\n",
    "        init_value = self.get_init_value(model, x, estimator_variables)\n",
    "        # print(\"init:\", round(init_value, 2))\n",
    "\n",
    "        equation_list = []\n",
    "\n",
    "        estimator_sum = Real(\"estimator_sum\")\n",
    "        equation_o = estimator_sum == Sum(estimator_variables)\n",
    "        equation_list.append(equation_o)\n",
    "\n",
    "        decision = Real(\"decision\")\n",
    "        equation_list.append(decision == estimator_sum + init_value)\n",
    "\n",
    "        if predicted_class == 0:\n",
    "            final_equation = decision < 0\n",
    "        else:\n",
    "            final_equation = decision > 0\n",
    "\n",
    "        return final_equation, And(equation_list)\n",
    "\n",
    "    def instance_expression(self, instance):\n",
    "        formula = [Real(self.columns[i]) == value for i, value in enumerate(instance)]\n",
    "        return formula\n",
    "\n",
    "    def explain_expression(self, I, T_s, D_s, model, reorder):\n",
    "        i_expression = I.copy()\n",
    "\n",
    "        importances = model.feature_importances_\n",
    "        non_zero_indices = np.where(importances != 0)[0]\n",
    "\n",
    "        if reorder == \"asc\":\n",
    "            sorted_feature_indices = non_zero_indices[\n",
    "                np.argsort(importances[non_zero_indices])\n",
    "            ]\n",
    "            i_expression = [i_expression[i] for i in sorted_feature_indices]\n",
    "        elif reorder == \"desc\":\n",
    "            sorted_feature_indices = non_zero_indices[\n",
    "                np.argsort(-importances[non_zero_indices])\n",
    "            ]\n",
    "            i_expression = [i_expression[i] for i in sorted_feature_indices]\n",
    "\n",
    "        for feature in i_expression.copy():\n",
    "            # print(\"\\n---removed\", feature)\n",
    "            i_expression.remove(feature)\n",
    "\n",
    "            # prove(Implies(And(And(i_expression), T), D))\n",
    "            if self.is_proved(Implies(And(And(i_expression), T_s), D_s)):\n",
    "                continue\n",
    "                # print('proved')\n",
    "            else:\n",
    "                # print('not proved')\n",
    "                i_expression.append(feature)\n",
    "        # print(self.is_proved(Implies(And(And(i_expression), T_s), D_s)))\n",
    "        return i_expression\n",
    "\n",
    "    def explain_expression_prob(self, I, T_s, D_s, model, reorder, threshold_margin, target_threshold):\n",
    "        i_expression = I.copy()\n",
    "\n",
    "        importances = model.feature_importances_\n",
    "        non_zero_indices = np.where(importances != 0)[0]\n",
    "\n",
    "        if reorder == \"asc\":\n",
    "            sorted_feature_indices = non_zero_indices[\n",
    "                np.argsort(importances[non_zero_indices])\n",
    "            ]\n",
    "            i_expression = [i_expression[i] for i in sorted_feature_indices]\n",
    "        elif reorder == \"desc\":\n",
    "            sorted_feature_indices = non_zero_indices[\n",
    "                np.argsort(-importances[non_zero_indices])\n",
    "            ]\n",
    "            i_expression = [i_expression[i] for i in sorted_feature_indices]\n",
    "\n",
    "        threshold = 0\n",
    "\n",
    "        if target_threshold:\n",
    "            threshold = target_threshold\n",
    "        elif threshold_margin != 0:\n",
    "            threshold = self.predicted_margin * threshold_margin/100\n",
    "            # print(\"margin:\", self.predicted_margin, \"accepted margin:\", threshold)\n",
    "        self.xai_predicted_margin = self.predicted_margin\n",
    "\n",
    "        for feature in i_expression.copy():\n",
    "            # print(\"\\n---removed\", feature)\n",
    "            i_expression.remove(feature)\n",
    "\n",
    "            if self.is_proved_sat(And(And(i_expression), T_s), threshold):\n",
    "                # print('proved')\n",
    "                continue\n",
    "            else:\n",
    "                # print('not proved -- added back')\n",
    "                i_expression.append(feature)\n",
    "        return i_expression\n",
    "\n",
    "\n",
    "    def is_proved(self, decision_exp):\n",
    "        s = Solver()\n",
    "        s.add(Not(decision_exp))\n",
    "        if s.check() == unsat:\n",
    "            return True\n",
    "        else:\n",
    "            # print(s.model())\n",
    "            return False\n",
    "\n",
    "    def is_proved_sat(self, decision_exp, threshold):\n",
    "      decision = Real(\"decision\")\n",
    "\n",
    "      debug = Real(\"debug\") == 0\n",
    "      predicted_class = self.predicted_class\n",
    "\n",
    "      if predicted_class == 0:\n",
    "        estmax = Optimize()\n",
    "        estmax.add(decision_exp)\n",
    "        estmax.add(debug)\n",
    "        maxvalue = estmax.maximize(decision)\n",
    "        if estmax.check() == sat:\n",
    "            # print(\"\\nmax sat\", maxvalue.value())\n",
    "            try:\n",
    "              if float(maxvalue.value().as_fraction()) > threshold:\n",
    "                  return False # can change class\n",
    "              else:\n",
    "                  self.xai_predicted_margin = float(maxvalue.value().as_fraction())\n",
    "            except:\n",
    "              print(\"error max =\", maxvalue.value())\n",
    "              return False\n",
    "        else:\n",
    "            print(\"error\")\n",
    "\n",
    "      if predicted_class == 1:\n",
    "        estmin = Optimize()\n",
    "        estmin.add(decision_exp)\n",
    "        estmin.add(debug)\n",
    "        minvalue = estmin.minimize(decision)\n",
    "        if estmin.check() == sat:\n",
    "            # print(\"\\nmin sat\", minvalue.value())\n",
    "            try:\n",
    "              if float(minvalue.value().as_fraction()) < threshold:\n",
    "                  return False # can change class\n",
    "              else:\n",
    "                  self.xai_predicted_margin = float(minvalue.value().as_fraction())\n",
    "            except:\n",
    "              print(\"error min =\", minvalue.value())\n",
    "              return False\n",
    "        else:\n",
    "            print(\"error\")\n",
    "\n",
    "      if predicted_class == 0:\n",
    "        self.solvermodel = estmax.model()\n",
    "      if predicted_class == 1:\n",
    "        self.solvermodel = estmin.model()\n",
    "      return True\n",
    "  \n",
    "def generate_results(explainer, X_test, y_pred, classification, path, reorder=\"asc\"):\n",
    "    results = []\n",
    "    if classification == 0:\n",
    "        increase_prob = -0.01\n",
    "    else:\n",
    "        increase_prob = 0.01\n",
    "    for i in X_test[y_pred == classification].index:\n",
    "        sample = X_test.loc[i].values\n",
    "        xai = explainer.explain_prob(sample, reorder=reorder)\n",
    "        xaiprob_initial = explainer.xai_predicted_margin\n",
    "        len_xai_initial = len(xai)\n",
    "\n",
    "        xai = explainer.explain_prob(sample, reorder=reorder, target_threshold=xaiprob_initial + increase_prob)\n",
    "        xaiprob_final = explainer.xai_predicted_margin\n",
    "        len_xai_final = len(xai)\n",
    "\n",
    "        if round(xaiprob_initial, 2) == round(xaiprob_final, 2):\n",
    "            len_xai_initial = len_xai_final\n",
    "        results.append({\n",
    "            \"index\": i,\n",
    "            \"class\": classification,\n",
    "            \"xaiprob_initial\": round(xaiprob_initial, 2),\n",
    "            \"len_xai_initial\": len_xai_initial,\n",
    "            \"xaiprob_final\": round(xaiprob_final, 2),\n",
    "            \"len_xai_final\": len_xai_final\n",
    "        })\n",
    "    df_results = pd.DataFrame(results)\n",
    "    return df_results\n",
    "    # df_results.to_csv(f'{path}/results_{classification}_{reorder}.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fc67b6",
   "metadata": {},
   "source": [
    "# Prepare datasets and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "877534ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset_model_explainer(dataset_name, dataset_params):\n",
    "    # Fetch data\n",
    "    dataset = fetch_data(dataset_name)\n",
    "    X = dataset.drop('target', axis=1)\n",
    "    y = dataset['target']\n",
    "    \n",
    "    if dataset_name == \"adult\" and len(X) > 5000:\n",
    "        X, _, y, _ = train_test_split(\n",
    "            X, y, train_size=5000, stratify=y, random_state=42\n",
    "        )\n",
    "\n",
    "    params = dataset_params[dataset_name]\n",
    "\n",
    "    # Train model\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    # Metrics\n",
    "    print(f\"== {dataset_name.upper()} Dataset ==\")\n",
    "    print(\"Dataset size:\", len(X))\n",
    "    print(\"Columns:\", len(X.columns))\n",
    "    # print(\"Accuracy:\", accuracy_score(y, y_pred))\n",
    "    # print(\"Precision:\", precision_score(y, y_pred))\n",
    "    # print(\"Recall:\", recall_score(y, y_pred))\n",
    "    print(\"F1-score:\", f1_score(y, y_pred))\n",
    "\n",
    "    # Explainer\n",
    "    explainer = XGBoostExplainer(model, X)\n",
    "\n",
    "    return model, X, y, explainer\n",
    "\n",
    "def prepare_all_datasets(dataset_names, dataset_params):\n",
    "    context = {}\n",
    "    for name in dataset_names:\n",
    "        print(f\"\\n--- Preparing {name} ---\")\n",
    "        model, X, y, explainer = prepare_dataset_model_explainer(name, dataset_params)\n",
    "        context[name] = (model, X, y, explainer)\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f96f764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preparing saheart ---\n",
      "== SAHEART Dataset ==\n",
      "Dataset size: 462\n",
      "Columns: 9\n",
      "F1-score: 0.9968652037617555\n",
      "\n",
      "--- Preparing adult ---\n",
      "== ADULT Dataset ==\n",
      "Dataset size: 5000\n",
      "Columns: 14\n",
      "F1-score: 0.9409646302250804\n",
      "\n",
      "--- Preparing mushroom ---\n",
      "== MUSHROOM Dataset ==\n",
      "Dataset size: 8124\n",
      "Columns: 22\n",
      "F1-score: 1.0\n",
      "\n",
      "--- Preparing sonar ---\n",
      "== SONAR Dataset ==\n",
      "Dataset size: 208\n",
      "Columns: 60\n",
      "F1-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "dataset_names = [\"saheart\", \"adult\", \"mushroom\", \"sonar\"]\n",
    "\n",
    "dataset_params = {\n",
    "    \"adult\": {\"n_estimators\": 30},\n",
    "    \"saheart\": {\"n_estimators\": 30},\n",
    "    \"mushroom\": {\"n_estimators\": 30},\n",
    "    \"sonar\": {\"n_estimators\": 30},\n",
    "}\n",
    "\n",
    "dataset_context = prepare_all_datasets(dataset_names, dataset_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbeaf39",
   "metadata": {},
   "source": [
    "# Check explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b55a38d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_explain_results(dataset_name):\n",
    "    model, X, y, explainer = dataset_context[dataset_name]\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    # Function to explain a sample of a given class\n",
    "    def explain_for_class(classification):\n",
    "        # Get a sample of the specified class in predictions\n",
    "        indices = X[y_pred == classification].index\n",
    "        if len(indices) == 0:\n",
    "            print(f\"No samples predicted as class {classification}.\")\n",
    "            return\n",
    "        i = indices[0]\n",
    "        sample = X.loc[i].values\n",
    "\n",
    "        # Initial explanation\n",
    "        margin = model.predict([sample], output_margin=True)[0]\n",
    "        print(f\"\\nClass {classification} - Margin: {margin}, Sample index: {i}\")\n",
    "\n",
    "        xai = explainer.explain_prob(sample)\n",
    "        print(\"Initial abductive explanation:\", xai)\n",
    "        \n",
    "        xaiprob_initial = explainer.xai_predicted_margin\n",
    "        print(\"Initial predicted margin:\", xaiprob_initial)\n",
    "\n",
    "        # Adjust margin direction\n",
    "        # increase_prob = -0.01 if classification == 0 else 0.01\n",
    "\n",
    "        # Explanation with adjusted threshold\n",
    "        xai_confidence = explainer.explain_prob(sample, target_threshold= margin / 2)\n",
    "        xaiprob_final = explainer.xai_predicted_margin\n",
    "        print(\"Confidence-aware abductive explanation:\", xai_confidence)\n",
    "        print(\"Final predicted margin:\", xaiprob_final)\n",
    "\n",
    "    # Explain for both classes\n",
    "    explain_for_class(0)\n",
    "    explain_for_class(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27c75f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class 0 - Margin: -8.39293384552002, Sample index: 0\n",
      "Initial abductive explanation: [gill-size == 0, spore-print-color == 1]\n",
      "Initial predicted margin: -5.9726229332\n",
      "Confidence-aware abductive explanation: [gill-size == 0, spore-print-color == 1]\n",
      "Final predicted margin: -5.9726229332\n",
      "\n",
      "Class 1 - Margin: 8.46451473236084, Sample index: 3\n",
      "Initial abductive explanation: [stalk-surface-below-ring == 2, gill-spacing == 0, veil-color == 2, spore-print-color == 3]\n",
      "Initial predicted margin: 2.37855409442\n",
      "Confidence-aware abductive explanation: [stalk-surface-below-ring == 2, odor == 4, gill-spacing == 0, veil-color == 2, spore-print-color == 3]\n",
      "Final predicted margin: 5.08424244958\n"
     ]
    }
   ],
   "source": [
    "get_explain_results(\"mushroom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9864ddbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class 0 - Margin: -5.76040506362915, Sample index: 33044\n",
      "Initial abductive explanation: [age == 46, education-num == 13, capital-gain == 27828, relationship == 1]\n",
      "Initial predicted margin: -1.5279432290741\n",
      "Confidence-aware abductive explanation: [occupation == 4, age == 46, capital-loss == 0, education-num == 13, capital-gain == 27828, marital-status == 0, relationship == 1]\n",
      "Final predicted margin: -3.02649918073\n",
      "\n",
      "Class 1 - Margin: 1.490314245223999, Sample index: 47519\n",
      "Initial abductive explanation: [fnlwgt == 174373, hours-per-week == 30, capital-loss == 0, education-num == 9, capital-gain == 0, relationship == 0]\n",
      "Initial predicted margin: 0.009739591496\n",
      "Confidence-aware abductive explanation: [fnlwgt == 174373, native-country == 39, hours-per-week == 30, capital-loss == 0, education-num == 9, capital-gain == 0, relationship == 0]\n",
      "Final predicted margin: 1.060730009926\n"
     ]
    }
   ],
   "source": [
    "get_explain_results(\"adult\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ba516fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class 0 - Margin: -5.715680122375488, Sample index: 0\n",
      "Initial abductive explanation: [A17 == 0.287, A47 == 0.1688, A9 == 0.1865, A52 == 0.012, A48 == 0.1037, A51 == 0.013, A27 == 0.9301, A12 == 0.3553, A15 == 0.178, A4 == 0.057, A21 == 0.7969, A16 == 0.2794, A11 == 0.3188]\n",
      "Initial predicted margin: -0.08802267005\n",
      "Confidence-aware abductive explanation: [A18 == 0.3969, A8 == 0.1684, A37 == 0.0702, A55 == 0.0062, A17 == 0.287, A49 == 0.0501, A47 == 0.1688, A28 == 0.9955, A31 == 0.3934, A9 == 0.1865, A6 == 0.1091, A52 == 0.012, A48 == 0.1037, A51 == 0.013, A27 == 0.9301, A12 == 0.3553, A15 == 0.178, A4 == 0.057, A21 == 0.7969, A16 == 0.2794, A34 == 0.114, A11 == 0.3188]\n",
      "Final predicted margin: -2.95120893735\n",
      "\n",
      "Class 1 - Margin: 5.48876953125, Sample index: 12\n",
      "Initial abductive explanation: [A47 == 0.0342, A28 == 0.6742, A54 == 0.0052, A9 == 0.1151, A48 == 0.0469, A45 == 0.084, A12 == 0.1102, A4 == 0.0139, A21 == 0.2005, A16 == 0.2138, A11 == 0.1203]\n",
      "Initial predicted margin: 0.1394765883\n",
      "Confidence-aware abductive explanation: [A23 == 0.2605, A43 == 0.1587, A36 == 0.2344, A18 == 0.1765, A17 == 0.1929, A53 == 0.0044, A47 == 0.0342, A28 == 0.6742, A31 == 0.3609, A54 == 0.0052, A9 == 0.1151, A48 == 0.0469, A45 == 0.084, A51 == 0.0082, A12 == 0.1102, A4 == 0.0139, A21 == 0.2005, A16 == 0.2138, A11 == 0.1203]\n",
      "Final predicted margin: 2.8178880496\n"
     ]
    }
   ],
   "source": [
    "get_explain_results(\"sonar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96d90cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class 0 - Margin: -3.512935161590576, Sample index: 2\n",
      "Initial abductive explanation: [Sbp == 118, Ldl == 3.48, Typea == 52, Tobacco == 0.08, Age == 46]\n",
      "Initial predicted margin: -0.2604648052\n",
      "Confidence-aware abductive explanation: [Obesity == 29.14, Ldl == 3.48, Adiposity == 32.28, Typea == 52, Tobacco == 0.08, Age == 46]\n",
      "Final predicted margin: -2.44854886201\n",
      "\n",
      "Class 1 - Margin: 2.5211021900177, Sample index: 0\n",
      "Initial abductive explanation: [Sbp == 160, Ldl == 5.73, Adiposity == 23.11, Typea == 49, Tobacco == 12, Famhist == 1, Age == 52]\n",
      "Initial predicted margin: 0.30301121976\n",
      "Confidence-aware abductive explanation: [Obesity == 25.3, Sbp == 160, Ldl == 5.73, Typea == 49, Tobacco == 12, Famhist == 1, Age == 52]\n",
      "Final predicted margin: 1.936349560668\n"
     ]
    }
   ],
   "source": [
    "get_explain_results(\"saheart\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78aaf623",
   "metadata": {},
   "source": [
    "# Check threshold datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef001579",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a20aca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_explain_results_n(dataset_name, n_samples):\n",
    "    model, X, y, explainer = dataset_context[dataset_name]\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    # Prepare result DataFrame\n",
    "    results = []\n",
    "\n",
    "    # Loop over both classes\n",
    "    for classification in [0, 1]:\n",
    "        # Get indices for predicted samples of this class\n",
    "        indices = X[y_pred == classification].index[:n_samples]\n",
    "        if len(indices) == 0:\n",
    "            print(f\"No samples predicted as class {classification}.\")\n",
    "            continue\n",
    "\n",
    "        for idx in indices:\n",
    "            sample = X.loc[idx].values\n",
    "\n",
    "            # Initial explanation\n",
    "            margin = model.predict([sample], output_margin=True)[0]\n",
    "            xai_initial = explainer.explain_prob(sample)\n",
    "            xaiprob_initial = explainer.xai_predicted_margin\n",
    "            exp_len_initial = len(xai_initial)\n",
    "\n",
    "            # Explanation with adjusted threshold (half the margin)\n",
    "            xai_confidence_case1 = explainer.explain_prob(sample, target_threshold=margin / 2)\n",
    "            xaiprob_case1 = explainer.xai_predicted_margin\n",
    "            exp_len_case1 = len(xai_confidence_case1)\n",
    "            \n",
    "            increase_prob = -0.01 if margin < 0 else 0.01\n",
    "            xai_confidence_case2 = explainer.explain_prob(sample, target_threshold= xaiprob_initial + increase_prob)\n",
    "            xaiprob_case2 = explainer.xai_predicted_margin\n",
    "            exp_len_case2 = len(xai_confidence_case2)\n",
    "\n",
    "            # Append to results\n",
    "            results.append({\n",
    "                'sample_id': idx,\n",
    "                'class': classification,\n",
    "                'pred_margin': round(margin, 4),\n",
    "                'exp_len_inicial': exp_len_initial,\n",
    "                'xaiprob_inicial': round(xaiprob_initial, 4),\n",
    "                'exp_len_case1': exp_len_case1,\n",
    "                'xaiprob_case1': round(xaiprob_case1, 4),\n",
    "                'exp_len_case2': exp_len_case2,\n",
    "                'xaiprob_case2': round(xaiprob_case2, 4),\n",
    "            })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df_results = pd.DataFrame(results)\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "def summarize_explanations(df_results):\n",
    "    # Agrupar por classe e calcular as mÃ©tricas\n",
    "    summary = df_results.groupby('class').agg(\n",
    "        pred_margin_mean=('pred_margin', 'mean'),\n",
    "        pred_margin_std=('pred_margin', 'std'),\n",
    "        exp_len_inicial_mean=('exp_len_inicial', 'mean'),\n",
    "        exp_len_inicial_std=('exp_len_inicial', 'std'),\n",
    "        xaiprob_inicial_mean=('xaiprob_inicial', 'mean'),\n",
    "        xaiprob_inicial_std=('xaiprob_inicial', 'std'),\n",
    "        exp_len_case1_mean=('exp_len_case1', 'mean'),\n",
    "        exp_len_case1_std=('exp_len_case1', 'std'),\n",
    "        xaiprob_case1_mean=('xaiprob_case1', 'mean'),\n",
    "        xaiprob_case1_std=('xaiprob_case1', 'std'),\n",
    "        exp_len_case2_mean=('exp_len_case2', 'mean'),\n",
    "        exp_len_case2_std=('exp_len_case2', 'std'),\n",
    "        xaiprob_case2_mean=('xaiprob_case2', 'mean'),\n",
    "        xaiprob_case2_std=('xaiprob_case2', 'std'),\n",
    "    ).reset_index()\n",
    "\n",
    "    # FunÃ§Ã£o para combinar mean Â± std com 2 casas decimais\n",
    "    def format_mean_std(mean, std):\n",
    "        return f\"{mean:.2f} Â± {std:.2f}\"\n",
    "\n",
    "    # Aplicar a formataÃ§Ã£o em cada par de colunas\n",
    "    formatted = pd.DataFrame()\n",
    "    formatted['class'] = summary['class']\n",
    "    formatted['Pred Margin'] = summary.apply(lambda row: format_mean_std(row['pred_margin_mean'], row['pred_margin_std']), axis=1)\n",
    "    formatted['Exp Len Inicial'] = summary.apply(lambda row: format_mean_std(row['exp_len_inicial_mean'], row['exp_len_inicial_std']), axis=1)\n",
    "    formatted['ECM Inicial'] = summary.apply(lambda row: format_mean_std(row['xaiprob_inicial_mean'], row['xaiprob_inicial_std']), axis=1)\n",
    "    formatted['Exp Len case1'] = summary.apply(lambda row: format_mean_std(row['exp_len_case1_mean'], row['exp_len_case1_std']), axis=1)\n",
    "    formatted['ECM case1'] = summary.apply(lambda row: format_mean_std(row['xaiprob_case1_mean'], row['xaiprob_case1_std']), axis=1)\n",
    "    formatted['Exp Len case2'] = summary.apply(lambda row: format_mean_std(row['exp_len_case2_mean'], row['exp_len_case2_std']), axis=1)\n",
    "    formatted['ECM case2'] = summary.apply(lambda row: format_mean_std(row['xaiprob_case2_mean'], row['xaiprob_case2_std']), axis=1)\n",
    "\n",
    "    return formatted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b911b5",
   "metadata": {},
   "source": [
    "# datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5847dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>Pred Margin</th>\n",
       "      <th>Exp Len Inicial</th>\n",
       "      <th>ECM Inicial</th>\n",
       "      <th>Exp Len case1</th>\n",
       "      <th>ECM case1</th>\n",
       "      <th>Exp Len case2</th>\n",
       "      <th>ECM case2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-3.12 Â± 1.17</td>\n",
       "      <td>5.71 Â± 1.20</td>\n",
       "      <td>-0.36 Â± 0.33</td>\n",
       "      <td>7.07 Â± 0.79</td>\n",
       "      <td>-1.92 Â± 0.66</td>\n",
       "      <td>6.24 Â± 1.18</td>\n",
       "      <td>-0.79 Â± 0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.07 Â± 0.87</td>\n",
       "      <td>6.46 Â± 1.09</td>\n",
       "      <td>0.33 Â± 0.27</td>\n",
       "      <td>7.26 Â± 0.88</td>\n",
       "      <td>1.33 Â± 0.51</td>\n",
       "      <td>6.94 Â± 1.08</td>\n",
       "      <td>0.76 Â± 0.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class   Pred Margin Exp Len Inicial   ECM Inicial Exp Len case1  \\\n",
       "0      0  -3.12 Â± 1.17     5.71 Â± 1.20  -0.36 Â± 0.33   7.07 Â± 0.79   \n",
       "1      1   2.07 Â± 0.87     6.46 Â± 1.09   0.33 Â± 0.27   7.26 Â± 0.88   \n",
       "\n",
       "      ECM case1 Exp Len case2     ECM case2  \n",
       "0  -1.92 Â± 0.66   6.24 Â± 1.18  -0.79 Â± 0.46  \n",
       "1   1.33 Â± 0.51   6.94 Â± 1.08   0.76 Â± 0.35  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_saheart = get_explain_results_n(\"saheart\", 100)\n",
    "df_summary_saheart = summarize_explanations(df_saheart)\n",
    "df_summary_saheart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5174dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>Pred Margin</th>\n",
       "      <th>Exp Len Inicial</th>\n",
       "      <th>ECM Inicial</th>\n",
       "      <th>Exp Len case1</th>\n",
       "      <th>ECM case1</th>\n",
       "      <th>Exp Len case2</th>\n",
       "      <th>ECM case2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.99 Â± 2.06</td>\n",
       "      <td>9.67 Â± 3.28</td>\n",
       "      <td>-0.26 Â± 0.31</td>\n",
       "      <td>10.76 Â± 2.45</td>\n",
       "      <td>-1.16 Â± 1.10</td>\n",
       "      <td>10.24 Â± 3.16</td>\n",
       "      <td>-0.53 Â± 0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.22 Â± 2.02</td>\n",
       "      <td>6.65 Â± 1.39</td>\n",
       "      <td>0.20 Â± 0.22</td>\n",
       "      <td>8.26 Â± 1.11</td>\n",
       "      <td>1.80 Â± 1.09</td>\n",
       "      <td>7.38 Â± 1.83</td>\n",
       "      <td>0.56 Â± 0.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class   Pred Margin Exp Len Inicial   ECM Inicial Exp Len case1  \\\n",
       "0      0  -1.99 Â± 2.06     9.67 Â± 3.28  -0.26 Â± 0.31  10.76 Â± 2.45   \n",
       "1      1   3.22 Â± 2.02     6.65 Â± 1.39   0.20 Â± 0.22   8.26 Â± 1.11   \n",
       "\n",
       "      ECM case1 Exp Len case2     ECM case2  \n",
       "0  -1.16 Â± 1.10  10.24 Â± 3.16  -0.53 Â± 0.48  \n",
       "1   1.80 Â± 1.09   7.38 Â± 1.83   0.56 Â± 0.41  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adult = get_explain_results_n(\"adult\", 100)\n",
    "df_summary_adult = summarize_explanations(df_adult)\n",
    "df_summary_adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46b7809f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>Pred Margin</th>\n",
       "      <th>Exp Len Inicial</th>\n",
       "      <th>ECM Inicial</th>\n",
       "      <th>Exp Len case1</th>\n",
       "      <th>ECM case1</th>\n",
       "      <th>Exp Len case2</th>\n",
       "      <th>ECM case2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-7.82 Â± 0.95</td>\n",
       "      <td>2.11 Â± 0.40</td>\n",
       "      <td>-5.29 Â± 1.56</td>\n",
       "      <td>2.33 Â± 0.82</td>\n",
       "      <td>-5.52 Â± 1.01</td>\n",
       "      <td>3.11 Â± 0.40</td>\n",
       "      <td>-6.19 Â± 1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.97 Â± 0.80</td>\n",
       "      <td>4.51 Â± 0.56</td>\n",
       "      <td>2.41 Â± 0.63</td>\n",
       "      <td>5.44 Â± 0.69</td>\n",
       "      <td>5.00 Â± 0.69</td>\n",
       "      <td>5.51 Â± 0.56</td>\n",
       "      <td>3.27 Â± 0.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class   Pred Margin Exp Len Inicial   ECM Inicial Exp Len case1  \\\n",
       "0      0  -7.82 Â± 0.95     2.11 Â± 0.40  -5.29 Â± 1.56   2.33 Â± 0.82   \n",
       "1      1   7.97 Â± 0.80     4.51 Â± 0.56   2.41 Â± 0.63   5.44 Â± 0.69   \n",
       "\n",
       "      ECM case1 Exp Len case2     ECM case2  \n",
       "0  -5.52 Â± 1.01   3.11 Â± 0.40  -6.19 Â± 1.75  \n",
       "1   5.00 Â± 0.69   5.51 Â± 0.56   3.27 Â± 0.48  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mushroom = get_explain_results_n(\"mushroom\", 100)\n",
    "df_summary_mushroom = summarize_explanations(df_mushroom)\n",
    "df_summary_mushroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ef3b035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>Pred Margin</th>\n",
       "      <th>Exp Len Inicial</th>\n",
       "      <th>ECM Inicial</th>\n",
       "      <th>Exp Len case1</th>\n",
       "      <th>ECM case1</th>\n",
       "      <th>Exp Len case2</th>\n",
       "      <th>ECM case2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-4.14 Â± 0.90</td>\n",
       "      <td>14.62 Â± 3.05</td>\n",
       "      <td>-0.05 Â± 0.04</td>\n",
       "      <td>19.21 Â± 2.83</td>\n",
       "      <td>-2.12 Â± 0.45</td>\n",
       "      <td>14.83 Â± 3.00</td>\n",
       "      <td>-0.13 Â± 0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.92 Â± 0.95</td>\n",
       "      <td>13.36 Â± 3.32</td>\n",
       "      <td>0.07 Â± 0.07</td>\n",
       "      <td>17.55 Â± 2.86</td>\n",
       "      <td>2.02 Â± 0.50</td>\n",
       "      <td>13.76 Â± 3.15</td>\n",
       "      <td>0.16 Â± 0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class   Pred Margin Exp Len Inicial   ECM Inicial Exp Len case1  \\\n",
       "0      0  -4.14 Â± 0.90    14.62 Â± 3.05  -0.05 Â± 0.04  19.21 Â± 2.83   \n",
       "1      1   3.92 Â± 0.95    13.36 Â± 3.32   0.07 Â± 0.07  17.55 Â± 2.86   \n",
       "\n",
       "      ECM case1 Exp Len case2     ECM case2  \n",
       "0  -2.12 Â± 0.45  14.83 Â± 3.00  -0.13 Â± 0.07  \n",
       "1   2.02 Â± 0.50  13.76 Â± 3.15   0.16 Â± 0.12  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sonar = get_explain_results_n(\"sonar\", 100)\n",
    "df_summary_sonar = summarize_explanations(df_sonar)\n",
    "df_summary_sonar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be6cac7",
   "metadata": {},
   "source": [
    "# Test robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c27f6d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_robustness_results_n(dataset_name, n_samples, n_extra_samples, target_class=1,\n",
    "                              mult_margin=0, noise_level=0.5):\n",
    "    model, X, y, explainer = dataset_context[dataset_name]\n",
    "\n",
    "    # Armazena os resultados em lista\n",
    "    results = []\n",
    "\n",
    "    count = 0\n",
    "    for i in range(len(X)):\n",
    "        if count >= n_samples:\n",
    "            break\n",
    "\n",
    "        sample = X.iloc[i]\n",
    "        pred_class = model.predict([sample])[0]\n",
    "        if pred_class != target_class:\n",
    "            continue\n",
    "\n",
    "        margin = model.predict([sample], output_margin=True)[0]\n",
    "        explanation = explainer.explain_prob(sample, reorder=\"asc\", target_threshold=margin * mult_margin)\n",
    "\n",
    "        satisfying_df = generate_samples_for_conditions(X, explanation, n_samples=n_extra_samples, random_state=42)\n",
    "        noisy_df = apply_noise_to_samples(X, satisfying_df, noise_level=noise_level)\n",
    "        noisy_pred = model.predict(noisy_df)\n",
    "        noisy_pred_margin = model.predict(noisy_df, output_margin=True)\n",
    "\n",
    "        class_0 = np.sum(noisy_pred == 0)\n",
    "        class_1 = np.sum(noisy_pred == 1)\n",
    "\n",
    "        results.append({\n",
    "            \"amostra\": i,\n",
    "            \"classe_prevista\": int(pred_class),\n",
    "            \"classe_0_com_ruido\": int(class_0),\n",
    "            \"classe_1_com_ruido\": int(class_1),\n",
    "            # \"output_margin_medio\": float(np.mean(noisy_pred_margin)),\n",
    "            # \"output_margin_max\": float(np.max(noisy_pred_margin)),\n",
    "            # \"output_margin_min\": float(np.min(noisy_pred_margin))\n",
    "        })\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    # Converte para DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # CÃ¡lculo de mÃ©dia Â± desvio padrÃ£o para cada coluna\n",
    "    mean_0 = results_df[\"classe_0_com_ruido\"].mean()\n",
    "    std_0 = results_df[\"classe_0_com_ruido\"].std()\n",
    "\n",
    "    mean_1 = results_df[\"classe_1_com_ruido\"].mean()\n",
    "    std_1 = results_df[\"classe_1_com_ruido\"].std()\n",
    "\n",
    "    mean_results = pd.DataFrame([{\n",
    "        \"explanation class\": int(pred_class),\n",
    "        \"noise samples\": n_extra_samples,\n",
    "        \"noise level\": noise_level,\n",
    "        \"classified 0\": f\"{mean_0:.2f} Â± {std_0:.2f}\",\n",
    "        \"classified 1\": f\"{mean_1:.2f} Â± {std_1:.2f}\"\n",
    "    }])\n",
    "\n",
    "    return mean_results\n",
    "\n",
    "\n",
    "def generate_samples_for_conditions(df, conditions, n_samples=10, random_state=None):\n",
    "    \"\"\"\n",
    "    Gera amostras aleatÃ³rias que atendem a um conjunto de condiÃ§Ãµes, variando apenas as outras features.\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    fixed_values = {str(cond.arg(0)): float(cond.arg(1).as_fraction()) for cond in conditions}\n",
    "\n",
    "    df_variation = df.drop(columns=fixed_values.keys())\n",
    "    samples = {col: np.random.uniform(df[col].min(), df[col].max(), n_samples) for col in df_variation.columns}\n",
    "    samples = {key: np.round(value, 2) for key, value in samples.items()}\n",
    "\n",
    "    for feature, value in fixed_values.items():\n",
    "        samples[feature] = [value] * n_samples\n",
    "\n",
    "    generated_df = pd.DataFrame(samples)\n",
    "    return generated_df[df.columns]\n",
    "\n",
    "\n",
    "def apply_noise_to_samples(X, df, noise_level):\n",
    "    df_noisy = df.copy()\n",
    "    for col in df.columns:\n",
    "        min_val = X[col].min()\n",
    "        max_val = X[col].max()\n",
    "        random_vals = np.random.uniform(min_val, max_val, size=len(df))\n",
    "        # Interpola entre valor original e valor aleatÃ³rio\n",
    "        df_noisy[col] = (1 - noise_level) * df[col] + noise_level * random_vals\n",
    "    return df_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8112de35",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    {\"target_class\": 0, \"mult_margin\": 0},\n",
    "    {\"target_class\": 0, \"mult_margin\": 0.5},\n",
    "    {\"target_class\": 1, \"mult_margin\": 0},\n",
    "    {\"target_class\": 1, \"mult_margin\": 0.5},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa9e14ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>explanation class</th>\n",
       "      <th>noise samples</th>\n",
       "      <th>noise level</th>\n",
       "      <th>classified 0</th>\n",
       "      <th>classified 1</th>\n",
       "      <th>exp. threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>86.76 Â± 13.82</td>\n",
       "      <td>13.24 Â± 13.82</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>88.69 Â± 15.60</td>\n",
       "      <td>11.31 Â± 15.60</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>57.27 Â± 30.01</td>\n",
       "      <td>42.73 Â± 30.01</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>53.67 Â± 32.62</td>\n",
       "      <td>46.33 Â± 32.62</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   explanation class  noise samples  noise level   classified 0  \\\n",
       "0                  0            100          0.1  86.76 Â± 13.82   \n",
       "1                  0            100          0.1  88.69 Â± 15.60   \n",
       "2                  1            100          0.1  57.27 Â± 30.01   \n",
       "3                  1            100          0.1  53.67 Â± 32.62   \n",
       "\n",
       "    classified 1 exp. threshold  \n",
       "0  13.24 Â± 13.82             0%  \n",
       "1  11.31 Â± 15.60            50%  \n",
       "2  42.73 Â± 30.01             0%  \n",
       "3  46.33 Â± 32.62            50%  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results = []\n",
    "for config in configs:\n",
    "    df = get_robustness_results_n(\n",
    "        \"saheart\", \n",
    "        n_samples=100, \n",
    "        n_extra_samples=100, \n",
    "        target_class=config[\"target_class\"], \n",
    "        mult_margin=config[\"mult_margin\"], \n",
    "        noise_level=0.1\n",
    "    )\n",
    "\n",
    "    df[\"exp. threshold\"] = \"0%\" if config[\"mult_margin\"] == 0 else \"50%\"\n",
    "    all_results.append(df)\n",
    "\n",
    "results_df = pd.concat(all_results, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358b2b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "for config in configs:\n",
    "    df = get_robustness_results_n(\n",
    "        \"adult\", \n",
    "        n_samples=100,\n",
    "        n_extra_samples=100, \n",
    "        target_class=config[\"target_class\"], \n",
    "        mult_margin=config[\"mult_margin\"], \n",
    "        noise_level=0.1\n",
    "    )\n",
    "\n",
    "    df[\"target_class\"] = config[\"target_class\"]\n",
    "    df[\"exp. threshold\"] = \"0%\" if config[\"mult_margin\"] == 0 else \"50%\"\n",
    "    all_results.append(df)\n",
    "\n",
    "results_df = pd.concat(all_results, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98cdef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "for config in configs:\n",
    "    df = get_robustness_results_n(\n",
    "        \"mushroom\", \n",
    "        n_samples=100,\n",
    "        n_extra_samples=100, \n",
    "        target_class=config[\"target_class\"], \n",
    "        mult_margin=config[\"mult_margin\"], \n",
    "        noise_level=0.1\n",
    "    )\n",
    "\n",
    "    df[\"target_class\"] = config[\"target_class\"]\n",
    "    df[\"exp. threshold\"] = \"0%\" if config[\"mult_margin\"] == 0 else \"50%\"\n",
    "    all_results.append(df)\n",
    "\n",
    "results_df = pd.concat(all_results, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e845c5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "for config in configs:\n",
    "    df = get_robustness_results_n(\n",
    "        \"sonar\", \n",
    "        n_samples=100,\n",
    "        n_extra_samples=100, \n",
    "        target_class=config[\"target_class\"], \n",
    "        mult_margin=config[\"mult_margin\"], \n",
    "        noise_level=0.1\n",
    "    )\n",
    "\n",
    "    df[\"target_class\"] = config[\"target_class\"]\n",
    "    df[\"exp. threshold\"] = \"0%\" if config[\"mult_margin\"] == 0 else \"50%\"\n",
    "    all_results.append(df)\n",
    "\n",
    "results_df = pd.concat(all_results, ignore_index=True)\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
