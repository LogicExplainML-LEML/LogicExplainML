{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "394f70f1",
   "metadata": {},
   "source": [
    "# Imports + class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "231f4500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from z3 import *\n",
    "from xgboost import XGBClassifier\n",
    "from pmlb import fetch_data\n",
    "set_option(rational_to_decimal=True)\n",
    "\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c38991a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoostExplainer:\n",
    "    def __init__(self, model, data):\n",
    "        self.model = model\n",
    "        self.data = data.values\n",
    "        self.columns = data.columns\n",
    "        self.max_categories = 2\n",
    "\n",
    "        set_option(rational_to_decimal=True)\n",
    "        self.categoric_features = self.get_categoric_features(self.data)\n",
    "        self.T_model = self.model_trees_expression(self.model)\n",
    "        self.T = self.T_model\n",
    "\n",
    "    def explain(self, instance, reorder=\"asc\"):\n",
    "        self.I = self.instance_expression(instance)\n",
    "        self.D, self.D_add = self.decision_function_expression(self.model, [instance])\n",
    "        return self.explain_expression(self.I, And(self.T, self.D_add), self.D, self.model, reorder)\n",
    "\n",
    "    def explain_prob(self, instance, reorder=\"asc\", threshold_margin=0, target_threshold=None):\n",
    "        try:\n",
    "            self.I = self.instance_expression(instance)\n",
    "            self.D, self.D_add = self.decision_function_expression(self.model, [instance])\n",
    "            return self.explain_expression_prob(self.I, And(self.T, self.D_add), self.D, self.model, reorder, threshold_margin, target_threshold)\n",
    "        except Exception as e:\n",
    "            print(\"Error in explain_prob:\", e)\n",
    "            return []\n",
    "\n",
    "    def get_categoric_features(self, data: np.ndarray):\n",
    "        categoric_features = []\n",
    "        for i in range(data.shape[1]):\n",
    "            feature_values = data[:, i]\n",
    "            unique_values = np.unique(feature_values)\n",
    "            if len(unique_values) <= self.max_categories:\n",
    "                categoric_features.append(self.columns[i])\n",
    "\n",
    "        return categoric_features\n",
    "\n",
    "    def feature_constraints(self, constraints=[]):\n",
    "        \"\"\"TODO\n",
    "        esperado receber limites das features pelo usuário\n",
    "        formato previso: matriz/dataframe [feaature, min/max, valor]\n",
    "        constraaint_expression = \"constraaint_df_to_feature()\"\n",
    "        \"\"\"\n",
    "        return\n",
    "\n",
    "    def model_trees_expression(self, model):\n",
    "        df = model.get_booster().trees_to_dataframe()\n",
    "        if model.get_booster().feature_names == None:\n",
    "            feature_map = {f\"f{i}\": col for i, col in enumerate(self.columns)}\n",
    "            df[\"Feature\"] = df[\"Feature\"].replace(feature_map)\n",
    "\n",
    "        df[\"Split\"] = df[\"Split\"].round(4)\n",
    "        self.booster_df = df\n",
    "        class_index = 0  # if model.n_classes_ == 2:\n",
    "        all_tree_formulas = []\n",
    "\n",
    "        for tree_index in df[\"Tree\"].unique():\n",
    "            tree_df = df[df[\"Tree\"] == tree_index]\n",
    "            o = Real(f\"o_{tree_index}_{class_index}\")\n",
    "\n",
    "            if len(tree_df) == 1 and tree_df.iloc[0][\"Feature\"] == \"Leaf\":\n",
    "                leaf_value = tree_df.iloc[0][\"Gain\"]\n",
    "                all_tree_formulas.append(And(o == leaf_value))\n",
    "                continue\n",
    "            path_formulas = []\n",
    "\n",
    "            def get_conditions(node_id):\n",
    "                conditions = []\n",
    "                current_node = tree_df[tree_df[\"ID\"] == node_id]\n",
    "                if current_node.empty:\n",
    "                    return conditions\n",
    "\n",
    "                parent_node = tree_df[\n",
    "                    (tree_df[\"Yes\"] == node_id) | (tree_df[\"No\"] == node_id)\n",
    "                ]\n",
    "                if not parent_node.empty:\n",
    "                    parent_data = parent_node.iloc[0]\n",
    "                    feature = parent_data[\"Feature\"]\n",
    "                    split_value = parent_data[\"Split\"]\n",
    "                    x = Real(feature)\n",
    "                    if parent_data[\"Yes\"] == node_id:\n",
    "                        conditions.append(x < split_value)\n",
    "                    else:\n",
    "                        conditions.append(x >= split_value)\n",
    "                    conditions = get_conditions(parent_data[\"ID\"]) + conditions\n",
    "\n",
    "                return conditions\n",
    "\n",
    "            for _, node in tree_df[tree_df[\"Feature\"] == \"Leaf\"].iterrows():\n",
    "                leaf_value = node[\"Gain\"]\n",
    "                leaf_id = node[\"ID\"]\n",
    "                conditions = get_conditions(leaf_id)\n",
    "                path_formula = And(*conditions)\n",
    "                implication = Implies(path_formula, o == leaf_value)\n",
    "                path_formulas.append(implication)\n",
    "\n",
    "            all_tree_formulas.append(And(*path_formulas))\n",
    "        return And(*all_tree_formulas)\n",
    "\n",
    "    def get_init_value(self, model, x, estimator_variables):\n",
    "        estimator_pred = Solver()\n",
    "        estimator_pred.add(self.I)\n",
    "        estimator_pred.add(self.T)\n",
    "        if estimator_pred.check() == sat:\n",
    "            solvermodel = estimator_pred.model()\n",
    "            total_sum = sum(\n",
    "                float(solvermodel.eval(var).as_fraction()) for var in estimator_variables\n",
    "            )\n",
    "        else:\n",
    "            total_sum = 0\n",
    "            print(\"estimator error\")\n",
    "        self.predicted_margin = model.predict(x, output_margin=True)[0]\n",
    "        init_value = self.predicted_margin - total_sum\n",
    "        self.init_value = init_value\n",
    "        return init_value\n",
    "\n",
    "    def decision_function_expression(self, model, x):\n",
    "        n_classes = 1 if model.n_classes_ <= 2 else model.n_classes_\n",
    "        predicted_class = model.predict(x)[0]\n",
    "        self.predicted_class = predicted_class\n",
    "        n_estimators = int(len(model.get_booster().get_dump()) / n_classes)\n",
    "        estimator_variables = [Real(f\"o_{i}_0\") for i in range(n_estimators)] # _0 only for binary classification\n",
    "        self.estimator_variables = estimator_variables\n",
    "        init_value = self.get_init_value(model, x, estimator_variables)\n",
    "        # print(\"init:\", round(init_value, 2))\n",
    "\n",
    "        equation_list = []\n",
    "\n",
    "        estimator_sum = Real(\"estimator_sum\")\n",
    "        equation_o = estimator_sum == Sum(estimator_variables)\n",
    "        equation_list.append(equation_o)\n",
    "\n",
    "        decision = Real(\"decision\")\n",
    "        equation_list.append(decision == estimator_sum + init_value)\n",
    "\n",
    "        if predicted_class == 0:\n",
    "            final_equation = decision < 0\n",
    "        else:\n",
    "            final_equation = decision > 0\n",
    "\n",
    "        return final_equation, And(equation_list)\n",
    "\n",
    "    def instance_expression(self, instance):\n",
    "        formula = [Real(self.columns[i]) == value for i, value in enumerate(instance)]\n",
    "        return formula\n",
    "\n",
    "    def explain_expression(self, I, T_s, D_s, model, reorder):\n",
    "        i_expression = I.copy()\n",
    "\n",
    "        importances = model.feature_importances_\n",
    "        non_zero_indices = np.where(importances != 0)[0]\n",
    "\n",
    "        if reorder == \"asc\":\n",
    "            sorted_feature_indices = non_zero_indices[\n",
    "                np.argsort(importances[non_zero_indices])\n",
    "            ]\n",
    "            i_expression = [i_expression[i] for i in sorted_feature_indices]\n",
    "        elif reorder == \"desc\":\n",
    "            sorted_feature_indices = non_zero_indices[\n",
    "                np.argsort(-importances[non_zero_indices])\n",
    "            ]\n",
    "            i_expression = [i_expression[i] for i in sorted_feature_indices]\n",
    "\n",
    "        for feature in i_expression.copy():\n",
    "            # print(\"\\n---removed\", feature)\n",
    "            i_expression.remove(feature)\n",
    "\n",
    "            # prove(Implies(And(And(i_expression), T), D))\n",
    "            if self.is_proved(Implies(And(And(i_expression), T_s), D_s)):\n",
    "                continue\n",
    "                # print('proved')\n",
    "            else:\n",
    "                # print('not proved')\n",
    "                i_expression.append(feature)\n",
    "        # print(self.is_proved(Implies(And(And(i_expression), T_s), D_s)))\n",
    "        return i_expression\n",
    "\n",
    "    def explain_expression_prob(self, I, T_s, D_s, model, reorder, threshold_margin, target_threshold):\n",
    "        i_expression = I.copy()\n",
    "\n",
    "        importances = model.feature_importances_\n",
    "        non_zero_indices = np.where(importances != 0)[0]\n",
    "\n",
    "        if reorder == \"asc\":\n",
    "            sorted_feature_indices = non_zero_indices[\n",
    "                np.argsort(importances[non_zero_indices])\n",
    "            ]\n",
    "            i_expression = [i_expression[i] for i in sorted_feature_indices]\n",
    "        elif reorder == \"desc\":\n",
    "            sorted_feature_indices = non_zero_indices[\n",
    "                np.argsort(-importances[non_zero_indices])\n",
    "            ]\n",
    "            i_expression = [i_expression[i] for i in sorted_feature_indices]\n",
    "\n",
    "        threshold = 0\n",
    "\n",
    "        if target_threshold:\n",
    "            threshold = target_threshold\n",
    "        elif threshold_margin != 0:\n",
    "            threshold = self.predicted_margin * threshold_margin/100\n",
    "            # print(\"margin:\", self.predicted_margin, \"accepted margin:\", threshold)\n",
    "        self.xai_predicted_margin = self.predicted_margin\n",
    "\n",
    "        for feature in i_expression.copy():\n",
    "            # print(\"\\n---removed\", feature)\n",
    "            i_expression.remove(feature)\n",
    "\n",
    "            if self.is_proved_sat(And(And(i_expression), T_s), threshold):\n",
    "                # print('proved')\n",
    "                continue\n",
    "            else:\n",
    "                # print('not proved -- added back')\n",
    "                i_expression.append(feature)\n",
    "        return i_expression\n",
    "\n",
    "\n",
    "    def is_proved(self, decision_exp):\n",
    "        s = Solver()\n",
    "        s.add(Not(decision_exp))\n",
    "        if s.check() == unsat:\n",
    "            return True\n",
    "        else:\n",
    "            # print(s.model())\n",
    "            return False\n",
    "\n",
    "    def is_proved_sat(self, decision_exp, threshold):\n",
    "      decision = Real(\"decision\")\n",
    "\n",
    "      debug = Real(\"debug\") == 0\n",
    "      predicted_class = self.predicted_class\n",
    "\n",
    "      if predicted_class == 0:\n",
    "        estmax = Optimize()\n",
    "        estmax.add(decision_exp)\n",
    "        estmax.add(debug)\n",
    "        maxvalue = estmax.maximize(decision)\n",
    "        if estmax.check() == sat:\n",
    "            # print(\"\\nmax sat\", maxvalue.value())\n",
    "            try:\n",
    "              if float(maxvalue.value().as_fraction()) > threshold:\n",
    "                  return False # can change class\n",
    "              else:\n",
    "                  self.xai_predicted_margin = float(maxvalue.value().as_fraction())\n",
    "            except:\n",
    "              print(\"error max =\", maxvalue.value())\n",
    "              return False\n",
    "        else:\n",
    "            print(\"error\")\n",
    "\n",
    "      if predicted_class == 1:\n",
    "        estmin = Optimize()\n",
    "        estmin.add(decision_exp)\n",
    "        estmin.add(debug)\n",
    "        minvalue = estmin.minimize(decision)\n",
    "        if estmin.check() == sat:\n",
    "            # print(\"\\nmin sat\", minvalue.value())\n",
    "            try:\n",
    "              if float(minvalue.value().as_fraction()) < threshold:\n",
    "                  return False # can change class\n",
    "              else:\n",
    "                  self.xai_predicted_margin = float(minvalue.value().as_fraction())\n",
    "            except:\n",
    "              print(\"error min =\", minvalue.value())\n",
    "              return False\n",
    "        else:\n",
    "            print(\"error\")\n",
    "\n",
    "      if predicted_class == 0:\n",
    "        self.solvermodel = estmax.model()\n",
    "      if predicted_class == 1:\n",
    "        self.solvermodel = estmin.model()\n",
    "      return True\n",
    "  \n",
    "def generate_results(explainer, X_test, y_pred, classification, path, reorder=\"asc\"):\n",
    "    results = []\n",
    "    if classification == 0:\n",
    "        increase_prob = -0.01\n",
    "    else:\n",
    "        increase_prob = 0.01\n",
    "    for i in X_test[y_pred == classification].index:\n",
    "        sample = X_test.loc[i].values\n",
    "        xai = explainer.explain_prob(sample, reorder=reorder)\n",
    "        xaiprob_initial = explainer.xai_predicted_margin\n",
    "        len_xai_initial = len(xai)\n",
    "\n",
    "        xai = explainer.explain_prob(sample, reorder=reorder, target_threshold=xaiprob_initial + increase_prob)\n",
    "        xaiprob_final = explainer.xai_predicted_margin\n",
    "        len_xai_final = len(xai)\n",
    "\n",
    "        if round(xaiprob_initial, 2) == round(xaiprob_final, 2):\n",
    "            len_xai_initial = len_xai_final\n",
    "        results.append({\n",
    "            \"index\": i,\n",
    "            \"class\": classification,\n",
    "            \"xaiprob_initial\": round(xaiprob_initial, 2),\n",
    "            \"len_xai_initial\": len_xai_initial,\n",
    "            \"xaiprob_final\": round(xaiprob_final, 2),\n",
    "            \"len_xai_final\": len_xai_final\n",
    "        })\n",
    "    df_results = pd.DataFrame(results)\n",
    "    return df_results\n",
    "    # df_results.to_csv(f'{path}/results_{classification}_{reorder}.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fc67b6",
   "metadata": {},
   "source": [
    "# Prepare datasets and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "877534ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset_model_explainer(dataset_name, dataset_params):\n",
    "    # Fetch data\n",
    "    dataset = fetch_data(dataset_name)\n",
    "    X = dataset.drop('target', axis=1)\n",
    "    y = dataset['target']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "    \n",
    "    params = dataset_params[dataset_name]\n",
    "\n",
    "    # Train model\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Metrics\n",
    "    print(\"Dataset size:\", len(X))\n",
    "    print(\"Columns:\", len(X.columns))\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"F1-score:\", f1_score(y_test, y_pred))\n",
    "\n",
    "    # Explainer\n",
    "    explainer = XGBoostExplainer(model, X_train)\n",
    "\n",
    "    return model, X, y, X_test, y_test, explainer\n",
    "\n",
    "def prepare_all_datasets(dataset_names, dataset_params):\n",
    "    context = {}\n",
    "    for name in dataset_names:\n",
    "        print(f\"\\n--- Preparing {name} ---\")\n",
    "        model, X, y, X_test, y_test, explainer = prepare_dataset_model_explainer(name, dataset_params)\n",
    "        context[name] = (model, X, y, X_test, y_test, explainer)\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f96f764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preparing magic ---\n",
      "Dataset size: 19020\n",
      "Columns: 10\n",
      "Accuracy: 0.8755695758850333\n",
      "F1-score: 0.8060109289617486\n",
      "\n",
      "--- Preparing adult ---\n",
      "Dataset size: 48842\n",
      "Columns: 14\n",
      "Accuracy: 0.8652835596806114\n",
      "F1-score: 0.9144491635607177\n",
      "\n",
      "--- Preparing mushroom ---\n",
      "Dataset size: 8124\n",
      "Columns: 22\n",
      "Accuracy: 1.0\n",
      "F1-score: 1.0\n",
      "\n",
      "--- Preparing spambase ---\n",
      "Dataset size: 4601\n",
      "Columns: 57\n",
      "Accuracy: 0.9471397538015931\n",
      "F1-score: 0.9322191272051996\n"
     ]
    }
   ],
   "source": [
    "dataset_names = [\n",
    "                \"magic\", \n",
    "                \"adult\", \n",
    "                \"mushroom\", \n",
    "                \"spambase\",\n",
    "                 ]\n",
    "\n",
    "dataset_params = {\n",
    "    \"magic\": {\"n_estimators\": 30, \"max_depth\": 3},\n",
    "    \"adult\": {\"n_estimators\": 30, \"max_depth\": 3},\n",
    "    \"mushroom\": {\"n_estimators\": 30, \"max_depth\": 3},\n",
    "    \"spambase\": {\"n_estimators\": 30, \"max_depth\": 3},\n",
    "}\n",
    "\n",
    "dataset_context = prepare_all_datasets(dataset_names, dataset_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20e5c0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: magic, Class 0: 4052, Class 1: 1654\n",
      "Dataset: adult, Class 0: 2726, Class 1: 11927\n",
      "Dataset: mushroom, Class 0: 1263, Class 1: 1175\n",
      "Dataset: spambase, Class 0: 848, Class 1: 533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.int64(848), np.int64(533))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_classes(dataset_name):\n",
    "    model, X, y, X_test, y_test, explainer = dataset_context[dataset_name]\n",
    "    y_pred = model.predict(X_test)\n",
    "    class_0_count = np.sum(y_pred == 0)\n",
    "    class_1_count = np.sum(y_pred == 1)\n",
    "    print(f\"Dataset: {dataset_name}, Class 0: {class_0_count}, Class 1: {class_1_count}\")\n",
    "    return class_0_count, class_1_count\n",
    "\n",
    "count_classes(\"magic\")\n",
    "count_classes(\"adult\")\n",
    "count_classes(\"mushroom\")\n",
    "count_classes(\"spambase\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbeaf39",
   "metadata": {},
   "source": [
    "# Check explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b55a38d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_explain_results(dataset_name, print_exp = False):\n",
    "    model, X, y, X_test, y_test, explainer = dataset_context[dataset_name]\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Function to explain a sample of a given class\n",
    "    def explain_for_class(classification):\n",
    "        # Get a sample of the specified class in predictions\n",
    "        indices = X_test[y_pred == classification].index\n",
    "        if len(indices) == 0:\n",
    "            print(f\"No samples predicted as class {classification}.\")\n",
    "            return\n",
    "        \n",
    "        for i in indices:\n",
    "            sample = X_test.loc[i].values\n",
    "            margin = model.predict([sample], output_margin=True)[0]\n",
    "            if abs(margin) > 1.0:\n",
    "                break\n",
    "        else:\n",
    "            print(f\"No samples with |margin| > 1.0 for class {classification}.\")\n",
    "            return\n",
    "\n",
    "        # Initial explanation\n",
    "        margin = model.predict([sample], output_margin=True)[0]\n",
    "        print(f\"\\nClass {classification} - Margin: {margin}, Sample index: {i}\")\n",
    "\n",
    "        xai = explainer.explain_prob(sample)\n",
    "        if print_exp:\n",
    "            print(\"Initial abductive explanation:\", xai)\n",
    "        \n",
    "        xaiprob_initial = explainer.xai_predicted_margin\n",
    "        print(\"Initial predicted margin:\", xaiprob_initial)\n",
    "\n",
    "        # Adjust margin direction\n",
    "        # increase_prob = -0.01 if classification == 0 else 0.01\n",
    "\n",
    "        # Explanation with adjusted threshold\n",
    "        xai_confidence = explainer.explain_prob(sample, target_threshold= (margin / 4))\n",
    "        xaiprob_final = explainer.xai_predicted_margin\n",
    "        print(\"\\n0.25% exp len:\", len(xai_confidence))\n",
    "        if print_exp:\n",
    "            print(\"0.25% explanation:\", xai_confidence)\n",
    "        print(\"0.25% predicted margin:\", xaiprob_final)\n",
    "\n",
    "        xai_confidence = explainer.explain_prob(sample, target_threshold= (margin / 2))\n",
    "        xaiprob_final = explainer.xai_predicted_margin\n",
    "        print(\"\\n0.5% exp len:\", len(xai_confidence))\n",
    "        if print_exp:\n",
    "            print(\"0.5% explanation:\", xai_confidence)\n",
    "        print(\"0.5% predicted margin:\", xaiprob_final)\n",
    "        \n",
    "        xai_confidence = explainer.explain_prob(sample, target_threshold= (margin / 1.33333))\n",
    "        xaiprob_final = explainer.xai_predicted_margin\n",
    "        print(\"\\n0.75% exp len:\", len(xai_confidence))\n",
    "        if print_exp:\n",
    "            print(\"0.75% explanation:\", xai_confidence)\n",
    "        print(\"0.75% predicted margin:\", xaiprob_final)\n",
    "\n",
    "    # Explain for both classes\n",
    "    explain_for_class(0)\n",
    "    explain_for_class(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96d90cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class 0 - Margin: -1.5318019390106201, Sample index: 13519\n",
      "Initial predicted margin: -0.305143745439\n",
      "\n",
      "0.25% exp len: 8\n",
      "0.25% predicted margin: -0.842865952239\n",
      "\n",
      "0.5% exp len: 8\n",
      "0.5% predicted margin: -0.842865952239\n",
      "\n",
      "0.75% exp len: 9\n",
      "0.75% predicted margin: -1.438409154139\n",
      "\n",
      "Class 1 - Margin: 5.3488240242004395, Sample index: 14526\n",
      "Initial predicted margin: 0.298496220521\n",
      "\n",
      "0.25% exp len: 3\n",
      "0.25% predicted margin: 3.056817650122\n",
      "\n",
      "0.5% exp len: 3\n",
      "0.5% predicted margin: 3.056817650122\n",
      "\n",
      "0.75% exp len: 4\n",
      "0.75% predicted margin: 4.514383172382\n"
     ]
    }
   ],
   "source": [
    "get_explain_results(\"magic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9864ddbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class 0 - Margin: -1.0879830121994019, Sample index: 3829\n",
      "Initial predicted margin: -0.201337004746\n",
      "\n",
      "0.25% exp len: 8\n",
      "0.25% predicted margin: -0.623709311386\n",
      "\n",
      "0.5% exp len: 8\n",
      "0.5% predicted margin: -0.623709311386\n",
      "\n",
      "0.75% exp len: 10\n",
      "0.75% predicted margin: -0.875320690366\n",
      "\n",
      "Class 1 - Margin: 4.173804759979248, Sample index: 30437\n",
      "Initial predicted margin: 0.063445309674\n",
      "\n",
      "0.25% exp len: 5\n",
      "0.25% predicted margin: 1.69386289997\n",
      "\n",
      "0.5% exp len: 6\n",
      "0.5% predicted margin: 2.10872710087\n",
      "\n",
      "0.75% exp len: 7\n",
      "0.75% predicted margin: 3.172982332594\n"
     ]
    }
   ],
   "source": [
    "get_explain_results(\"adult\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27c75f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class 0 - Margin: -7.027366638183594, Sample index: 7176\n",
      "Initial predicted margin: -4.6045556678\n",
      "\n",
      "0.25% exp len: 3\n",
      "0.25% predicted margin: -4.6045556678\n",
      "\n",
      "0.5% exp len: 3\n",
      "0.5% predicted margin: -4.6045556678\n",
      "\n",
      "0.75% exp len: 5\n",
      "0.75% predicted margin: -5.6530501859\n",
      "\n",
      "Class 1 - Margin: 8.294289588928223, Sample index: 4961\n",
      "Initial predicted margin: 0.0284762922\n",
      "\n",
      "0.25% exp len: 4\n",
      "0.25% predicted margin: 3.9462458302\n",
      "\n",
      "0.5% exp len: 5\n",
      "0.5% predicted margin: 5.1567087872\n",
      "\n",
      "0.75% exp len: 7\n",
      "0.75% predicted margin: 6.4058943492\n"
     ]
    }
   ],
   "source": [
    "get_explain_results(\"mushroom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ba516fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class 0 - Margin: -6.460454940795898, Sample index: 4538\n",
      "Initial predicted margin: -0.04732684392\n",
      "\n",
      "0.25% exp len: 13\n",
      "0.25% predicted margin: -1.68991961052\n",
      "\n",
      "0.5% exp len: 17\n",
      "0.5% predicted margin: -3.317425186\n",
      "\n",
      "0.75% exp len: 19\n",
      "0.75% predicted margin: -4.8820868495\n",
      "\n",
      "Class 1 - Margin: 4.380174160003662, Sample index: 1685\n",
      "Initial predicted margin: 0.1421553674\n",
      "\n",
      "0.25% exp len: 15\n",
      "0.25% predicted margin: 1.1584000099\n",
      "\n",
      "0.5% exp len: 18\n",
      "0.5% predicted margin: 2.21234623721\n",
      "\n",
      "0.75% exp len: 21\n",
      "0.75% predicted margin: 3.2869784274\n"
     ]
    }
   ],
   "source": [
    "get_explain_results(\"spambase\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78aaf623",
   "metadata": {},
   "source": [
    "# Check threshold datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef001579",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20aca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_explain_results_n(dataset_name, n_samples):\n",
    "#     model, X, y, X_test, y_test, explainer = dataset_context[dataset_name]\n",
    "#     y_pred = model.predict(X_test)\n",
    "\n",
    "#     # Prepare result DataFrame\n",
    "#     results = []\n",
    "\n",
    "#     # Loop over both classes\n",
    "#     for classification in [0, 1]:\n",
    "#         # Get indices for predicted samples of this class\n",
    "#         indices = X_test[y_pred == classification].index[:n_samples]\n",
    "#         if len(indices) == 0:\n",
    "#             print(f\"No samples predicted as class {classification}.\")\n",
    "#             continue\n",
    "\n",
    "#         for idx in indices:\n",
    "#             sample = X_test.loc[idx].values\n",
    "\n",
    "#             # Initial explanation\n",
    "#             margin = model.predict([sample], output_margin=True)[0]\n",
    "#             xai_initial = explainer.explain_prob(sample)\n",
    "#             xaiprob_initial = explainer.xai_predicted_margin\n",
    "#             exp_len_initial = len(xai_initial)\n",
    "\n",
    "#             # Explanation with adjusted threshold (half the margin)\n",
    "#             xai_confidence_case1 = explainer.explain_prob(sample, target_threshold=margin / 2)\n",
    "#             xaiprob_case1 = explainer.xai_predicted_margin\n",
    "#             exp_len_case1 = len(xai_confidence_case1)\n",
    "            \n",
    "#             increase_prob = -0.01 if margin < 0 else 0.01\n",
    "#             xai_confidence_case2 = explainer.explain_prob(sample, target_threshold= xaiprob_initial + increase_prob)\n",
    "#             xaiprob_case2 = explainer.xai_predicted_margin\n",
    "#             exp_len_case2 = len(xai_confidence_case2)\n",
    "\n",
    "#             # Append to results\n",
    "#             results.append({\n",
    "#                 'sample_id': idx,\n",
    "#                 'class': classification,\n",
    "#                 'pred_margin': round(margin, 4),\n",
    "#                 'exp_len_inicial': exp_len_initial,\n",
    "#                 'xaiprob_inicial': round(xaiprob_initial, 4),\n",
    "#                 'exp_len_case1': exp_len_case1,\n",
    "#                 'xaiprob_case1': round(xaiprob_case1, 4),\n",
    "#                 'exp_len_case2': exp_len_case2,\n",
    "#                 'xaiprob_case2': round(xaiprob_case2, 4),\n",
    "#             })\n",
    "\n",
    "#     # Convert to DataFrame\n",
    "#     df_results = pd.DataFrame(results)\n",
    "    \n",
    "#     return df_results\n",
    "\n",
    "# def summarize_explanations(df_results):\n",
    "#     # Agrupar por classe e calcular as métricas\n",
    "#     summary = df_results.groupby('class').agg(\n",
    "#         pred_margin_mean=('pred_margin', 'mean'),\n",
    "#         pred_margin_std=('pred_margin', 'std'),\n",
    "#         exp_len_inicial_mean=('exp_len_inicial', 'mean'),\n",
    "#         exp_len_inicial_std=('exp_len_inicial', 'std'),\n",
    "#         xaiprob_inicial_mean=('xaiprob_inicial', 'mean'),\n",
    "#         xaiprob_inicial_std=('xaiprob_inicial', 'std'),\n",
    "#         exp_len_case1_mean=('exp_len_case1', 'mean'),\n",
    "#         exp_len_case1_std=('exp_len_case1', 'std'),\n",
    "#         xaiprob_case1_mean=('xaiprob_case1', 'mean'),\n",
    "#         xaiprob_case1_std=('xaiprob_case1', 'std'),\n",
    "#         exp_len_case2_mean=('exp_len_case2', 'mean'),\n",
    "#         exp_len_case2_std=('exp_len_case2', 'std'),\n",
    "#         xaiprob_case2_mean=('xaiprob_case2', 'mean'),\n",
    "#         xaiprob_case2_std=('xaiprob_case2', 'std'),\n",
    "#     ).reset_index()\n",
    "\n",
    "#     # Função para combinar mean ± std com 2 casas decimais\n",
    "#     def format_mean_std(mean, std):\n",
    "#         return f\"{mean:.2f} ± {std:.2f}\"\n",
    "\n",
    "#     # Aplicar a formatação em cada par de colunas\n",
    "#     formatted = pd.DataFrame()\n",
    "#     formatted['class'] = summary['class']\n",
    "#     formatted['Pred Margin'] = summary.apply(lambda row: format_mean_std(row['pred_margin_mean'], row['pred_margin_std']), axis=1)\n",
    "#     formatted['Exp Len Inicial'] = summary.apply(lambda row: format_mean_std(row['exp_len_inicial_mean'], row['exp_len_inicial_std']), axis=1)\n",
    "#     formatted['MCT Inicial'] = summary.apply(lambda row: format_mean_std(row['xaiprob_inicial_mean'], row['xaiprob_inicial_std']), axis=1)\n",
    "#     formatted['Exp Len case1'] = summary.apply(lambda row: format_mean_std(row['exp_len_case1_mean'], row['exp_len_case1_std']), axis=1)\n",
    "#     formatted['MCT case1'] = summary.apply(lambda row: format_mean_std(row['xaiprob_case1_mean'], row['xaiprob_case1_std']), axis=1)\n",
    "#     formatted['Exp Len case2'] = summary.apply(lambda row: format_mean_std(row['exp_len_case2_mean'], row['exp_len_case2_std']), axis=1)\n",
    "#     formatted['MCT case2'] = summary.apply(lambda row: format_mean_std(row['xaiprob_case2_mean'], row['xaiprob_case2_std']), axis=1)\n",
    "\n",
    "#     return formatted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d63deff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_explain_results_n(dataset_name, n_samples):\n",
    "    model, X, y, X_test, y_test, explainer = dataset_context[dataset_name]\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Prepare result DataFrame\n",
    "    results = []\n",
    "\n",
    "    # Loop over both classes\n",
    "    for classification in [0, 1]:\n",
    "        # Get indices for predicted samples of this class\n",
    "        indices = X_test[y_pred == classification].index[:n_samples]\n",
    "        if len(indices) == 0:\n",
    "            print(f\"No samples predicted as class {classification}.\")\n",
    "            continue\n",
    "\n",
    "        for idx in indices:\n",
    "            sample = X_test.loc[idx].values\n",
    "\n",
    "            # Initial explanation\n",
    "            margin = model.predict([sample], output_margin=True)[0]\n",
    "            xai_initial = explainer.explain_prob(sample)\n",
    "            xaiprob_initial = explainer.xai_predicted_margin\n",
    "            exp_len_initial = len(xai_initial)\n",
    "\n",
    "            # Explanation with adjusted threshold (half the margin)\n",
    "            xai_confidence_25 = explainer.explain_prob(sample, target_threshold=margin / 4)\n",
    "            xaiprob_25 = explainer.xai_predicted_margin\n",
    "            exp_len_25 = len(xai_confidence_25)\n",
    "            \n",
    "            # Explanation with adjusted threshold (half the margin)\n",
    "            xai_confidence_50 = explainer.explain_prob(sample, target_threshold=margin / 2)\n",
    "            xaiprob_50 = explainer.xai_predicted_margin\n",
    "            exp_len_50 = len(xai_confidence_50)\n",
    "\n",
    "            # Explanation with adjusted threshold (half the margin)\n",
    "            xai_confidence_75 = explainer.explain_prob(sample, target_threshold=margin / 1.3333)\n",
    "            xaiprob_75 = explainer.xai_predicted_margin\n",
    "            exp_len_75 = len(xai_confidence_75)\n",
    "\n",
    "            # Append to results\n",
    "            results.append({\n",
    "                'sample_id': idx,\n",
    "                'class': classification,\n",
    "                'pred_margin': round(margin, 4),\n",
    "                'exp_len_inicial': exp_len_initial,\n",
    "                'xaiprob_inicial': round(xaiprob_initial, 4),\n",
    "                'exp_len_25': exp_len_25,\n",
    "                'xaiprob_25': round(xaiprob_25, 4),\n",
    "                'exp_len_50': exp_len_50,\n",
    "                'xaiprob_50': round(xaiprob_50, 4),\n",
    "                'exp_len_75': exp_len_75,\n",
    "                'xaiprob_75': round(xaiprob_75, 4),\n",
    "            })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df_results = pd.DataFrame(results)\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "def summarize_explanations(df_results):\n",
    "    # Agrupar por classe e calcular as métricas\n",
    "    summary = df_results.groupby('class').agg(\n",
    "        pred_margin_mean=('pred_margin', 'mean'),\n",
    "        pred_margin_std=('pred_margin', 'std'),\n",
    "        exp_len_inicial_mean=('exp_len_inicial', 'mean'),\n",
    "        exp_len_inicial_std=('exp_len_inicial', 'std'),\n",
    "        xaiprob_inicial_mean=('xaiprob_inicial', 'mean'),\n",
    "        xaiprob_inicial_std=('xaiprob_inicial', 'std'),\n",
    "        exp_len_25_mean=('exp_len_25', 'mean'),\n",
    "        exp_len_25_std=('exp_len_25', 'std'),\n",
    "        xaiprob_25_mean=('xaiprob_25', 'mean'),\n",
    "        xaiprob_25_std=('xaiprob_25', 'std'),\n",
    "        exp_len_50_mean=('exp_len_50', 'mean'),\n",
    "        exp_len_50_std=('exp_len_50', 'std'),\n",
    "        xaiprob_50_mean=('xaiprob_50', 'mean'),\n",
    "        xaiprob_50_std=('xaiprob_50', 'std'),\n",
    "        exp_len_75_mean=('exp_len_75', 'mean'),\n",
    "        exp_len_75_std=('exp_len_75', 'std'),\n",
    "        xaiprob_75_mean=('xaiprob_75', 'mean'),\n",
    "        xaiprob_75_std=('xaiprob_75', 'std'),\n",
    "    ).reset_index()\n",
    "\n",
    "\n",
    "    # Função para combinar mean ± std com 2 casas decimais\n",
    "    def format_mean_std(mean, std):\n",
    "        return f\"{mean:.2f} ± {std:.2f}\"\n",
    "\n",
    "    # Aplicar a formatação em cada par de colunas\n",
    "    formatted = pd.DataFrame()\n",
    "    formatted['class'] = summary['class']\n",
    "    formatted['Pred Margin'] = summary.apply(lambda row: format_mean_std(row['pred_margin_mean'], row['pred_margin_std']), axis=1)\n",
    "    formatted['Exp Len Inicial'] = summary.apply(lambda row: format_mean_std(row['exp_len_inicial_mean'], row['exp_len_inicial_std']), axis=1)\n",
    "    formatted['MCT Inicial'] = summary.apply(lambda row: format_mean_std(row['xaiprob_inicial_mean'], row['xaiprob_inicial_std']), axis=1)\n",
    "    formatted['Exp Len 25'] = summary.apply(lambda row: format_mean_std(row['exp_len_25_mean'], row['exp_len_25_std']), axis=1)\n",
    "    formatted['MCT 25'] = summary.apply(lambda row: format_mean_std(row['xaiprob_25_mean'], row['xaiprob_25_std']), axis=1)\n",
    "    formatted['Exp Len 50'] = summary.apply(lambda row: format_mean_std(row['exp_len_50_mean'], row['exp_len_50_std']), axis=1)\n",
    "    formatted['MCT 50'] = summary.apply(lambda row: format_mean_std(row['xaiprob_50_mean'], row['xaiprob_50_std']), axis=1)\n",
    "    formatted['Exp Len 75'] = summary.apply(lambda row: format_mean_std(row['exp_len_75_mean'], row['exp_len_75_std']), axis=1)\n",
    "    formatted['MCT 75'] = summary.apply(lambda row: format_mean_std(row['xaiprob_75_mean'], row['xaiprob_75_std']), axis=1)\n",
    "\n",
    "    return formatted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b911b5",
   "metadata": {},
   "source": [
    "# datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671ff1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_to_explain = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b5847dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>Pred Margin</th>\n",
       "      <th>Exp Len Inicial</th>\n",
       "      <th>MCT Inicial</th>\n",
       "      <th>Exp Len 25</th>\n",
       "      <th>MCT 25</th>\n",
       "      <th>Exp Len 50</th>\n",
       "      <th>MCT 50</th>\n",
       "      <th>Exp Len 75</th>\n",
       "      <th>MCT 75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.18 ± 1.00</td>\n",
       "      <td>6.40 ± 1.35</td>\n",
       "      <td>-0.28 ± 0.31</td>\n",
       "      <td>6.90 ± 1.29</td>\n",
       "      <td>-0.89 ± 0.42</td>\n",
       "      <td>7.70 ± 1.06</td>\n",
       "      <td>-1.33 ± 0.68</td>\n",
       "      <td>8.40 ± 0.70</td>\n",
       "      <td>-1.92 ± 0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.19 ± 1.98</td>\n",
       "      <td>3.40 ± 0.70</td>\n",
       "      <td>0.18 ± 0.13</td>\n",
       "      <td>4.20 ± 0.63</td>\n",
       "      <td>0.92 ± 0.86</td>\n",
       "      <td>4.50 ± 0.71</td>\n",
       "      <td>1.41 ± 1.20</td>\n",
       "      <td>5.10 ± 0.74</td>\n",
       "      <td>1.86 ± 1.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class   Pred Margin Exp Len Inicial   MCT Inicial   Exp Len 25  \\\n",
       "0      0  -2.18 ± 1.00     6.40 ± 1.35  -0.28 ± 0.31  6.90 ± 1.29   \n",
       "1      1   2.19 ± 1.98     3.40 ± 0.70   0.18 ± 0.13  4.20 ± 0.63   \n",
       "\n",
       "         MCT 25   Exp Len 50        MCT 50   Exp Len 75        MCT 75  \n",
       "0  -0.89 ± 0.42  7.70 ± 1.06  -1.33 ± 0.68  8.40 ± 0.70  -1.92 ± 0.91  \n",
       "1   0.92 ± 0.86  4.50 ± 0.71   1.41 ± 1.20  5.10 ± 0.74   1.86 ± 1.65  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_saheart = get_explain_results_n(\"magic\", instances_to_explain)\n",
    "df_summary_saheart = summarize_explanations(df_saheart)\n",
    "df_summary_saheart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f5174dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>Pred Margin</th>\n",
       "      <th>Exp Len Inicial</th>\n",
       "      <th>MCT Inicial</th>\n",
       "      <th>Exp Len 25</th>\n",
       "      <th>MCT 25</th>\n",
       "      <th>Exp Len 50</th>\n",
       "      <th>MCT 50</th>\n",
       "      <th>Exp Len 75</th>\n",
       "      <th>MCT 75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.28 ± 1.45</td>\n",
       "      <td>8.10 ± 2.28</td>\n",
       "      <td>-0.16 ± 0.18</td>\n",
       "      <td>8.60 ± 2.01</td>\n",
       "      <td>-0.47 ± 0.44</td>\n",
       "      <td>9.40 ± 1.78</td>\n",
       "      <td>-0.72 ± 0.74</td>\n",
       "      <td>10.50 ± 1.18</td>\n",
       "      <td>-1.04 ± 1.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.16 ± 1.32</td>\n",
       "      <td>4.60 ± 1.26</td>\n",
       "      <td>0.08 ± 0.04</td>\n",
       "      <td>5.20 ± 0.92</td>\n",
       "      <td>0.92 ± 0.54</td>\n",
       "      <td>5.60 ± 1.07</td>\n",
       "      <td>1.24 ± 0.67</td>\n",
       "      <td>6.50 ± 0.85</td>\n",
       "      <td>1.70 ± 1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class   Pred Margin Exp Len Inicial   MCT Inicial   Exp Len 25  \\\n",
       "0      0  -1.28 ± 1.45     8.10 ± 2.28  -0.16 ± 0.18  8.60 ± 2.01   \n",
       "1      1   2.16 ± 1.32     4.60 ± 1.26   0.08 ± 0.04  5.20 ± 0.92   \n",
       "\n",
       "         MCT 25   Exp Len 50        MCT 50    Exp Len 75        MCT 75  \n",
       "0  -0.47 ± 0.44  9.40 ± 1.78  -0.72 ± 0.74  10.50 ± 1.18  -1.04 ± 1.12  \n",
       "1   0.92 ± 0.54  5.60 ± 1.07   1.24 ± 0.67   6.50 ± 0.85   1.70 ± 1.00  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adult = get_explain_results_n(\"adult\", instances_to_explain)\n",
    "df_summary_adult = summarize_explanations(df_adult)\n",
    "df_summary_adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "46b7809f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>Pred Margin</th>\n",
       "      <th>Exp Len Inicial</th>\n",
       "      <th>MCT Inicial</th>\n",
       "      <th>Exp Len 25</th>\n",
       "      <th>MCT 25</th>\n",
       "      <th>Exp Len 50</th>\n",
       "      <th>MCT 50</th>\n",
       "      <th>Exp Len 75</th>\n",
       "      <th>MCT 75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-6.24 ± 2.11</td>\n",
       "      <td>3.60 ± 1.43</td>\n",
       "      <td>-2.89 ± 2.22</td>\n",
       "      <td>4.00 ± 1.76</td>\n",
       "      <td>-3.55 ± 1.73</td>\n",
       "      <td>4.30 ± 2.11</td>\n",
       "      <td>-3.77 ± 1.41</td>\n",
       "      <td>6.60 ± 1.65</td>\n",
       "      <td>-4.82 ± 1.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6.75 ± 1.68</td>\n",
       "      <td>2.90 ± 0.88</td>\n",
       "      <td>0.69 ± 0.61</td>\n",
       "      <td>4.10 ± 0.57</td>\n",
       "      <td>2.49 ± 1.10</td>\n",
       "      <td>5.50 ± 0.85</td>\n",
       "      <td>3.95 ± 1.16</td>\n",
       "      <td>7.30 ± 1.49</td>\n",
       "      <td>5.35 ± 1.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class   Pred Margin Exp Len Inicial   MCT Inicial   Exp Len 25  \\\n",
       "0      0  -6.24 ± 2.11     3.60 ± 1.43  -2.89 ± 2.22  4.00 ± 1.76   \n",
       "1      1   6.75 ± 1.68     2.90 ± 0.88   0.69 ± 0.61  4.10 ± 0.57   \n",
       "\n",
       "         MCT 25   Exp Len 50        MCT 50   Exp Len 75        MCT 75  \n",
       "0  -3.55 ± 1.73  4.30 ± 2.11  -3.77 ± 1.41  6.60 ± 1.65  -4.82 ± 1.63  \n",
       "1   2.49 ± 1.10  5.50 ± 0.85   3.95 ± 1.16  7.30 ± 1.49   5.35 ± 1.33  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mushroom = get_explain_results_n(\"mushroom\", instances_to_explain)\n",
    "df_summary_mushroom = summarize_explanations(df_mushroom)\n",
    "df_summary_mushroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6ef3b035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>Pred Margin</th>\n",
       "      <th>Exp Len Inicial</th>\n",
       "      <th>MCT Inicial</th>\n",
       "      <th>Exp Len 25</th>\n",
       "      <th>MCT 25</th>\n",
       "      <th>Exp Len 50</th>\n",
       "      <th>MCT 50</th>\n",
       "      <th>Exp Len 75</th>\n",
       "      <th>MCT 75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-3.31 ± 1.62</td>\n",
       "      <td>13.30 ± 2.87</td>\n",
       "      <td>-0.05 ± 0.05</td>\n",
       "      <td>15.40 ± 2.27</td>\n",
       "      <td>-0.89 ± 0.41</td>\n",
       "      <td>16.70 ± 1.70</td>\n",
       "      <td>-1.73 ± 0.82</td>\n",
       "      <td>18.50 ± 1.27</td>\n",
       "      <td>-2.54 ± 1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.63 ± 0.98</td>\n",
       "      <td>12.00 ± 1.94</td>\n",
       "      <td>0.06 ± 0.04</td>\n",
       "      <td>14.20 ± 1.14</td>\n",
       "      <td>0.97 ± 0.26</td>\n",
       "      <td>16.50 ± 1.51</td>\n",
       "      <td>1.87 ± 0.47</td>\n",
       "      <td>18.60 ± 1.43</td>\n",
       "      <td>2.78 ± 0.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class   Pred Margin Exp Len Inicial   MCT Inicial    Exp Len 25  \\\n",
       "0      0  -3.31 ± 1.62    13.30 ± 2.87  -0.05 ± 0.05  15.40 ± 2.27   \n",
       "1      1   3.63 ± 0.98    12.00 ± 1.94   0.06 ± 0.04  14.20 ± 1.14   \n",
       "\n",
       "         MCT 25    Exp Len 50        MCT 50    Exp Len 75        MCT 75  \n",
       "0  -0.89 ± 0.41  16.70 ± 1.70  -1.73 ± 0.82  18.50 ± 1.27  -2.54 ± 1.20  \n",
       "1   0.97 ± 0.26  16.50 ± 1.51   1.87 ± 0.47  18.60 ± 1.43   2.78 ± 0.72  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sonar = get_explain_results_n(\"spambase\", instances_to_explain)\n",
    "df_summary_sonar = summarize_explanations(df_sonar)\n",
    "df_summary_sonar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb00bbc",
   "metadata": {},
   "source": [
    "# Margin - Anchor - Lime - Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79ba12e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples_from_explanation(X, explanation, base_sample, n_samples=100):\n",
    "    feature_names = [str(cond.arg(0)) for cond in explanation]\n",
    "    explained_features = set(feature_names)\n",
    "\n",
    "    # Gera amostras aleatórias\n",
    "    synthetic_samples = X.sample(n=n_samples, replace=True).reset_index(drop=True)\n",
    "\n",
    "    # Substitui valores das features explicadas pelos valores da base_sample\n",
    "    for feature in explained_features:\n",
    "        synthetic_samples[feature] = base_sample[feature]\n",
    "\n",
    "    return synthetic_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8e909d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_margin_similar_samples(dataset_name, explainer_name, n_per_class=5, n_synthetic=100):\n",
    "    model, X, y, X_test, y_test, explainer = dataset_context[dataset_name]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for target_class in [0, 1]:\n",
    "        count = 0\n",
    "        for i in range(len(X_test)):\n",
    "            if count >= n_per_class:\n",
    "                break\n",
    "\n",
    "            sample = X_test.iloc[i]\n",
    "            pred = model.predict([sample])[0]\n",
    "            if pred != target_class:\n",
    "                continue\n",
    "\n",
    "            if explainer_name == \"anchor\":\n",
    "                #anchor exp\n",
    "                pass\n",
    "            elif explainer_name == \"lime\":\n",
    "                # lime exp\n",
    "                pass\n",
    "            elif explainer_name == \"explainer\":\n",
    "                explanation = explainer.explain(sample, reorder=\"asc\")\n",
    "            elif explainer_name == \"explainer_prob\":\n",
    "                margin = model.predict([sample], output_margin=True)[0]\n",
    "                explanation = explainer.explain_prob(sample, reorder=\"asc\", target_threshold=margin / 2)\n",
    "\n",
    "            synthetic_df = generate_samples_from_explanation(X, explanation, sample, n_samples=n_synthetic)\n",
    "            margins = model.predict(synthetic_df, output_margin=True)\n",
    "\n",
    "            results.append({\n",
    "                \"original_class\": target_class,\n",
    "                \"mean_margin\": np.mean(margins),\n",
    "                \"min_margin\": np.min(margins),\n",
    "                \"max_margin\": np.max(margins),\n",
    "                \"explainer\": explainer_name,\n",
    "            })\n",
    "\n",
    "            count += 1\n",
    "    \n",
    "    results = pd.DataFrame(results)\n",
    "\n",
    "    summary = results.groupby(\"original_class\").agg({\n",
    "        \"mean_margin\": \"mean\",\n",
    "        \"min_margin\": \"mean\",  # média dos mínimos\n",
    "        \"max_margin\": \"mean\"   # média dos máximos\n",
    "    }).reset_index()\n",
    "\n",
    "    summary.columns = [\"class\", \"avg_mean_margin\", \"avg_min_margin\", \"avg_max_margin\"]\n",
    "\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3024af8",
   "metadata": {},
   "source": [
    "## magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "da4d8b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results = check_margin_similar_samples(\"magic\", \"anchor\")\n",
    "# df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b5608d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results = check_margin_similar_samples(\"magic\", \"lime\")\n",
    "# df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "73b5b42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>avg_mean_margin</th>\n",
       "      <th>avg_min_margin</th>\n",
       "      <th>avg_max_margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.285163</td>\n",
       "      <td>-3.097516</td>\n",
       "      <td>-0.991033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.111000</td>\n",
       "      <td>0.317251</td>\n",
       "      <td>5.645457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  avg_mean_margin  avg_min_margin  avg_max_margin\n",
       "0      0        -2.285163       -3.097516       -0.991033\n",
       "1      1         2.111000        0.317251        5.645457"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = check_margin_similar_samples(\"magic\", \"explainer\")\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "045b6cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>avg_mean_margin</th>\n",
       "      <th>avg_min_margin</th>\n",
       "      <th>avg_max_margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.347820</td>\n",
       "      <td>-2.748309</td>\n",
       "      <td>-1.438401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.084973</td>\n",
       "      <td>1.469171</td>\n",
       "      <td>5.575043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  avg_mean_margin  avg_min_margin  avg_max_margin\n",
       "0      0        -2.347820       -2.748309       -1.438401\n",
       "1      1         3.084973        1.469171        5.575043"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = check_margin_similar_samples(\"magic\", \"explainer_prob\")\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee349a61",
   "metadata": {},
   "source": [
    "## adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9f09cde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results = check_margin_similar_samples(\"adult\", \"anchor\")\n",
    "# df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "61a39fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results = check_margin_similar_samples(\"adult\", \"lime\")\n",
    "# df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a2cbdce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>avg_mean_margin</th>\n",
       "      <th>avg_min_margin</th>\n",
       "      <th>avg_max_margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.30076</td>\n",
       "      <td>-1.810563</td>\n",
       "      <td>-0.752324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.71532</td>\n",
       "      <td>0.448645</td>\n",
       "      <td>5.117767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  avg_mean_margin  avg_min_margin  avg_max_margin\n",
       "0      0         -1.30076       -1.810563       -0.752324\n",
       "1      1          2.71532        0.448645        5.117767"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = check_margin_similar_samples(\"adult\", \"explainer\")\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "179e0445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>avg_mean_margin</th>\n",
       "      <th>avg_min_margin</th>\n",
       "      <th>avg_max_margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.386895</td>\n",
       "      <td>-1.744472</td>\n",
       "      <td>-0.983192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.710778</td>\n",
       "      <td>1.266646</td>\n",
       "      <td>4.813052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  avg_mean_margin  avg_min_margin  avg_max_margin\n",
       "0      0        -1.386895       -1.744472       -0.983192\n",
       "1      1         2.710778        1.266646        4.813052"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = check_margin_similar_samples(\"adult\", \"explainer_prob\")\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85e0faa",
   "metadata": {},
   "source": [
    "## mushroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "47f0d62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results = check_margin_similar_samples(\"mushroom\", \"anchor\")\n",
    "# df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a795eb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results = check_margin_similar_samples(\"mushroom\", \"lime\")\n",
    "# df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a13a8086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>avg_mean_margin</th>\n",
       "      <th>avg_min_margin</th>\n",
       "      <th>avg_max_margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-6.253671</td>\n",
       "      <td>-7.884968</td>\n",
       "      <td>-4.884665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.768359</td>\n",
       "      <td>2.512560</td>\n",
       "      <td>7.677604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  avg_mean_margin  avg_min_margin  avg_max_margin\n",
       "0      0        -6.253671       -7.884968       -4.884665\n",
       "1      1         5.768359        2.512560        7.677604"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = check_margin_similar_samples(\"mushroom\", \"explainer\")\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5c9c4c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>avg_mean_margin</th>\n",
       "      <th>avg_min_margin</th>\n",
       "      <th>avg_max_margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-6.284242</td>\n",
       "      <td>-7.838942</td>\n",
       "      <td>-4.838922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6.375678</td>\n",
       "      <td>4.408938</td>\n",
       "      <td>7.594402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  avg_mean_margin  avg_min_margin  avg_max_margin\n",
       "0      0        -6.284242       -7.838942       -4.838922\n",
       "1      1         6.375678        4.408938        7.594402"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = check_margin_similar_samples(\"mushroom\", \"explainer_prob\")\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbca5d4c",
   "metadata": {},
   "source": [
    "## spambase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cd76ff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results = check_margin_similar_samples(\"spambase\", \"anchor\")\n",
    "# df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ab5dc055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results = check_margin_similar_samples(\"spambase\", \"lime\")\n",
    "# df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "14a83779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>avg_mean_margin</th>\n",
       "      <th>avg_min_margin</th>\n",
       "      <th>avg_max_margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-3.900222</td>\n",
       "      <td>-7.022644</td>\n",
       "      <td>-1.254080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.771840</td>\n",
       "      <td>2.247439</td>\n",
       "      <td>5.551502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  avg_mean_margin  avg_min_margin  avg_max_margin\n",
       "0      0        -3.900222       -7.022644       -1.254080\n",
       "1      1         3.771840        2.247439        5.551502"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = check_margin_similar_samples(\"spambase\", \"explainer\")\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "29e59de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>avg_mean_margin</th>\n",
       "      <th>avg_min_margin</th>\n",
       "      <th>avg_max_margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-4.635751</td>\n",
       "      <td>-7.269703</td>\n",
       "      <td>-3.002661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.056298</td>\n",
       "      <td>2.830221</td>\n",
       "      <td>5.517482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  avg_mean_margin  avg_min_margin  avg_max_margin\n",
       "0      0        -4.635751       -7.269703       -3.002661\n",
       "1      1         4.056298        2.830221        5.517482"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = check_margin_similar_samples(\"spambase\", \"explainer_prob\")\n",
    "df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
