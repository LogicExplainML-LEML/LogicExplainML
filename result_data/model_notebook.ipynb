{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "394f70f1",
   "metadata": {},
   "source": [
    "# Imports + class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "231f4500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from z3 import *\n",
    "from xgboost import XGBClassifier\n",
    "from pmlb import fetch_data\n",
    "set_option(rational_to_decimal=True)\n",
    "\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "from model import XGBoostExplainer, generate_results\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c38991a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XGBoostExplainer:\n",
    "    def __init__(self, model, data):\n",
    "        self.model = model\n",
    "        self.data = data.values\n",
    "        self.columns = data.columns\n",
    "        self.max_categories = 2\n",
    "\n",
    "        set_option(rational_to_decimal=True)\n",
    "        self.categoric_features = self.get_categoric_features(self.data)\n",
    "        self.T_model = self.model_trees_expression(self.model)\n",
    "        self.T = self.T_model\n",
    "\n",
    "    def explain(self, instance, reorder=\"asc\"):\n",
    "        self.I = self.instance_expression(instance)\n",
    "        self.D, self.D_add = self.decision_function_expression(self.model, [instance])\n",
    "        return self.explain_expression(self.I, And(self.T, self.D_add), self.D, self.model, reorder)\n",
    "\n",
    "    def explain_prob(self, instance, reorder=\"asc\", threshold_margin=0, target_threshold=None):\n",
    "        self.I = self.instance_expression(instance)\n",
    "        self.D, self.D_add = self.decision_function_expression(self.model, [instance])\n",
    "        return self.explain_expression_prob(self.I, And(self.T, self.D_add), self.D, self.model, reorder, threshold_margin, target_threshold)\n",
    "\n",
    "    def get_categoric_features(self, data: np.ndarray):\n",
    "        categoric_features = []\n",
    "        for i in range(data.shape[1]):\n",
    "            feature_values = data[:, i]\n",
    "            unique_values = np.unique(feature_values)\n",
    "            if len(unique_values) <= self.max_categories:\n",
    "                categoric_features.append(self.columns[i])\n",
    "\n",
    "        return categoric_features\n",
    "\n",
    "    def feature_constraints(self, constraints=[]):\n",
    "        \"\"\"TODO\n",
    "        esperado receber limites das features pelo usuário\n",
    "        formato previso: matriz/dataframe [feaature, min/max, valor]\n",
    "        constraaint_expression = \"constraaint_df_to_feature()\"\n",
    "        \"\"\"\n",
    "        return\n",
    "\n",
    "    def model_trees_expression(self, model):\n",
    "        df = model.get_booster().trees_to_dataframe()\n",
    "        if model.get_booster().feature_names == None:\n",
    "            feature_map = {f\"f{i}\": col for i, col in enumerate(self.columns)}\n",
    "            df[\"Feature\"] = df[\"Feature\"].replace(feature_map)\n",
    "\n",
    "        df[\"Split\"] = df[\"Split\"].round(4)\n",
    "        self.booster_df = df\n",
    "        class_index = 0  # if model.n_classes_ == 2:\n",
    "        all_tree_formulas = []\n",
    "\n",
    "        for tree_index in df[\"Tree\"].unique():\n",
    "            tree_df = df[df[\"Tree\"] == tree_index]\n",
    "            o = Real(f\"o_{tree_index}_{class_index}\")\n",
    "\n",
    "            if len(tree_df) == 1 and tree_df.iloc[0][\"Feature\"] == \"Leaf\":\n",
    "                leaf_value = tree_df.iloc[0][\"Gain\"]\n",
    "                all_tree_formulas.append(And(o == leaf_value))\n",
    "                continue\n",
    "            path_formulas = []\n",
    "\n",
    "            def get_conditions(node_id):\n",
    "                conditions = []\n",
    "                current_node = tree_df[tree_df[\"ID\"] == node_id]\n",
    "                if current_node.empty:\n",
    "                    return conditions\n",
    "\n",
    "                parent_node = tree_df[\n",
    "                    (tree_df[\"Yes\"] == node_id) | (tree_df[\"No\"] == node_id)\n",
    "                ]\n",
    "                if not parent_node.empty:\n",
    "                    parent_data = parent_node.iloc[0]\n",
    "                    feature = parent_data[\"Feature\"]\n",
    "                    split_value = parent_data[\"Split\"]\n",
    "                    x = Real(feature)\n",
    "                    if parent_data[\"Yes\"] == node_id:\n",
    "                        conditions.append(x < split_value)\n",
    "                    else:\n",
    "                        conditions.append(x >= split_value)\n",
    "                    conditions = get_conditions(parent_data[\"ID\"]) + conditions\n",
    "\n",
    "                return conditions\n",
    "\n",
    "            for _, node in tree_df[tree_df[\"Feature\"] == \"Leaf\"].iterrows():\n",
    "                leaf_value = node[\"Gain\"]\n",
    "                leaf_id = node[\"ID\"]\n",
    "                conditions = get_conditions(leaf_id)\n",
    "                path_formula = And(*conditions)\n",
    "                implication = Implies(path_formula, o == leaf_value)\n",
    "                path_formulas.append(implication)\n",
    "\n",
    "            all_tree_formulas.append(And(*path_formulas))\n",
    "        return And(*all_tree_formulas)\n",
    "\n",
    "    def get_init_value(self, model, x, estimator_variables):\n",
    "        estimator_pred = Solver()\n",
    "        estimator_pred.add(self.I)\n",
    "        estimator_pred.add(self.T)\n",
    "        if estimator_pred.check() == sat:\n",
    "            solvermodel = estimator_pred.model()\n",
    "            total_sum = sum(\n",
    "                float(solvermodel.eval(var).as_fraction()) for var in estimator_variables\n",
    "            )\n",
    "        else:\n",
    "            total_sum = 0\n",
    "            print(\"estimator error\")\n",
    "        self.predicted_margin = model.predict(x, output_margin=True)[0]\n",
    "        init_value = self.predicted_margin - total_sum\n",
    "        self.init_value = init_value\n",
    "        return init_value\n",
    "\n",
    "    def decision_function_expression(self, model, x):\n",
    "        n_classes = 1 if model.n_classes_ <= 2 else model.n_classes_\n",
    "        predicted_class = model.predict(x)[0]\n",
    "        self.predicted_class = predicted_class\n",
    "        n_estimators = int(len(model.get_booster().get_dump()) / n_classes)\n",
    "        estimator_variables = [Real(f\"o_{i}_0\") for i in range(n_estimators)] # _0 only for binary classification\n",
    "        self.estimator_variables = estimator_variables\n",
    "        init_value = self.get_init_value(model, x, estimator_variables)\n",
    "        # print(\"init:\", round(init_value, 2))\n",
    "\n",
    "        equation_list = []\n",
    "\n",
    "        estimator_sum = Real(\"estimator_sum\")\n",
    "        equation_o = estimator_sum == Sum(estimator_variables)\n",
    "        equation_list.append(equation_o)\n",
    "\n",
    "        decision = Real(\"decision\")\n",
    "        equation_list.append(decision == estimator_sum + init_value)\n",
    "\n",
    "        if predicted_class == 0:\n",
    "            final_equation = decision < 0\n",
    "        else:\n",
    "            final_equation = decision > 0\n",
    "\n",
    "        return final_equation, And(equation_list)\n",
    "\n",
    "    def instance_expression(self, instance):\n",
    "        formula = [Real(self.columns[i]) == value for i, value in enumerate(instance)]\n",
    "        return formula\n",
    "\n",
    "    def explain_expression(self, I, T_s, D_s, model, reorder):\n",
    "        i_expression = I.copy()\n",
    "\n",
    "        importances = model.feature_importances_\n",
    "        non_zero_indices = np.where(importances != 0)[0]\n",
    "\n",
    "        if reorder == \"asc\":\n",
    "            sorted_feature_indices = non_zero_indices[\n",
    "                np.argsort(importances[non_zero_indices])\n",
    "            ]\n",
    "            i_expression = [i_expression[i] for i in sorted_feature_indices]\n",
    "        elif reorder == \"desc\":\n",
    "            sorted_feature_indices = non_zero_indices[\n",
    "                np.argsort(-importances[non_zero_indices])\n",
    "            ]\n",
    "            i_expression = [i_expression[i] for i in sorted_feature_indices]\n",
    "\n",
    "        for feature in i_expression.copy():\n",
    "            # print(\"\\n---removed\", feature)\n",
    "            i_expression.remove(feature)\n",
    "\n",
    "            # prove(Implies(And(And(i_expression), T), D))\n",
    "            if self.is_proved(Implies(And(And(i_expression), T_s), D_s)):\n",
    "                continue\n",
    "                # print('proved')\n",
    "            else:\n",
    "                # print('not proved')\n",
    "                i_expression.append(feature)\n",
    "        # print(self.is_proved(Implies(And(And(i_expression), T_s), D_s)))\n",
    "        return i_expression\n",
    "\n",
    "    def explain_expression_prob(self, I, T_s, D_s, model, reorder, threshold_margin, target_threshold):\n",
    "        i_expression = I.copy()\n",
    "\n",
    "        importances = model.feature_importances_\n",
    "        non_zero_indices = np.where(importances != 0)[0]\n",
    "\n",
    "        if reorder == \"asc\":\n",
    "            sorted_feature_indices = non_zero_indices[\n",
    "                np.argsort(importances[non_zero_indices])\n",
    "            ]\n",
    "            i_expression = [i_expression[i] for i in sorted_feature_indices]\n",
    "        elif reorder == \"desc\":\n",
    "            sorted_feature_indices = non_zero_indices[\n",
    "                np.argsort(-importances[non_zero_indices])\n",
    "            ]\n",
    "            i_expression = [i_expression[i] for i in sorted_feature_indices]\n",
    "\n",
    "        threshold = 0\n",
    "\n",
    "        if target_threshold:\n",
    "            threshold = target_threshold\n",
    "        elif threshold_margin != 0:\n",
    "            threshold = self.predicted_margin * threshold_margin/100\n",
    "            # print(\"margin:\", self.predicted_margin, \"accepted margin:\", threshold)\n",
    "        self.xai_predicted_margin = self.predicted_margin\n",
    "\n",
    "        for feature in i_expression.copy():\n",
    "            # print(\"\\n---removed\", feature)\n",
    "            i_expression.remove(feature)\n",
    "\n",
    "            if self.is_proved_sat(And(And(i_expression), T_s), threshold):\n",
    "                # print('proved')\n",
    "                continue\n",
    "            else:\n",
    "                # print('not proved -- added back')\n",
    "                i_expression.append(feature)\n",
    "        return i_expression\n",
    "\n",
    "\n",
    "    def is_proved(self, decision_exp):\n",
    "        s = Solver()\n",
    "        s.add(Not(decision_exp))\n",
    "        if s.check() == unsat:\n",
    "            return True\n",
    "        else:\n",
    "            # print(s.model())\n",
    "            return False\n",
    "\n",
    "    def is_proved_sat(self, decision_exp, threshold):\n",
    "      decision = Real(\"decision\")\n",
    "\n",
    "      debug = Real(\"debug\") == 0\n",
    "      predicted_class = self.predicted_class\n",
    "\n",
    "      if predicted_class == 0:\n",
    "        estmax = Optimize()\n",
    "        estmax.add(decision_exp)\n",
    "        estmax.add(debug)\n",
    "        maxvalue = estmax.maximize(decision)\n",
    "        if estmax.check() == sat:\n",
    "            # print(\"\\nmax sat\", maxvalue.value())\n",
    "            try:\n",
    "              if float(maxvalue.value().as_fraction()) > threshold:\n",
    "                  return False # can change class\n",
    "              else:\n",
    "                  self.xai_predicted_margin = float(maxvalue.value().as_fraction())\n",
    "            except:\n",
    "              print(\"error max =\", maxvalue.value())\n",
    "              return False\n",
    "        else:\n",
    "            print(\"error\")\n",
    "\n",
    "      if predicted_class == 1:\n",
    "        estmin = Optimize()\n",
    "        estmin.add(decision_exp)\n",
    "        estmin.add(debug)\n",
    "        minvalue = estmin.minimize(decision)\n",
    "        if estmin.check() == sat:\n",
    "            # print(\"\\nmin sat\", minvalue.value())\n",
    "            try:\n",
    "              if float(minvalue.value().as_fraction()) < threshold:\n",
    "                  return False # can change class\n",
    "              else:\n",
    "                  self.xai_predicted_margin = float(minvalue.value().as_fraction())\n",
    "            except:\n",
    "              print(\"error min =\", minvalue.value())\n",
    "              return False\n",
    "        else:\n",
    "            print(\"error\")\n",
    "\n",
    "      if predicted_class == 0:\n",
    "        self.solvermodel = estmax.model()\n",
    "      if predicted_class == 1:\n",
    "        self.solvermodel = estmin.model()\n",
    "      return True\n",
    "  \n",
    "def generate_results(explainer, X_test, y_pred, classification, path, reorder=\"asc\"):\n",
    "    results = []\n",
    "    if classification == 0:\n",
    "        increase_prob = -0.01\n",
    "    else:\n",
    "        increase_prob = 0.01\n",
    "    for i in X_test[y_pred == classification].index:\n",
    "        sample = X_test.loc[i].values\n",
    "        xai = explainer.explain_prob(sample, reorder=reorder)\n",
    "        xaiprob_initial = explainer.xai_predicted_margin\n",
    "        len_xai_initial = len(xai)\n",
    "\n",
    "        xai = explainer.explain_prob(sample, reorder=reorder, target_threshold=xaiprob_initial + increase_prob)\n",
    "        xaiprob_final = explainer.xai_predicted_margin\n",
    "        len_xai_final = len(xai)\n",
    "\n",
    "        if round(xaiprob_initial, 2) == round(xaiprob_final, 2):\n",
    "            len_xai_initial = len_xai_final\n",
    "        results.append({\n",
    "            \"index\": i,\n",
    "            \"class\": classification,\n",
    "            \"xaiprob_initial\": round(xaiprob_initial, 2),\n",
    "            \"len_xai_initial\": len_xai_initial,\n",
    "            \"xaiprob_final\": round(xaiprob_final, 2),\n",
    "            \"len_xai_final\": len_xai_final\n",
    "        })\n",
    "    df_results = pd.DataFrame(results)\n",
    "    return df_results\n",
    "    # df_results.to_csv(f'{path}/results_{classification}_{reorder}.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fc67b6",
   "metadata": {},
   "source": [
    "# Prepare datasets and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "877534ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset_model_explainer(dataset_name, dataset_params):\n",
    "    # Fetch data\n",
    "    dataset = fetch_data(dataset_name)\n",
    "    X = dataset.drop('target', axis=1)\n",
    "    y = dataset['target']\n",
    "\n",
    "    params = dataset_params[dataset_name]\n",
    "\n",
    "    # Train model\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    # Metrics\n",
    "    print(\"Dataset size:\", len(X))\n",
    "    print(\"Columns:\", len(X.columns))\n",
    "    # print(\"Accuracy:\", accuracy_score(y, y_pred))\n",
    "    # print(\"Precision:\", precision_score(y, y_pred))\n",
    "    # print(\"Recall:\", recall_score(y, y_pred))\n",
    "    print(\"F1-score:\", f1_score(y, y_pred))\n",
    "\n",
    "    # Explainer\n",
    "    explainer = XGBoostExplainer(model, X)\n",
    "\n",
    "    return model, X, y, explainer\n",
    "\n",
    "def prepare_all_datasets(dataset_names, dataset_params):\n",
    "    context = {}\n",
    "    for name in dataset_names:\n",
    "        print(f\"\\n--- Preparing {name} ---\")\n",
    "        model, X, y, explainer = prepare_dataset_model_explainer(name, dataset_params)\n",
    "        context[name] = (model, X, y, explainer)\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f96f764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Preparing saheart ---\n",
      "Dataset size: 462\n",
      "Columns: 9\n",
      "F1-score: 0.9144736842105263\n",
      "\n",
      "--- Preparing adult ---\n",
      "Dataset size: 48842\n",
      "Columns: 14\n",
      "F1-score: 0.9156271028521145\n",
      "\n",
      "--- Preparing mushroom ---\n",
      "Dataset size: 8124\n",
      "Columns: 22\n",
      "F1-score: 1.0\n",
      "\n",
      "--- Preparing sonar ---\n",
      "Dataset size: 208\n",
      "Columns: 60\n",
      "F1-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "dataset_names = [\"saheart\", \"adult\", \"mushroom\", \"sonar\"]\n",
    "\n",
    "dataset_params = {\n",
    "    \"saheart\": {\"n_estimators\": 50, \"max_depth\": 3},\n",
    "    \"adult\": {\"n_estimators\": 30, \"max_depth\": 3},\n",
    "    \"mushroom\": {\"n_estimators\": 30, \"max_depth\": 3},\n",
    "    \"sonar\": {\"n_estimators\": 30, \"max_depth\": 3},\n",
    "}\n",
    "\n",
    "dataset_context = prepare_all_datasets(dataset_names, dataset_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbeaf39",
   "metadata": {},
   "source": [
    "# Check explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b55a38d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_explain_results(dataset_name):\n",
    "    model, X, y, explainer = dataset_context[dataset_name]\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    # Function to explain a sample of a given class\n",
    "    def explain_for_class(classification):\n",
    "        # Get a sample of the specified class in predictions\n",
    "        indices = X[y_pred == classification].index\n",
    "        if len(indices) == 0:\n",
    "            print(f\"No samples predicted as class {classification}.\")\n",
    "            return\n",
    "        i = indices[0]\n",
    "        sample = X.loc[i].values\n",
    "\n",
    "        # Initial explanation\n",
    "        margin = model.predict([sample], output_margin=True)[0]\n",
    "        print(f\"\\nClass {classification} - Margin: {margin}, Sample index: {i}\")\n",
    "\n",
    "        xai = explainer.explain_prob(sample)\n",
    "        print(\"Initial abductive explanation:\", xai)\n",
    "        \n",
    "        xaiprob_initial = explainer.xai_predicted_margin\n",
    "        print(\"Initial predicted margin:\", xaiprob_initial)\n",
    "\n",
    "        # Adjust margin direction\n",
    "        # increase_prob = -0.01 if classification == 0 else 0.01\n",
    "\n",
    "        # Explanation with adjusted threshold\n",
    "        xai_confidence = explainer.explain_prob(sample, target_threshold= margin / 2)\n",
    "        xaiprob_final = explainer.xai_predicted_margin\n",
    "        print(\"Confidence-aware abductive explanation:\", xai_confidence)\n",
    "        print(\"Final predicted margin:\", xaiprob_final)\n",
    "\n",
    "    # Explain for both classes\n",
    "    explain_for_class(0)\n",
    "    explain_for_class(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27c75f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class 0 - Margin: -6.846377849578857, Sample index: 0\n",
      "Initial abductive explanation: [odor == 6, gill-size == 0, spore-print-color == 1]\n",
      "Initial predicted margin: -3.9321851558\n",
      "Confidence-aware abductive explanation: [odor == 6, gill-size == 0, spore-print-color == 1]\n",
      "Final predicted margin: -3.9321851558\n",
      "\n",
      "Class 1 - Margin: 7.956404685974121, Sample index: 3\n",
      "Initial abductive explanation: [odor == 4, veil-color == 2, spore-print-color == 3]\n",
      "Initial predicted margin: 1.6946676614\n",
      "Confidence-aware abductive explanation: [odor == 4, gill-spacing == 0, gill-size == 0, veil-color == 2, spore-print-color == 3]\n",
      "Final predicted margin: 5.4277561085\n"
     ]
    }
   ],
   "source": [
    "get_explain_results(\"mushroom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9864ddbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class 0 - Margin: -0.020596586167812347, Sample index: 4\n",
      "Initial abductive explanation: [fnlwgt == 338409, sex == 0, workclass == 4, capital-loss == 0, occupation == 10, age == 28, hours-per-week == 40, capital-gain == 0, marital-status == 2, education-num == 13, relationship == 5]\n",
      "Initial predicted margin: -0.02059663832\n",
      "Confidence-aware abductive explanation: [fnlwgt == 338409, sex == 0, workclass == 4, capital-loss == 0, occupation == 10, age == 28, hours-per-week == 40, capital-gain == 0, marital-status == 2, education-num == 13, relationship == 5]\n",
      "Final predicted margin: -0.02059663832\n",
      "\n",
      "Class 1 - Margin: 2.4348256587982178, Sample index: 0\n",
      "Initial abductive explanation: [capital-loss == 0, capital-gain == 2174, education-num == 13, relationship == 1]\n",
      "Initial predicted margin: 0.14839767258\n",
      "Confidence-aware abductive explanation: [capital-loss == 0, hours-per-week == 40, capital-gain == 2174, marital-status == 4, education-num == 13, relationship == 1]\n",
      "Final predicted margin: 1.31344249368\n"
     ]
    }
   ],
   "source": [
    "get_explain_results(\"adult\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ba516fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class 0 - Margin: -5.826420783996582, Sample index: 0\n",
      "Initial abductive explanation: [A51 == 0.013, A31 == 0.3934, A37 == 0.0702, A52 == 0.012, A48 == 0.1037, A45 == 0.1814, A20 == 0.6936, A12 == 0.3553, A34 == 0.114, A16 == 0.2794, A11 == 0.3188]\n",
      "Initial predicted margin: -0.05964847832\n",
      "Confidence-aware abductive explanation: [A36 == 0.008, A23 == 0.8203, A9 == 0.1865, A17 == 0.287, A51 == 0.013, A42 == 0.102, A31 == 0.3934, A37 == 0.0702, A52 == 0.012, A15 == 0.178, A48 == 0.1037, A45 == 0.1814, A20 == 0.6936, A12 == 0.3553, A47 == 0.1688, A34 == 0.114, A16 == 0.2794, A11 == 0.3188]\n",
      "Final predicted margin: -3.00395026691\n",
      "\n",
      "Class 1 - Margin: 5.359158992767334, Sample index: 12\n",
      "Initial abductive explanation: [A23 == 0.2605, A44 == 0.0942, A48 == 0.0469, A45 == 0.084, A12 == 0.1102, A21 == 0.2005, A47 == 0.0342, A5 == 0.0357, A4 == 0.0139, A11 == 0.1203]\n",
      "Initial predicted margin: 0.08716987994\n",
      "Confidence-aware abductive explanation: [A28 == 0.6742, A10 == 0.0973, A54 == 0.0052, A27 == 0.8684, A36 == 0.2344, A23 == 0.2605, A29 == 0.5537, A44 == 0.0942, A48 == 0.0469, A45 == 0.084, A12 == 0.1102, A21 == 0.2005, A47 == 0.0342, A5 == 0.0357, A4 == 0.0139, A11 == 0.1203]\n",
      "Final predicted margin: 2.77448168974\n"
     ]
    }
   ],
   "source": [
    "get_explain_results(\"sonar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96d90cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class 0 - Margin: -0.2692931890487671, Sample index: 1\n",
      "Initial abductive explanation: [Sbp == 144, Obesity == 28.87, Adiposity == 28.61, Ldl == 4.41, Typea == 55, Tobacco == 0.01, Famhist == 0]\n",
      "Initial predicted margin: -0.1002989025\n",
      "Confidence-aware abductive explanation: [Sbp == 144, Obesity == 28.87, Alcohol == 2.06, Adiposity == 28.61, Ldl == 4.41, Typea == 55, Tobacco == 0.01, Famhist == 0]\n",
      "Final predicted margin: -0.26929319084\n",
      "\n",
      "Class 1 - Margin: 1.7746528387069702, Sample index: 0\n",
      "Initial abductive explanation: [Alcohol == 97.2, Ldl == 5.73, Tobacco == 12, Famhist == 1, Age == 52]\n",
      "Initial predicted margin: 0.12975603705\n",
      "Confidence-aware abductive explanation: [Obesity == 25.3, Alcohol == 97.2, Ldl == 5.73, Tobacco == 12, Famhist == 1, Age == 52]\n",
      "Final predicted margin: 1.07581014872\n"
     ]
    }
   ],
   "source": [
    "get_explain_results(\"saheart\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78aaf623",
   "metadata": {},
   "source": [
    "# Check threshold datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef001579",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a20aca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_explain_results_n(dataset_name, n_samples):\n",
    "    model, X, y, explainer = dataset_context[dataset_name]\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    # Prepare result DataFrame\n",
    "    results = []\n",
    "\n",
    "    # Loop over both classes\n",
    "    for classification in [0, 1]:\n",
    "        # Get indices for predicted samples of this class\n",
    "        indices = X[y_pred == classification].index[:n_samples]\n",
    "        if len(indices) == 0:\n",
    "            print(f\"No samples predicted as class {classification}.\")\n",
    "            continue\n",
    "\n",
    "        for idx in indices:\n",
    "            sample = X.loc[idx].values\n",
    "\n",
    "            # Initial explanation\n",
    "            margin = model.predict([sample], output_margin=True)[0]\n",
    "            xai_initial = explainer.explain_prob(sample)\n",
    "            xaiprob_initial = explainer.xai_predicted_margin\n",
    "            exp_len_initial = len(xai_initial)\n",
    "\n",
    "            # Explanation with adjusted threshold (half the margin)\n",
    "            xai_confidence_case1 = explainer.explain_prob(sample, target_threshold=margin / 2)\n",
    "            xaiprob_case1 = explainer.xai_predicted_margin\n",
    "            exp_len_case1 = len(xai_confidence_case1)\n",
    "            \n",
    "            increase_prob = -0.01 if margin < 0 else 0.01\n",
    "            xai_confidence_case2 = explainer.explain_prob(sample, target_threshold= xaiprob_initial + increase_prob)\n",
    "            xaiprob_case2 = explainer.xai_predicted_margin\n",
    "            exp_len_case2 = len(xai_confidence_case2)\n",
    "\n",
    "            # Append to results\n",
    "            results.append({\n",
    "                'sample_id': idx,\n",
    "                'class': classification,\n",
    "                'pred_margin': round(margin, 4),\n",
    "                'exp_len_inicial': exp_len_initial,\n",
    "                'xaiprob_inicial': round(xaiprob_initial, 4),\n",
    "                'exp_len_case1': exp_len_case1,\n",
    "                'xaiprob_case1': round(xaiprob_case1, 4),\n",
    "                'exp_len_case2': exp_len_case2,\n",
    "                'xaiprob_case2': round(xaiprob_case2, 4),\n",
    "            })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df_results = pd.DataFrame(results)\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "def summarize_explanations(df_results):\n",
    "    # Agrupar por classe e calcular as métricas\n",
    "    summary = df_results.groupby('class').agg(\n",
    "        pred_margin_mean=('pred_margin', 'mean'),\n",
    "        pred_margin_std=('pred_margin', 'std'),\n",
    "        exp_len_inicial_mean=('exp_len_inicial', 'mean'),\n",
    "        exp_len_inicial_std=('exp_len_inicial', 'std'),\n",
    "        xaiprob_inicial_mean=('xaiprob_inicial', 'mean'),\n",
    "        xaiprob_inicial_std=('xaiprob_inicial', 'std'),\n",
    "        exp_len_case1_mean=('exp_len_case1', 'mean'),\n",
    "        exp_len_case1_std=('exp_len_case1', 'std'),\n",
    "        xaiprob_case1_mean=('xaiprob_case1', 'mean'),\n",
    "        xaiprob_case1_std=('xaiprob_case1', 'std'),\n",
    "        exp_len_case2_mean=('exp_len_case2', 'mean'),\n",
    "        exp_len_case2_std=('exp_len_case2', 'std'),\n",
    "        xaiprob_case2_mean=('xaiprob_case2', 'mean'),\n",
    "        xaiprob_case2_std=('xaiprob_case2', 'std'),\n",
    "    ).reset_index()\n",
    "\n",
    "    # Função para combinar mean ± std com 2 casas decimais\n",
    "    def format_mean_std(mean, std):\n",
    "        return f\"{mean:.2f} ± {std:.2f}\"\n",
    "\n",
    "    # Aplicar a formatação em cada par de colunas\n",
    "    formatted = pd.DataFrame()\n",
    "    formatted['class'] = summary['class']\n",
    "    formatted['Pred Margin'] = summary.apply(lambda row: format_mean_std(row['pred_margin_mean'], row['pred_margin_std']), axis=1)\n",
    "    formatted['Exp Len Inicial'] = summary.apply(lambda row: format_mean_std(row['exp_len_inicial_mean'], row['exp_len_inicial_std']), axis=1)\n",
    "    formatted['ECM Inicial'] = summary.apply(lambda row: format_mean_std(row['xaiprob_inicial_mean'], row['xaiprob_inicial_std']), axis=1)\n",
    "    formatted['Exp Len case1'] = summary.apply(lambda row: format_mean_std(row['exp_len_case1_mean'], row['exp_len_case1_std']), axis=1)\n",
    "    formatted['ECM case1'] = summary.apply(lambda row: format_mean_std(row['xaiprob_case1_mean'], row['xaiprob_case1_std']), axis=1)\n",
    "    formatted['Exp Len case2'] = summary.apply(lambda row: format_mean_std(row['exp_len_case2_mean'], row['exp_len_case2_std']), axis=1)\n",
    "    formatted['ECM case2'] = summary.apply(lambda row: format_mean_std(row['xaiprob_case2_mean'], row['xaiprob_case2_std']), axis=1)\n",
    "\n",
    "    return formatted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b911b5",
   "metadata": {},
   "source": [
    "# datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5847dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>Pred Margin</th>\n",
       "      <th>Exp Len Inicial</th>\n",
       "      <th>ECM Inicial</th>\n",
       "      <th>Exp Len case1</th>\n",
       "      <th>ECM case1</th>\n",
       "      <th>Exp Len case2</th>\n",
       "      <th>ECM case2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.04 ± 1.33</td>\n",
       "      <td>6.49 ± 0.93</td>\n",
       "      <td>-0.36 ± 0.31</td>\n",
       "      <td>7.21 ± 0.70</td>\n",
       "      <td>-1.31 ± 0.81</td>\n",
       "      <td>7.21 ± 0.96</td>\n",
       "      <td>-0.70 ± 0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.35 ± 0.95</td>\n",
       "      <td>6.30 ± 1.31</td>\n",
       "      <td>0.27 ± 0.24</td>\n",
       "      <td>7.10 ± 1.08</td>\n",
       "      <td>0.86 ± 0.56</td>\n",
       "      <td>6.93 ± 1.29</td>\n",
       "      <td>0.55 ± 0.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class   Pred Margin Exp Len Inicial   ECM Inicial Exp Len case1  \\\n",
       "0      0  -2.04 ± 1.33     6.49 ± 0.93  -0.36 ± 0.31   7.21 ± 0.70   \n",
       "1      1   1.35 ± 0.95     6.30 ± 1.31   0.27 ± 0.24   7.10 ± 1.08   \n",
       "\n",
       "      ECM case1 Exp Len case2     ECM case2  \n",
       "0  -1.31 ± 0.81   7.21 ± 0.96  -0.70 ± 0.48  \n",
       "1   0.86 ± 0.56   6.93 ± 1.29   0.55 ± 0.35  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_saheart = get_explain_results_n(\"saheart\", 100)\n",
    "df_summary_saheart = summarize_explanations(df_saheart)\n",
    "df_summary_saheart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5174dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>Pred Margin</th>\n",
       "      <th>Exp Len Inicial</th>\n",
       "      <th>ECM Inicial</th>\n",
       "      <th>Exp Len case1</th>\n",
       "      <th>ECM case1</th>\n",
       "      <th>Exp Len case2</th>\n",
       "      <th>ECM case2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.64 ± 1.60</td>\n",
       "      <td>7.39 ± 2.47</td>\n",
       "      <td>-0.18 ± 0.19</td>\n",
       "      <td>8.75 ± 2.29</td>\n",
       "      <td>-0.93 ± 0.86</td>\n",
       "      <td>7.99 ± 2.82</td>\n",
       "      <td>-0.39 ± 0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.52 ± 1.78</td>\n",
       "      <td>5.14 ± 1.41</td>\n",
       "      <td>0.31 ± 0.30</td>\n",
       "      <td>5.78 ± 1.14</td>\n",
       "      <td>1.48 ± 0.99</td>\n",
       "      <td>5.52 ± 1.85</td>\n",
       "      <td>0.63 ± 0.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class   Pred Margin Exp Len Inicial   ECM Inicial Exp Len case1  \\\n",
       "0      0  -1.64 ± 1.60     7.39 ± 2.47  -0.18 ± 0.19   8.75 ± 2.29   \n",
       "1      1   2.52 ± 1.78     5.14 ± 1.41   0.31 ± 0.30   5.78 ± 1.14   \n",
       "\n",
       "      ECM case1 Exp Len case2     ECM case2  \n",
       "0  -0.93 ± 0.86   7.99 ± 2.82  -0.39 ± 0.31  \n",
       "1   1.48 ± 0.99   5.52 ± 1.85   0.63 ± 0.47  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adult = get_explain_results_n(\"adult\", 100)\n",
    "df_summary_adult = summarize_explanations(df_adult)\n",
    "df_summary_adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46b7809f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>Pred Margin</th>\n",
       "      <th>Exp Len Inicial</th>\n",
       "      <th>ECM Inicial</th>\n",
       "      <th>Exp Len case1</th>\n",
       "      <th>ECM case1</th>\n",
       "      <th>Exp Len case2</th>\n",
       "      <th>ECM case2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-6.43 ± 1.15</td>\n",
       "      <td>2.89 ± 1.16</td>\n",
       "      <td>-2.66 ± 1.78</td>\n",
       "      <td>3.74 ± 1.76</td>\n",
       "      <td>-3.95 ± 1.01</td>\n",
       "      <td>3.88 ± 1.16</td>\n",
       "      <td>-3.13 ± 2.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.20 ± 1.10</td>\n",
       "      <td>3.58 ± 0.82</td>\n",
       "      <td>1.14 ± 0.61</td>\n",
       "      <td>5.77 ± 1.01</td>\n",
       "      <td>4.35 ± 0.96</td>\n",
       "      <td>4.57 ± 0.76</td>\n",
       "      <td>2.39 ± 1.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class   Pred Margin Exp Len Inicial   ECM Inicial Exp Len case1  \\\n",
       "0      0  -6.43 ± 1.15     2.89 ± 1.16  -2.66 ± 1.78   3.74 ± 1.76   \n",
       "1      1   7.20 ± 1.10     3.58 ± 0.82   1.14 ± 0.61   5.77 ± 1.01   \n",
       "\n",
       "      ECM case1 Exp Len case2     ECM case2  \n",
       "0  -3.95 ± 1.01   3.88 ± 1.16  -3.13 ± 2.06  \n",
       "1   4.35 ± 0.96   4.57 ± 0.76   2.39 ± 1.06  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mushroom = get_explain_results_n(\"mushroom\", 100)\n",
    "df_summary_mushroom = summarize_explanations(df_mushroom)\n",
    "df_summary_mushroom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ef3b035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>Pred Margin</th>\n",
       "      <th>Exp Len Inicial</th>\n",
       "      <th>ECM Inicial</th>\n",
       "      <th>Exp Len case1</th>\n",
       "      <th>ECM case1</th>\n",
       "      <th>Exp Len case2</th>\n",
       "      <th>ECM case2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-3.93 ± 1.11</td>\n",
       "      <td>13.28 ± 2.63</td>\n",
       "      <td>-0.08 ± 0.07</td>\n",
       "      <td>17.54 ± 2.81</td>\n",
       "      <td>-2.03 ± 0.57</td>\n",
       "      <td>13.28 ± 2.68</td>\n",
       "      <td>-0.21 ± 0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.79 ± 1.18</td>\n",
       "      <td>14.00 ± 2.16</td>\n",
       "      <td>0.07 ± 0.07</td>\n",
       "      <td>18.45 ± 1.69</td>\n",
       "      <td>1.95 ± 0.59</td>\n",
       "      <td>14.13 ± 2.07</td>\n",
       "      <td>0.16 ± 0.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class   Pred Margin Exp Len Inicial   ECM Inicial Exp Len case1  \\\n",
       "0      0  -3.93 ± 1.11    13.28 ± 2.63  -0.08 ± 0.07  17.54 ± 2.81   \n",
       "1      1   3.79 ± 1.18    14.00 ± 2.16   0.07 ± 0.07  18.45 ± 1.69   \n",
       "\n",
       "      ECM case1 Exp Len case2     ECM case2  \n",
       "0  -2.03 ± 0.57  13.28 ± 2.68  -0.21 ± 0.15  \n",
       "1   1.95 ± 0.59  14.13 ± 2.07   0.16 ± 0.11  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sonar = get_explain_results_n(\"sonar\", 100)\n",
    "df_summary_sonar = summarize_explanations(df_sonar)\n",
    "df_summary_sonar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be6cac7",
   "metadata": {},
   "source": [
    "# Test robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c27f6d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_robustness_results_n(dataset_name, n_samples, n_extra_samples, target_class=1,\n",
    "                              mult_margin=0, noise_level=0.5):\n",
    "    model, X, y, explainer = dataset_context[dataset_name]\n",
    "\n",
    "    # Armazena os resultados em lista\n",
    "    results = []\n",
    "\n",
    "    count = 0\n",
    "    for i in range(len(X)):\n",
    "        if count >= n_samples:\n",
    "            break\n",
    "\n",
    "        sample = X.iloc[i]\n",
    "        pred_class = model.predict([sample])[0]\n",
    "        if pred_class != target_class:\n",
    "            continue\n",
    "\n",
    "        margin = model.predict([sample], output_margin=True)[0]\n",
    "        explanation = explainer.explain_prob(sample, reorder=\"asc\", target_threshold=margin * mult_margin)\n",
    "\n",
    "        satisfying_df = generate_samples_for_conditions(X, explanation, n_samples=n_extra_samples, random_state=42)\n",
    "        noisy_df = apply_noise_to_samples(X, satisfying_df, noise_level=noise_level)\n",
    "        noisy_pred = model.predict(noisy_df)\n",
    "        noisy_pred_margin = model.predict(noisy_df, output_margin=True)\n",
    "\n",
    "        class_0 = np.sum(noisy_pred == 0)\n",
    "        class_1 = np.sum(noisy_pred == 1)\n",
    "\n",
    "        results.append({\n",
    "            \"amostra\": i,\n",
    "            \"classe_prevista\": int(pred_class),\n",
    "            \"classe_0_com_ruido\": int(class_0),\n",
    "            \"classe_1_com_ruido\": int(class_1),\n",
    "            # \"output_margin_medio\": float(np.mean(noisy_pred_margin)),\n",
    "            # \"output_margin_max\": float(np.max(noisy_pred_margin)),\n",
    "            # \"output_margin_min\": float(np.min(noisy_pred_margin))\n",
    "        })\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    # Converte para DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Cálculo de média ± desvio padrão para cada coluna\n",
    "    mean_0 = results_df[\"classe_0_com_ruido\"].mean()\n",
    "    std_0 = results_df[\"classe_0_com_ruido\"].std()\n",
    "\n",
    "    mean_1 = results_df[\"classe_1_com_ruido\"].mean()\n",
    "    std_1 = results_df[\"classe_1_com_ruido\"].std()\n",
    "\n",
    "    mean_results = pd.DataFrame([{\n",
    "        \"explanation class\": int(pred_class),\n",
    "        \"noise samples\": n_extra_samples,\n",
    "        \"noise level\": noise_level,\n",
    "        \"classified 0\": f\"{mean_0:.2f} ± {std_0:.2f}\",\n",
    "        \"classified 1\": f\"{mean_1:.2f} ± {std_1:.2f}\"\n",
    "    }])\n",
    "\n",
    "    return mean_results\n",
    "\n",
    "\n",
    "def generate_samples_for_conditions(df, conditions, n_samples=10, random_state=None):\n",
    "    \"\"\"\n",
    "    Gera amostras aleatórias que atendem a um conjunto de condições, variando apenas as outras features.\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    fixed_values = {str(cond.arg(0)): float(cond.arg(1).as_fraction()) for cond in conditions}\n",
    "\n",
    "    df_variation = df.drop(columns=fixed_values.keys())\n",
    "    samples = {col: np.random.uniform(df[col].min(), df[col].max(), n_samples) for col in df_variation.columns}\n",
    "    samples = {key: np.round(value, 2) for key, value in samples.items()}\n",
    "\n",
    "    for feature, value in fixed_values.items():\n",
    "        samples[feature] = [value] * n_samples\n",
    "\n",
    "    generated_df = pd.DataFrame(samples)\n",
    "    return generated_df[df.columns]\n",
    "\n",
    "\n",
    "def apply_noise_to_samples(X, df, noise_level):\n",
    "    df_noisy = df.copy()\n",
    "    for col in df.columns:\n",
    "        min_val = X[col].min()\n",
    "        max_val = X[col].max()\n",
    "        random_vals = np.random.uniform(min_val, max_val, size=len(df))\n",
    "        # Interpola entre valor original e valor aleatório\n",
    "        df_noisy[col] = (1 - noise_level) * df[col] + noise_level * random_vals\n",
    "    return df_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8112de35",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    {\"target_class\": 0, \"mult_margin\": 0},\n",
    "    {\"target_class\": 0, \"mult_margin\": 0.5},\n",
    "    {\"target_class\": 1, \"mult_margin\": 0},\n",
    "    {\"target_class\": 1, \"mult_margin\": 0.5},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa9e14ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>explanation class</th>\n",
       "      <th>noise samples</th>\n",
       "      <th>noise level</th>\n",
       "      <th>classified 0</th>\n",
       "      <th>classified 1</th>\n",
       "      <th>exp. threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>92.14 ± 10.95</td>\n",
       "      <td>7.86 ± 10.95</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>93.65 ± 11.58</td>\n",
       "      <td>6.35 ± 11.58</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>49.57 ± 32.38</td>\n",
       "      <td>50.43 ± 32.38</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50.41 ± 34.78</td>\n",
       "      <td>49.59 ± 34.78</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   explanation class  noise samples  noise level   classified 0  \\\n",
       "0                  0            100          0.1  92.14 ± 10.95   \n",
       "1                  0            100          0.1  93.65 ± 11.58   \n",
       "2                  1            100          0.1  49.57 ± 32.38   \n",
       "3                  1            100          0.1  50.41 ± 34.78   \n",
       "\n",
       "    classified 1 exp. threshold  \n",
       "0   7.86 ± 10.95             0%  \n",
       "1   6.35 ± 11.58            50%  \n",
       "2  50.43 ± 32.38             0%  \n",
       "3  49.59 ± 34.78            50%  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results = []\n",
    "for config in configs:\n",
    "    df = get_robustness_results_n(\n",
    "        \"saheart\", \n",
    "        n_samples=100, \n",
    "        n_extra_samples=100, \n",
    "        target_class=config[\"target_class\"], \n",
    "        mult_margin=config[\"mult_margin\"], \n",
    "        noise_level=0.1\n",
    "    )\n",
    "\n",
    "    df[\"exp. threshold\"] = \"0%\" if config[\"mult_margin\"] == 0 else \"50%\"\n",
    "    all_results.append(df)\n",
    "\n",
    "results_df = pd.concat(all_results, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "358b2b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>explanation class</th>\n",
       "      <th>noise samples</th>\n",
       "      <th>noise level</th>\n",
       "      <th>classified 0</th>\n",
       "      <th>classified 1</th>\n",
       "      <th>target_class</th>\n",
       "      <th>exp. threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>71.25 ± 23.43</td>\n",
       "      <td>28.75 ± 23.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>70.09 ± 23.34</td>\n",
       "      <td>29.91 ± 23.34</td>\n",
       "      <td>0</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>31.94 ± 9.07</td>\n",
       "      <td>68.06 ± 9.07</td>\n",
       "      <td>1</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>31.94 ± 10.12</td>\n",
       "      <td>68.06 ± 10.12</td>\n",
       "      <td>1</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   explanation class  noise samples  noise level   classified 0  \\\n",
       "0                  0            100          0.1  71.25 ± 23.43   \n",
       "1                  0            100          0.1  70.09 ± 23.34   \n",
       "2                  1            100          0.1   31.94 ± 9.07   \n",
       "3                  1            100          0.1  31.94 ± 10.12   \n",
       "\n",
       "    classified 1  target_class exp. threshold  \n",
       "0  28.75 ± 23.43             0             0%  \n",
       "1  29.91 ± 23.34             0            50%  \n",
       "2   68.06 ± 9.07             1             0%  \n",
       "3  68.06 ± 10.12             1            50%  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results = []\n",
    "for config in configs:\n",
    "    df = get_robustness_results_n(\n",
    "        \"adult\", \n",
    "        n_samples=100,\n",
    "        n_extra_samples=100, \n",
    "        target_class=config[\"target_class\"], \n",
    "        mult_margin=config[\"mult_margin\"], \n",
    "        noise_level=0.1\n",
    "    )\n",
    "\n",
    "    df[\"target_class\"] = config[\"target_class\"]\n",
    "    df[\"exp. threshold\"] = \"0%\" if config[\"mult_margin\"] == 0 else \"50%\"\n",
    "    all_results.append(df)\n",
    "\n",
    "results_df = pd.concat(all_results, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e98cdef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>explanation class</th>\n",
       "      <th>noise samples</th>\n",
       "      <th>noise level</th>\n",
       "      <th>classified 0</th>\n",
       "      <th>classified 1</th>\n",
       "      <th>target_class</th>\n",
       "      <th>exp. threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>90.50 ± 24.90</td>\n",
       "      <td>9.50 ± 24.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>90.29 ± 25.53</td>\n",
       "      <td>9.71 ± 25.53</td>\n",
       "      <td>0</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>18.32 ± 22.36</td>\n",
       "      <td>81.68 ± 22.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>23.30 ± 26.21</td>\n",
       "      <td>76.70 ± 26.21</td>\n",
       "      <td>1</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   explanation class  noise samples  noise level   classified 0  \\\n",
       "0                  0            100          0.1  90.50 ± 24.90   \n",
       "1                  0            100          0.1  90.29 ± 25.53   \n",
       "2                  1            100          0.1  18.32 ± 22.36   \n",
       "3                  1            100          0.1  23.30 ± 26.21   \n",
       "\n",
       "    classified 1  target_class exp. threshold  \n",
       "0   9.50 ± 24.90             0             0%  \n",
       "1   9.71 ± 25.53             0            50%  \n",
       "2  81.68 ± 22.36             1             0%  \n",
       "3  76.70 ± 26.21             1            50%  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results = []\n",
    "for config in configs:\n",
    "    df = get_robustness_results_n(\n",
    "        \"mushroom\", \n",
    "        n_samples=100,\n",
    "        n_extra_samples=100, \n",
    "        target_class=config[\"target_class\"], \n",
    "        mult_margin=config[\"mult_margin\"], \n",
    "        noise_level=0.1\n",
    "    )\n",
    "\n",
    "    df[\"target_class\"] = config[\"target_class\"]\n",
    "    df[\"exp. threshold\"] = \"0%\" if config[\"mult_margin\"] == 0 else \"50%\"\n",
    "    all_results.append(df)\n",
    "\n",
    "results_df = pd.concat(all_results, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e845c5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>explanation class</th>\n",
       "      <th>noise samples</th>\n",
       "      <th>noise level</th>\n",
       "      <th>classified 0</th>\n",
       "      <th>classified 1</th>\n",
       "      <th>target_class</th>\n",
       "      <th>exp. threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100.00 ± 0.00</td>\n",
       "      <td>0.00 ± 0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>99.99 ± 0.10</td>\n",
       "      <td>0.01 ± 0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10.41 ± 14.59</td>\n",
       "      <td>89.59 ± 14.59</td>\n",
       "      <td>1</td>\n",
       "      <td>0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.61 ± 11.18</td>\n",
       "      <td>94.39 ± 11.18</td>\n",
       "      <td>1</td>\n",
       "      <td>50%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   explanation class  noise samples  noise level   classified 0  \\\n",
       "0                  0            100          0.1  100.00 ± 0.00   \n",
       "1                  0            100          0.1   99.99 ± 0.10   \n",
       "2                  1            100          0.1  10.41 ± 14.59   \n",
       "3                  1            100          0.1   5.61 ± 11.18   \n",
       "\n",
       "    classified 1  target_class exp. threshold  \n",
       "0    0.00 ± 0.00             0             0%  \n",
       "1    0.01 ± 0.10             0            50%  \n",
       "2  89.59 ± 14.59             1             0%  \n",
       "3  94.39 ± 11.18             1            50%  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results = []\n",
    "for config in configs:\n",
    "    df = get_robustness_results_n(\n",
    "        \"sonar\", \n",
    "        n_samples=100,\n",
    "        n_extra_samples=100, \n",
    "        target_class=config[\"target_class\"], \n",
    "        mult_margin=config[\"mult_margin\"], \n",
    "        noise_level=0.1\n",
    "    )\n",
    "\n",
    "    df[\"target_class\"] = config[\"target_class\"]\n",
    "    df[\"exp. threshold\"] = \"0%\" if config[\"mult_margin\"] == 0 else \"50%\"\n",
    "    all_results.append(df)\n",
    "\n",
    "results_df = pd.concat(all_results, ignore_index=True)\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
