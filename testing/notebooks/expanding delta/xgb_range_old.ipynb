{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from z3 import *\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_option(rational_to_decimal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Real('test')\n",
    "testexp = test >= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 5 >=\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "testexp.arg(0),\n",
    "testexp.arg(1),\n",
    "testexp.decl()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from z3 import *\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class XGBoostExplainer:\n",
    "    \"\"\"Apenas classificação binária e base_score = None\n",
    "    data = X. labels = y\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, data):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            model (XGBoost): xgboost model fited\n",
    "            data (DataFrame): dataframe (X or X_train)\n",
    "            labels (array): y (targets)\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.data = data.values\n",
    "        self.columns = model.feature_names_in_.tolist()\n",
    "        self.max_categories = 2\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"Initialize Z3 expressions from model and categoric features from data.\n",
    "        z3 expressions are built here for pkl compatibility (use fit after export pkl)\n",
    "        \"\"\"\n",
    "        self.categoric_features = self.get_categoric_features(self.data)\n",
    "        self.T_model = self.model_trees_expression(self.model)\n",
    "        self.T = self.T_model\n",
    "\n",
    "    def explain(self, instance, reorder=\"asc\"):\n",
    "        self.I = self.instance_expression(instance)\n",
    "        self.D = self.decision_function_expression(self.model, [instance])\n",
    "\n",
    "        return self.explain_expression(self.I, self.T, self.D, self.model, reorder)\n",
    "\n",
    "    def get_categoric_features(self, data: np.ndarray):\n",
    "        \"\"\"\n",
    "        Recebe um dataset e retorna uma fórmula no z3 com:\n",
    "        - Restrições de valor máximo e mínimo para features contínuas.\n",
    "        - Restrições de igualdade para features categóricas binárias.\n",
    "        \"\"\"\n",
    "        categoric_features = []\n",
    "        for i in range(data.shape[1]):\n",
    "            feature_values = data[:, i]\n",
    "            unique_values = np.unique(feature_values)\n",
    "            if len(unique_values) <= self.max_categories:\n",
    "                categoric_features.append(self.columns[i])\n",
    "\n",
    "        return categoric_features\n",
    "\n",
    "    def feature_constraints(self, constraints=[]):\n",
    "        \"\"\" TODO\n",
    "        esperado receber limites das features pelo usuário\n",
    "        formato previso: matriz/dataframe [feaature, min/max, valor]\n",
    "        constraaint_expression = \"constraaint_df_to_feature()\"\n",
    "        \"\"\"\n",
    "        return\n",
    "\n",
    "    def model_trees_expression(self, model):\n",
    "        \"\"\"\n",
    "        Constrói expressões lógicas para todas as árvores de decisão em um dataframe de XGBoost.\n",
    "        Para árvores que são apenas folhas, gera diretamente um And com o valor da folha.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): Dataframe contendo informações das árvores.\n",
    "            class_index (int): Índice da classe atual.\n",
    "\n",
    "        Returns:\n",
    "            z3.ExprRef: Fórmula representando todos os caminhos de todas as árvores.\n",
    "        \"\"\"\n",
    "        df = model.get_booster().trees_to_dataframe()\n",
    "        df[\"Split\"] = df[\"Split\"].round(4)\n",
    "        self.booster_df = df\n",
    "        class_index = 0  # if model.n_classes_ == 2:\n",
    "        all_tree_formulas = []\n",
    "\n",
    "        for tree_index in df[\"Tree\"].unique():\n",
    "            tree_df = df[df[\"Tree\"] == tree_index]\n",
    "            o = Real(f\"o_{tree_index}_{class_index}\")\n",
    "\n",
    "            if len(tree_df) == 1 and tree_df.iloc[0][\"Feature\"] == \"Leaf\":\n",
    "                leaf_value = tree_df.iloc[0][\"Gain\"]\n",
    "                all_tree_formulas.append(And(o == leaf_value))\n",
    "                continue\n",
    "            path_formulas = []\n",
    "\n",
    "            def get_conditions(node_id):\n",
    "                conditions = []\n",
    "                current_node = tree_df[tree_df[\"ID\"] == node_id]\n",
    "                if current_node.empty:\n",
    "                    return conditions\n",
    "\n",
    "                parent_node = tree_df[\n",
    "                    (tree_df[\"Yes\"] == node_id) | (tree_df[\"No\"] == node_id)\n",
    "                ]\n",
    "                if not parent_node.empty:\n",
    "                    parent_data = parent_node.iloc[0]\n",
    "                    feature = parent_data[\"Feature\"]\n",
    "                    split_value = parent_data[\"Split\"]\n",
    "                    x = Real(feature)\n",
    "                    if parent_data[\"Yes\"] == node_id:\n",
    "                        conditions.append(x < split_value)\n",
    "                    else:\n",
    "                        conditions.append(x >= split_value)\n",
    "                    conditions = get_conditions(parent_data[\"ID\"]) + conditions\n",
    "\n",
    "                return conditions\n",
    "\n",
    "            for _, node in tree_df[tree_df[\"Feature\"] == \"Leaf\"].iterrows():\n",
    "                leaf_value = node[\"Gain\"]\n",
    "                leaf_id = node[\"ID\"]\n",
    "                conditions = get_conditions(leaf_id)\n",
    "                path_formula = And(*conditions)\n",
    "                implication = Implies(path_formula, o == leaf_value)\n",
    "                path_formulas.append(implication)\n",
    "\n",
    "            all_tree_formulas.append(And(*path_formulas))\n",
    "        return And(*all_tree_formulas)\n",
    "\n",
    "    def decision_function_expression(self, model, x):\n",
    "        n_classes = 1 if model.n_classes_ <= 2 else model.n_classes_\n",
    "        predicted_class = model.predict(x)[0]\n",
    "        n_estimators = len(model.get_booster().get_dump())\n",
    "\n",
    "        estimator_pred = Solver()\n",
    "        estimator_pred.add(self.I)\n",
    "        estimator_pred.add(self.T)\n",
    "        variables = [Real(f\"o_{i}_0\") for i in range(n_estimators)]\n",
    "        if estimator_pred.check() == sat:\n",
    "            solvermodel = estimator_pred.model()\n",
    "            total_sum = sum(\n",
    "                float(solvermodel.eval(var).as_fraction()) for var in variables\n",
    "            )\n",
    "        else:\n",
    "            total_sum = 0\n",
    "            print(\"estimator error\")\n",
    "        init_value = model.predict(x, output_margin=True)[0] - total_sum\n",
    "\n",
    "        equation_list = []\n",
    "        for class_number in range(n_classes):\n",
    "            estimator_list = []\n",
    "            for estimator_number in range(\n",
    "                int(len(model.get_booster().get_dump()) / n_classes)\n",
    "            ):\n",
    "                o = Real(f\"o_{estimator_number}_{class_number}\")\n",
    "                estimator_list.append(o)\n",
    "            equation_o = Sum(estimator_list) + init_value\n",
    "            equation_list.append(equation_o)\n",
    "\n",
    "        if n_classes <= 2:\n",
    "            if predicted_class == 0:\n",
    "                final_equation = equation_list[0] < 0\n",
    "            else:\n",
    "                final_equation = equation_list[0] > 0\n",
    "        else:\n",
    "            compare_equation = []\n",
    "            for class_number in range(n_classes):\n",
    "                if predicted_class != class_number:\n",
    "                    compare_equation.append(\n",
    "                        equation_list[predicted_class] > equation_list[class_number]\n",
    "                    )\n",
    "            final_equation = And(compare_equation)\n",
    "\n",
    "        return final_equation\n",
    "\n",
    "    def instance_expression(self, instance):\n",
    "        formula = [Real(self.columns[i]) == value for i, value in enumerate(instance)]\n",
    "        return formula\n",
    "\n",
    "    def explain_expression(self, I, T, D, model, reorder):\n",
    "        i_expression = I.copy()\n",
    "        T_s = T\n",
    "        D_s = D\n",
    "\n",
    "        importances = model.feature_importances_\n",
    "        non_zero_indices = np.where(importances != 0)[0]\n",
    "\n",
    "        if reorder == \"asc\":\n",
    "            sorted_feature_indices = non_zero_indices[\n",
    "                np.argsort(importances[non_zero_indices])\n",
    "            ]\n",
    "            i_expression = [i_expression[i] for i in sorted_feature_indices]\n",
    "        elif reorder == \"desc\":\n",
    "            sorted_feature_indices = non_zero_indices[\n",
    "                np.argsort(-importances[non_zero_indices])\n",
    "            ]\n",
    "            i_expression = [i_expression[i] for i in sorted_feature_indices]\n",
    "\n",
    "        for feature in i_expression.copy():\n",
    "\n",
    "            i_expression.remove(feature)\n",
    "\n",
    "            # prove(Implies(And(And(i_expression), T), D))\n",
    "            if self.is_proved(Implies(And(And(i_expression), T_s), D_s)):\n",
    "                continue\n",
    "                # print('proved')\n",
    "            else:\n",
    "                # print('not proved')\n",
    "                i_expression.append(feature)\n",
    "        # print(self.is_proved(Implies(And(And(i_expression), T_s), D_s)))\n",
    "        return i_expression\n",
    "\n",
    "    def is_proved(self, f):\n",
    "        s = Solver()\n",
    "        s.add(Not(f))\n",
    "        if s.check() == unsat:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def delta_expression(self, exp):\n",
    "        expressions = []\n",
    "        delta = Real(\"delta\")\n",
    "\n",
    "        self.delta_features = []\n",
    "        for name in exp:\n",
    "            tokens = name.split(\" == \")\n",
    "            z3feature = Real(tokens[0])\n",
    "            self.delta_features.append(str(z3feature))\n",
    "            value = tokens[1]\n",
    "\n",
    "            if tokens[0] in self.categoric_features:\n",
    "                expressions.append(z3feature == float(value))\n",
    "            else:\n",
    "                expressions.append(z3feature >= float(value) - delta)\n",
    "                expressions.append(z3feature <= float(value) + delta)\n",
    "\n",
    "        expressions.append(delta >= 0)\n",
    "        self.deltaexp = expressions\n",
    "        return expressions\n",
    "\n",
    "    def get_delta(self, exp):\n",
    "        expstr = []\n",
    "        for expression in exp:\n",
    "            self.cumulative_range_expresson.append(expression)\n",
    "            expstr.append(str(expression))\n",
    "            \n",
    "        self.delta_expressions = self.delta_expression(expstr)\n",
    "\n",
    "        opt = Optimize()\n",
    "        opt.add(self.delta_expressions)\n",
    "        opt.add(self.T)\n",
    "        opt.add(Not(self.D))\n",
    "\n",
    "        delta = Real(\"delta\")\n",
    "        expmin = opt.minimize(delta)\n",
    "        opt.check()\n",
    "\n",
    "        # rangemodel = opt.model()\n",
    "\n",
    "        value = str(expmin.value())\n",
    "\n",
    "        if \"+ epsilon\" in value:\n",
    "            delta_value = float(value.split(\" + \")[0])\n",
    "        elif \"epsilon\" == value:\n",
    "            delta_value = 0\n",
    "        else:\n",
    "            delta_value = float(value) - 0.01\n",
    "        return delta_value\n",
    "\n",
    "    def explain_range(\n",
    "        self,\n",
    "        instance,\n",
    "        reorder=\"asc\",\n",
    "        dataset_bounds=True,\n",
    "    ):\n",
    "        self.cumulative_range_expresson = []\n",
    "        self.range_metric = 0\n",
    "        exp = self.explain(instance, reorder)\n",
    "        if exp != []:\n",
    "            delta_value = self.get_delta(exp)\n",
    "\n",
    "            if delta_value == 0:\n",
    "                expstr = []\n",
    "                for exppart in exp:\n",
    "                    expstr.append(str(exppart))\n",
    "                return expstr\n",
    "            # save_deltas for model comparison\n",
    "\n",
    "            range_exp = []\n",
    "            for item in exp:\n",
    "                name = str(item.arg(0))\n",
    "                if name not in self.categoric_features:\n",
    "                    itemvalue = float(item.arg(1).as_fraction())\n",
    "                    lower = round(itemvalue - delta_value, 2)\n",
    "                    upper = round(itemvalue + delta_value, 2)\n",
    "\n",
    "                    if dataset_bounds == True:\n",
    "                        idx = list(self.columns).index(name)\n",
    "                        min_idx = np.min(self.data[:, idx])\n",
    "                        max_idx = np.max(self.data[:, idx])\n",
    "                        if lower < min_idx:\n",
    "                            lower = min_idx\n",
    "                        if upper > max_idx:\n",
    "                            upper = max_idx\n",
    "                    \n",
    "                    self.range_metric += (upper - lower)\n",
    "                    range_exp.append(f\"{lower} <= {name} <= {upper}\")\n",
    "                else:\n",
    "                    range_exp.append(f\"{name} == {item.arg(1)}\")\n",
    "\n",
    "            return range_exp\n",
    "        else:\n",
    "            return exp\n",
    "\n",
    "    def explain_range_other():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnEncoderDecoder:\n",
    "    def __init__(self):\n",
    "        self.mapping = {}\n",
    "\n",
    "    def encode(self, df):\n",
    "        \"\"\"Substitui os nomes das colunas por x0, x1, ..., xn\"\"\"\n",
    "        self.mapping = {f\"x{i}\": col for i, col in enumerate(df.columns)}\n",
    "        df_encoded = df.rename(\n",
    "            columns={col: new_col for new_col, col in self.mapping.items()}\n",
    "        )\n",
    "        return df_encoded\n",
    "\n",
    "    def decode(self, text):\n",
    "        \"\"\"Substitui x0, x1, ..., xn pelos nomes originais das colunas\"\"\"\n",
    "        for new_col, original_col in self.mapping.items():\n",
    "            text = text.replace(new_col, original_col)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = iris.target\n",
    "\n",
    "# y = np.where(y == 0, 0, 1)  # converte em binario\n",
    "y[y == 2] = 0\n",
    "# X = X.iloc[:, :2] # corta colunas do df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Texto decodificado:\n",
      "decode de sepal width (cm)\n"
     ]
    }
   ],
   "source": [
    "encoder_decoder = ColumnEncoderDecoder()\n",
    "X = encoder_decoder.encode(X)\n",
    "\n",
    "encoded_text = \"decode de x1\"\n",
    "decoded_text = encoder_decoder.decode(encoded_text)\n",
    "\n",
    "print(\"\\nTexto decodificado:\")\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=101\n",
    ")\n",
    "\n",
    "xgbc = XGBClassifier(n_estimators=100, max_depth=3, learning_rate=0.1)\n",
    "xgbc.fit(X_train, y_train)\n",
    "\n",
    "preds = xgbc.predict(X_test)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = XGBoostExplainer(xgbc, X)\n",
    "explainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5.51 <= x2 <= 5.69', '6.01 <= x0 <= 6.19', '2.51 <= x1 <= 2.69']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explainer.explain_range(X_test.values[19], reorder=\"desc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03846328, 0.02926282, 0.36015186, 0.57212204], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbc.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.0 <= x2 <= 2.99']\n",
      "['1.0 <= x2 <= 2.99']\n",
      "['1.0 <= x2 <= 2.99']\n",
      "['x3 == 1.6', 'x2 == 5.8', 'x0 == 7.2', 'x1 == 3']\n",
      "['1.21 <= x3 <= 1.59', '4.51 <= x2 <= 4.89']\n",
      "['x3 == 1.8']\n",
      "['1.31 <= x3 <= 1.69', '4.31 <= x2 <= 4.69']\n",
      "['0.91 <= x3 <= 1.69', '3.61 <= x2 <= 4.39']\n",
      "['x2 == 5', 'x0 == 6.3', 'x1 == 2.5']\n",
      "['1.0 <= x2 <= 2.99']\n",
      "['1.8 <= x3 <= 2.2']\n",
      "['1.0 <= x2 <= 2.99']\n",
      "['1.0 <= x2 <= 2.99']\n",
      "['x2 == 6.7', 'x0 == 7.7', 'x1 == 2.8']\n",
      "['x3 == 1.8']\n",
      "['0.91 <= x3 <= 1.69', '3.91 <= x2 <= 4.69']\n",
      "['0.91 <= x3 <= 1.69', '3.71 <= x2 <= 4.49']\n",
      "['0.91 <= x3 <= 1.69', '3.81 <= x2 <= 4.59']\n",
      "['1.0 <= x2 <= 2.99']\n",
      "['5.51 <= x2 <= 5.69', '6.01 <= x0 <= 6.19', '2.51 <= x1 <= 2.69']\n",
      "['0.51 <= x3 <= 1.69', '3.21 <= x2 <= 4.39']\n",
      "['1.0 <= x2 <= 2.99']\n",
      "['0.71 <= x3 <= 1.69', '3.91 <= x2 <= 4.89']\n",
      "['1.11 <= x3 <= 1.69', '4.11 <= x2 <= 4.69']\n",
      "['0.91 <= x3 <= 1.69', '3.91 <= x2 <= 4.69']\n",
      "['0.91 <= x3 <= 1.69', '3.21 <= x2 <= 3.99']\n",
      "['0.7 <= x3 <= 1.3', '3.0 <= x2 <= 3.6']\n",
      "['1.8 <= x3 <= 2.5']\n",
      "['1.0 <= x2 <= 2.99']\n",
      "['1.0 <= x2 <= 2.99']\n"
     ]
    }
   ],
   "source": [
    "range_metric_list = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    print(explainer.explain_range(X_test.values[i], reorder=\"desc\"))\n",
    "    range_metric_list.append(explainer.range_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum: 39.10000000000001 mean: 1.3033333333333337\n"
     ]
    }
   ],
   "source": [
    "print(\"sum:\", np.sum(range_metric_list), \"mean:\", np.mean(range_metric_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['1.0 <= x2 <= 2.99']\n",
      "1 ['1.0 <= x2 <= 2.99']\n",
      "2 ['1.0 <= x2 <= 2.99']\n",
      "3 ['x1 == 3', 'x0 == 7.2', 'x2 == 5.8', 'x3 == 1.6']\n",
      "4 ['4.51 <= x2 <= 4.89', '1.21 <= x3 <= 1.59']\n",
      "5 ['x3 == 1.8']\n",
      "6 ['4.31 <= x2 <= 4.69', '1.31 <= x3 <= 1.69']\n",
      "7 ['3.61 <= x2 <= 4.39', '0.91 <= x3 <= 1.69']\n",
      "8 ['1.8 <= x3 <= 2.0']\n",
      "9 ['1.0 <= x2 <= 2.99']\n",
      "10 ['1.8 <= x3 <= 2.2']\n",
      "11 ['1.0 <= x2 <= 2.99']\n",
      "12 ['1.0 <= x2 <= 2.99']\n",
      "13 ['1.8 <= x3 <= 2.2']\n",
      "14 ['x3 == 1.8']\n",
      "15 ['3.91 <= x2 <= 4.69', '0.91 <= x3 <= 1.69']\n",
      "16 ['3.71 <= x2 <= 4.49', '0.91 <= x3 <= 1.69']\n",
      "17 ['3.81 <= x2 <= 4.59', '0.91 <= x3 <= 1.69']\n",
      "18 ['1.0 <= x2 <= 2.99']\n",
      "19 ['2.51 <= x1 <= 2.69', '6.01 <= x0 <= 6.19', '5.51 <= x2 <= 5.69']\n",
      "20 ['3.21 <= x2 <= 4.39', '0.51 <= x3 <= 1.69']\n",
      "21 ['1.0 <= x2 <= 2.99']\n",
      "22 ['3.91 <= x2 <= 4.89', '0.71 <= x3 <= 1.69']\n",
      "23 ['4.11 <= x2 <= 4.69', '1.11 <= x3 <= 1.69']\n",
      "24 ['3.91 <= x2 <= 4.69', '0.91 <= x3 <= 1.69']\n",
      "25 ['3.21 <= x2 <= 3.99', '0.91 <= x3 <= 1.69']\n",
      "26 ['3.0 <= x2 <= 3.6', '0.7 <= x3 <= 1.3']\n",
      "27 ['1.8 <= x3 <= 2.5']\n",
      "28 ['1.0 <= x2 <= 2.99']\n",
      "29 ['1.0 <= x2 <= 2.99']\n"
     ]
    }
   ],
   "source": [
    "for i in range(X_test.shape[0]):\n",
    "    print(i, explainer.explain_range(X_test.values[i], reorder=\"asc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_correct_explanation(exp, explainer):\n",
    "    opt = Optimize()\n",
    "\n",
    "    exprange_z3 = []\n",
    "    exptokens = []\n",
    "    for item in exp:\n",
    "        item = str(item)\n",
    "        if \"<=\" in item:\n",
    "            tokens = item.split(\" <= \")\n",
    "            exprange_z3.append((tokens[0]) <= Real(tokens[1]))\n",
    "            exprange_z3.append(Real(tokens[1]) <= (tokens[2]))\n",
    "            exptokens.append(tokens[1])\n",
    "        else:\n",
    "            tokens = item.split(\" == \")\n",
    "            exprange_z3.append(Real(tokens[0]) == (tokens[1]))\n",
    "            exptokens.append(tokens[0])\n",
    "    opt.add(exprange_z3)\n",
    "\n",
    "    inst = explainer.I\n",
    "    deltaexp = []\n",
    "    for item in inst:\n",
    "        item = str(item)\n",
    "        tokens = item.split(\" == \")\n",
    "        if tokens[0] not in exptokens:\n",
    "            if tokens[0] in explainer.categoric_features:\n",
    "                deltaexp.append(Real(tokens[0]) == (tokens[1]))\n",
    "            else:\n",
    "                deltaexp.append(Real(tokens[0]) >= (tokens[1]) - Real(\"delta\"))\n",
    "                deltaexp.append(Real(tokens[0]) <= (tokens[1]) + Real(\"delta\"))\n",
    "    opt.add(deltaexp)\n",
    "\n",
    "    opt.add(explainer.T_model)\n",
    "\n",
    "    opt.add(Not(explainer.D))\n",
    "\n",
    "    opt.add(Real(\"delta\") >= 0)\n",
    "\n",
    "    delta = Real(\"delta\")\n",
    "    expmin = opt.minimize(delta)\n",
    "\n",
    "    printlist = []\n",
    "    if opt.check() == sat:\n",
    "        for var in opt.model():\n",
    "            if str(var) in explainer.columns:\n",
    "                printlist.append(f\"{var} = {opt.model()[var]}\")\n",
    "        printlist.append(f\"delta = {opt.model().eval(delta)}\")\n",
    "    else:\n",
    "        printlist.append(\"unsat == correct\")\n",
    "    #   print(printlist)\n",
    "    value = str(expmin.value())\n",
    "    #   print(value)\n",
    "    return printlist, exprange_z3, deltaexp, explainer.T, Not(explainer.D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 150)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "explanationstest = []\n",
    "for i in range(0, len(X)):\n",
    "    exprange = explainer.explain_range(X.values[i])\n",
    "    explanationstest.append(exprange)\n",
    "    ans, ansrange, ansdelta, anst, ansnotd = check_correct_explanation(\n",
    "        exprange, explainer\n",
    "    )\n",
    "    if ans[0] == (\"unsat == correct\"):\n",
    "        count += 1\n",
    "    else:\n",
    "        print(i, ans)\n",
    "count, len(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
