{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from z3 import *\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_option(rational_to_decimal=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from z3 import *\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class XGBoostExplainer:\n",
    "    \"\"\"Apenas classificação binária e base_score = None\n",
    "    data = X. labels = y\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, data):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            model (XGBoost): xgboost model fited\n",
    "            data (DataFrame): dataframe (X or X_train)\n",
    "            labels (array): y (targets)\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.data = data.values\n",
    "        self.columns = model.feature_names_in_.tolist()\n",
    "        self.max_categories = 2\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"Initialize Z3 expressions from model and categoric features from data.\n",
    "        z3 expressions are built here for pkl compatibility (use fit after export pkl)\n",
    "        \"\"\"\n",
    "        set_option(rational_to_decimal=True)\n",
    "        \n",
    "        self.categoric_features = self.get_categoric_features(self.data)\n",
    "        self.T_model = self.model_trees_expression(self.model)\n",
    "        self.T = self.T_model\n",
    "\n",
    "    def explain(self, instance, reorder=\"asc\"):\n",
    "        self.I = self.instance_expression(instance)\n",
    "        self.D = self.decision_function_expression(self.model, [instance])\n",
    "\n",
    "        return self.explain_expression(self.I, self.T, self.D, self.model, reorder)\n",
    "\n",
    "    def get_categoric_features(self, data: np.ndarray):\n",
    "        \"\"\"\n",
    "        Recebe um dataset e retorna uma fórmula no z3 com:\n",
    "        - Restrições de valor máximo e mínimo para features contínuas.\n",
    "        - Restrições de igualdade para features categóricas binárias.\n",
    "        \"\"\"\n",
    "        categoric_features = []\n",
    "        for i in range(data.shape[1]):\n",
    "            feature_values = data[:, i]\n",
    "            unique_values = np.unique(feature_values)\n",
    "            if len(unique_values) <= self.max_categories:\n",
    "                categoric_features.append(self.columns[i])\n",
    "\n",
    "        return categoric_features\n",
    "\n",
    "    def feature_constraints(self, constraints=[]):\n",
    "        \"\"\"TODO\n",
    "        esperado receber limites das features pelo usuário\n",
    "        formato previso: matriz/dataframe [feaature, min/max, valor]\n",
    "        constraaint_expression = \"constraaint_df_to_feature()\"\n",
    "        \"\"\"\n",
    "        return\n",
    "\n",
    "    def model_trees_expression(self, model):\n",
    "        \"\"\"\n",
    "        Constrói expressões lógicas para todas as árvores de decisão em um dataframe de XGBoost.\n",
    "        Para árvores que são apenas folhas, gera diretamente um And com o valor da folha.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): Dataframe contendo informações das árvores.\n",
    "            class_index (int): Índice da classe atual.\n",
    "\n",
    "        Returns:\n",
    "            z3.ExprRef: Fórmula representando todos os caminhos de todas as árvores.\n",
    "        \"\"\"\n",
    "        df = model.get_booster().trees_to_dataframe()\n",
    "        df[\"Split\"] = df[\"Split\"].round(4)\n",
    "        self.booster_df = df\n",
    "        class_index = 0  # if model.n_classes_ == 2:\n",
    "        all_tree_formulas = []\n",
    "\n",
    "        for tree_index in df[\"Tree\"].unique():\n",
    "            tree_df = df[df[\"Tree\"] == tree_index]\n",
    "            o = Real(f\"o_{tree_index}_{class_index}\")\n",
    "\n",
    "            if len(tree_df) == 1 and tree_df.iloc[0][\"Feature\"] == \"Leaf\":\n",
    "                leaf_value = tree_df.iloc[0][\"Gain\"]\n",
    "                all_tree_formulas.append(And(o == leaf_value))\n",
    "                continue\n",
    "            path_formulas = []\n",
    "\n",
    "            def get_conditions(node_id):\n",
    "                conditions = []\n",
    "                current_node = tree_df[tree_df[\"ID\"] == node_id]\n",
    "                if current_node.empty:\n",
    "                    return conditions\n",
    "\n",
    "                parent_node = tree_df[\n",
    "                    (tree_df[\"Yes\"] == node_id) | (tree_df[\"No\"] == node_id)\n",
    "                ]\n",
    "                if not parent_node.empty:\n",
    "                    parent_data = parent_node.iloc[0]\n",
    "                    feature = parent_data[\"Feature\"]\n",
    "                    split_value = parent_data[\"Split\"]\n",
    "                    x = Real(feature)\n",
    "                    if parent_data[\"Yes\"] == node_id:\n",
    "                        conditions.append(x < split_value)\n",
    "                    else:\n",
    "                        conditions.append(x >= split_value)\n",
    "                    conditions = get_conditions(parent_data[\"ID\"]) + conditions\n",
    "\n",
    "                return conditions\n",
    "\n",
    "            for _, node in tree_df[tree_df[\"Feature\"] == \"Leaf\"].iterrows():\n",
    "                leaf_value = node[\"Gain\"]\n",
    "                leaf_id = node[\"ID\"]\n",
    "                conditions = get_conditions(leaf_id)\n",
    "                path_formula = And(*conditions)\n",
    "                implication = Implies(path_formula, o == leaf_value)\n",
    "                path_formulas.append(implication)\n",
    "\n",
    "            all_tree_formulas.append(And(*path_formulas))\n",
    "        return And(*all_tree_formulas)\n",
    "\n",
    "    def decision_function_expression(self, model, x):\n",
    "        n_classes = 1 if model.n_classes_ <= 2 else model.n_classes_\n",
    "        predicted_class = model.predict(x)[0]\n",
    "        n_estimators = len(model.get_booster().get_dump())\n",
    "\n",
    "        estimator_pred = Solver()\n",
    "        estimator_pred.add(self.I)\n",
    "        estimator_pred.add(self.T)\n",
    "        variables = [Real(f\"o_{i}_0\") for i in range(n_estimators)]\n",
    "        if estimator_pred.check() == sat:\n",
    "            solvermodel = estimator_pred.model()\n",
    "            total_sum = sum(\n",
    "                float(solvermodel.eval(var).as_fraction()) for var in variables\n",
    "            )\n",
    "        else:\n",
    "            total_sum = 0\n",
    "            print(\"estimator error\")\n",
    "        init_value = model.predict(x, output_margin=True)[0] - total_sum\n",
    "\n",
    "        equation_list = []\n",
    "        for class_number in range(n_classes):\n",
    "            estimator_list = []\n",
    "            for estimator_number in range(\n",
    "                int(len(model.get_booster().get_dump()) / n_classes)\n",
    "            ):\n",
    "                o = Real(f\"o_{estimator_number}_{class_number}\")\n",
    "                estimator_list.append(o)\n",
    "            equation_o = Sum(estimator_list) + init_value\n",
    "            equation_list.append(equation_o)\n",
    "\n",
    "        if n_classes <= 2:\n",
    "            if predicted_class == 0:\n",
    "                final_equation = equation_list[0] < 0\n",
    "            else:\n",
    "                final_equation = equation_list[0] > 0\n",
    "        else:\n",
    "            compare_equation = []\n",
    "            for class_number in range(n_classes):\n",
    "                if predicted_class != class_number:\n",
    "                    compare_equation.append(\n",
    "                        equation_list[predicted_class] > equation_list[class_number]\n",
    "                    )\n",
    "            final_equation = And(compare_equation)\n",
    "\n",
    "        return final_equation\n",
    "\n",
    "    def instance_expression(self, instance):\n",
    "        formula = [Real(self.columns[i]) == value for i, value in enumerate(instance)]\n",
    "        return formula\n",
    "\n",
    "    def explain_expression(self, I, T, D, model, reorder):\n",
    "        i_expression = I.copy()\n",
    "        T_s = T\n",
    "        D_s = D\n",
    "\n",
    "        importances = model.feature_importances_\n",
    "        non_zero_indices = np.where(importances != 0)[0]\n",
    "\n",
    "        if reorder == \"asc\":\n",
    "            sorted_feature_indices = non_zero_indices[\n",
    "                np.argsort(importances[non_zero_indices])\n",
    "            ]\n",
    "            i_expression = [i_expression[i] for i in sorted_feature_indices]\n",
    "        elif reorder == \"desc\":\n",
    "            sorted_feature_indices = non_zero_indices[\n",
    "                np.argsort(-importances[non_zero_indices])\n",
    "            ]\n",
    "            i_expression = [i_expression[i] for i in sorted_feature_indices]\n",
    "\n",
    "        for feature in i_expression.copy():\n",
    "\n",
    "            i_expression.remove(feature)\n",
    "\n",
    "            # prove(Implies(And(And(i_expression), T), D))\n",
    "            if self.is_proved(Implies(And(And(i_expression), T_s), D_s)):\n",
    "                continue\n",
    "                # print('proved')\n",
    "            else:\n",
    "                # print('not proved')\n",
    "                i_expression.append(feature)\n",
    "        # print(self.is_proved(Implies(And(And(i_expression), T_s), D_s)))\n",
    "        return i_expression\n",
    "\n",
    "    def is_proved(self, f):\n",
    "        s = Solver()\n",
    "        s.add(Not(f))\n",
    "        if s.check() == unsat:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def delta_expression(self, expression):\n",
    "        # print(delta_expressions)\n",
    "        return  # delta_expressions\n",
    "\n",
    "    def get_deltas(self, exp):\n",
    "\n",
    "        for expression in exp:\n",
    "            if str(expression.arg(0)) in self.categoric_features:\n",
    "                self.caterogic_expressions.append(expression)\n",
    "                exp = list(filter(lambda expr: not expr.eq(expression), exp))\n",
    "            else:\n",
    "                self.cumulative_range_expresson.append(expression)\n",
    "\n",
    "        delta_list = []\n",
    "        for expression in exp:\n",
    "\n",
    "            self.cumulative_range_expresson = list(\n",
    "                filter(\n",
    "                    lambda expr: not expr.eq(expression),\n",
    "                    self.cumulative_range_expresson,\n",
    "                )\n",
    "            )\n",
    "            lower_min, upper_min = self.optmize_delta(expression)\n",
    "\n",
    "            if lower_min != None:\n",
    "                delta_value_lower = self.get_delta_value(str(lower_min.value()))\n",
    "                self.cumulative_range_expresson.append(\n",
    "                    expression.arg(0) >= expression.arg(1) - delta_value_lower\n",
    "                )\n",
    "            else:\n",
    "                # print(\"unsat == open range lower\")\n",
    "                delta_value_lower = None\n",
    "\n",
    "            if upper_min != None:\n",
    "                delta_value_upper = self.get_delta_value(str(upper_min.value()))\n",
    "                self.cumulative_range_expresson.append(\n",
    "                    expression.arg(0) <= expression.arg(1) + delta_value_upper\n",
    "                )\n",
    "            else:\n",
    "                # print(\"unsat == open range upper\")\n",
    "                delta_value_upper = None\n",
    "\n",
    "            # print(expression, delta_value_lower, delta_value_upper)\n",
    "            delta_list.append([expression, delta_value_lower, delta_value_upper])\n",
    "\n",
    "        self.delta_list = delta_list\n",
    "        return delta_list\n",
    "\n",
    "    def get_delta_value(self, value):\n",
    "        if \"+ epsilon\" in value:\n",
    "            delta_value = float(value.split(\" + \")[0])\n",
    "        elif \"epsilon\" == value:\n",
    "            delta_value = 0\n",
    "        elif \"0\" == value:\n",
    "            print(\"ERROR: delta == 0, explanation incorrect?\")\n",
    "            delta_value = 0\n",
    "        else:\n",
    "            delta_value = round(float(value) - 0.01, 2)\n",
    "\n",
    "        return delta_value\n",
    "\n",
    "    def optmize_delta(self, expression):\n",
    "        delta_upper = Real(\"delta_upper\")\n",
    "        delta_lower = Real(\"delta_lower\")\n",
    "\n",
    "        self.delta_features = []\n",
    "\n",
    "        delta_expressions = []\n",
    "        delta_expressions.append(expression.arg(0) >= expression.arg(1) - delta_lower)\n",
    "        delta_expressions.append(expression.arg(0) <= expression.arg(1) + delta_upper)\n",
    "\n",
    "        self.delta_expressions = delta_expressions\n",
    "\n",
    "        expression_list = []\n",
    "        expression_list.append(And(self.cumulative_range_expresson))\n",
    "        expression_list.append(And(self.caterogic_expressions))\n",
    "        expression_list.append(And(self.delta_expressions))\n",
    "        expression_list.append(self.T)\n",
    "        expression_list.append(Not(self.D))\n",
    "        expression_list.append(delta_upper >= 0)\n",
    "        expression_list.append(delta_lower >= 0)\n",
    "\n",
    "        opt_lower = Optimize()\n",
    "        opt_lower.add(And(expression_list))\n",
    "        opt_lower.add(delta_upper == 0)\n",
    "        lower_min = opt_lower.minimize(delta_lower)\n",
    "        if opt_lower.check() != sat:\n",
    "            # print(\"lower unsat\")\n",
    "            lower_min = None\n",
    "\n",
    "        opt_upper = Optimize()\n",
    "        opt_upper.add(And(expression_list))\n",
    "        opt_upper.add(delta_lower == 0)\n",
    "        upper_min = opt_upper.minimize(delta_upper)\n",
    "        if opt_upper.check() != sat:\n",
    "            # print(\"upper unsat\")\n",
    "            upper_min = None\n",
    "\n",
    "        return lower_min, upper_min\n",
    "\n",
    "    def explain_range(\n",
    "        self,\n",
    "        instance,\n",
    "        reorder=\"asc\",\n",
    "        dataset_bounds=True,\n",
    "    ):\n",
    "        self.cumulative_range_expresson = []\n",
    "        self.caterogic_expressions = []\n",
    "        self.range_metric = 0\n",
    "        exp = self.explain(instance, reorder)\n",
    "        if exp != []:\n",
    "            delta_list = self.get_deltas(exp)\n",
    "            range_exp = []\n",
    "            for expression, delta_lower, delta_upper in delta_list:\n",
    "                expname = str(expression.arg(0))\n",
    "\n",
    "                expvalue = float(expression.arg(1).as_fraction())\n",
    "                lower = None\n",
    "                upper = None\n",
    "                if delta_lower is not None:\n",
    "                    lower = round(expvalue - delta_lower, 2)\n",
    "                if delta_upper is not None:\n",
    "                    upper = round(expvalue + delta_upper, 2)\n",
    "\n",
    "                if dataset_bounds == True:\n",
    "                    idx = list(self.columns).index(expname)\n",
    "                    min_idx = np.min(self.data[:, idx])\n",
    "                    max_idx = np.max(self.data[:, idx])\n",
    "                    if lower is not None and lower < min_idx:\n",
    "                        lower = min_idx\n",
    "                    if upper is not None and upper > max_idx:\n",
    "                        upper = max_idx\n",
    "\n",
    "                    # self.range_metric += (upper - lower)\n",
    "                if lower == upper:\n",
    "                    range_exp.append(f\"{expression.arg(0)} == {expression.arg(1)}\")\n",
    "                else:\n",
    "                    if lower is None:\n",
    "                        range_exp.append(f\"{expname} <= {upper}\")\n",
    "                    elif upper is None:\n",
    "                        range_exp.append(f\"{lower} <= {expname}\")\n",
    "                    else:\n",
    "                        range_exp.append(f\"{lower} <= {expname} <= {upper}\")\n",
    "\n",
    "            for expression in self.caterogic_expressions:\n",
    "                range_exp.append(f\"{expression.arg(0)} == {expression.arg(1)}\")\n",
    "\n",
    "            return range_exp\n",
    "        else:\n",
    "            return exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnEncoderDecoder:\n",
    "    def __init__(self):\n",
    "        self.mapping = {}\n",
    "\n",
    "    def encode(self, df):\n",
    "        \"\"\"Substitui os nomes das colunas por x0, x1, ..., xn\"\"\"\n",
    "        self.mapping = {f\"x{i}\": col for i, col in enumerate(df.columns)}\n",
    "        df_encoded = df.rename(\n",
    "            columns={col: new_col for new_col, col in self.mapping.items()}\n",
    "        )\n",
    "        return df_encoded\n",
    "\n",
    "    def decode(self, text):\n",
    "        \"\"\"Substitui x0, x1, ..., xn pelos nomes originais das colunas\"\"\"\n",
    "        for new_col, original_col in self.mapping.items():\n",
    "            text = text.replace(new_col, original_col)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Texto decodificado:\n",
      "decode de sepal width (cm)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = iris.target\n",
    "\n",
    "# y = np.where(y == 0, 0, 1)  # converte em binario\n",
    "y[y == 2] = 0\n",
    "# X = X.iloc[:, :2] # corta colunas do df\n",
    "\n",
    "encoder_decoder = ColumnEncoderDecoder()\n",
    "X = encoder_decoder.encode(X)\n",
    "\n",
    "encoded_text = \"decode de x1\"\n",
    "decoded_text = encoder_decoder.decode(encoded_text)\n",
    "\n",
    "print(\"\\nTexto decodificado:\")\n",
    "print(decoded_text)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=101\n",
    ")\n",
    "\n",
    "xgbc = XGBClassifier(n_estimators=100, max_depth=3, learning_rate=0.1)\n",
    "xgbc.fit(X_train, y_train)\n",
    "\n",
    "preds = xgbc.predict(X_test)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['5.51 <= x2 <= 5.69', '6.01 <= x0 <= 6.19', '2.51 <= x1 <= 2.69']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.5, 4.2, 1.4, 0.2])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbc.predict([X_test.values[0]])\n",
    "X_test.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = XGBoostExplainer(xgbc, X)\n",
    "explainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x1 <= 2.69', '6.0 <= x0 <= 6.29', '5.2 <= x2']"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explainer.explain_range(X_test.values[19], reorder=\"asc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x2 <= 2.99']"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explainer.explain_range(X_test.values[0], reorder=\"desc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = X[\n",
    "    (X[\"x2\"] >= 5.2) & (X[\"x0\"] >= 6) & (X[\"x0\"] <= 6.29) & (X[\"x1\"] <= 2.69)\n",
    "]\n",
    "\n",
    "xgbc.predict(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbc.predict(X[X[\"x2\"] <= 2.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[x2 <= 1.4 + 1.59]"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explainer.cumulative_range_expresson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5.2 <= x2', '6.0 <= x0 <= 6.29', 'x1 <= 2.69']"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explainer.explain_range(X_test.values[19], reorder=\"desc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[x2 >= 5.6 - 0.4, x0 >= 6.1 - 0.1, x0 <= 6.1 + 0.19, x1 <= 2.6 + 0.09]\n"
     ]
    }
   ],
   "source": [
    "copiaexp = explainer.cumulative_range_expresson\n",
    "print(copiaexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[x2 >= 5.6 - 0.4, x0 >= 6.1 - 0.1, x0 <= 6.1 + 0.19, x1 <= 2.6 + 0.09]\n"
     ]
    }
   ],
   "source": [
    "copiaexp = [expr for expr in copiaexp if not expr.eq(Real(\"x2\") == 5.6)]\n",
    "print(copiaexp)  # Saída esperada: [x0 == 6.1, x1 == 2.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[x2 >= 5.6 - 0.4, x0 >= 6.1 - 0.1, x0 <= 6.1 + 0.19, x1 <= 2.6 + 0.09]\n"
     ]
    }
   ],
   "source": [
    "copiaexp = list(filter(lambda expr: not expr.eq(Real(\"x2\") == 5.6), copiaexp))\n",
    "print(copiaexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03846328, 0.02926282, 0.36015186, 0.57212204], dtype=float32)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbc.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1])"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\"None <= x3 <= 1.69\", \"3.0 <= x2 <= 4.89\"]\n",
    "\n",
    "filtered_df = X[(X[\"x2\"] >= 3) & (X[\"x2\"] <= 4.89) & (X[\"x3\"] <= 1.69)]\n",
    "\n",
    "xgbc.predict(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x2 <= 2.99']\n",
      "['x2 <= 2.99']\n",
      "['x2 <= 2.99']\n",
      "['1.6 <= x3 <= 1.69', '3.0 <= x2', '6.3 <= x0', '3.0 <= x1']\n",
      "['x3 <= 1.69', '3.0 <= x2 <= 4.89']\n",
      "['1.8 <= x3']\n",
      "['x3 <= 1.69', '3.0 <= x2 <= 4.89']\n",
      "['x3 <= 1.69', '3.0 <= x2 <= 4.89']\n",
      "['5.0 <= x2', '6.0 <= x0', 'x1 <= 2.59']\n",
      "['x2 <= 2.99']\n",
      "['1.8 <= x3']\n",
      "['x2 <= 2.99']\n",
      "['x2 <= 2.99']\n",
      "['5.2 <= x2', '6.0 <= x0', '2.8 <= x1 <= 2.99']\n",
      "['1.8 <= x3']\n",
      "['x3 <= 1.69', '3.0 <= x2 <= 4.89']\n",
      "['x3 <= 1.69', '3.0 <= x2 <= 4.89']\n",
      "['x3 <= 1.69', '3.0 <= x2 <= 4.89']\n",
      "['x2 <= 2.99']\n",
      "['5.2 <= x2', '6.0 <= x0 <= 6.29', 'x1 <= 2.69']\n",
      "['x3 <= 1.69', '3.0 <= x2 <= 4.89']\n",
      "['x2 <= 2.99']\n",
      "['x3 <= 1.69', '3.0 <= x2 <= 4.89']\n",
      "['x3 <= 1.69', '3.0 <= x2 <= 4.89']\n",
      "['x3 <= 1.69', '3.0 <= x2 <= 4.89']\n",
      "['x3 <= 1.69', '3.0 <= x2 <= 4.89']\n",
      "['x3 <= 1.69', '3.0 <= x2 <= 4.89']\n",
      "['1.8 <= x3']\n",
      "['x2 <= 2.99']\n",
      "['x2 <= 2.99']\n"
     ]
    }
   ],
   "source": [
    "range_metric_list = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    print(explainer.explain_range(X_test.values[i], reorder=\"desc\"))\n",
    "    range_metric_list.append(explainer.range_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum: 0 mean: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"sum:\", np.sum(range_metric_list), \"mean:\", np.mean(range_metric_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x2 <= 2.99']\n",
      "['x2 <= 2.99']\n",
      "['x2 <= 2.99']\n",
      "['3.0 <= x1', '6.3 <= x0', '3.0 <= x2', '1.6 <= x3 <= 1.69']\n",
      "['3.0 <= x2 <= 4.99', 'x3 <= 1.59']\n",
      "['1.8 <= x3']\n",
      "['3.0 <= x2 <= 4.99', 'x3 <= 1.59']\n",
      "['3.0 <= x2 <= 4.99', 'x3 <= 1.59']\n",
      "['1.8 <= x3']\n",
      "['x2 <= 2.99']\n",
      "['1.8 <= x3']\n",
      "['x2 <= 2.99']\n",
      "['x2 <= 2.99']\n",
      "['1.8 <= x3']\n",
      "['1.8 <= x3']\n",
      "['3.0 <= x2 <= 4.99', 'x3 <= 1.59']\n",
      "['3.0 <= x2 <= 4.99', 'x3 <= 1.59']\n",
      "['3.0 <= x2 <= 4.99', 'x3 <= 1.59']\n",
      "['x2 <= 2.99']\n",
      "['x1 <= 2.69', '6.0 <= x0 <= 6.29', '5.2 <= x2']\n",
      "['3.0 <= x2 <= 4.99', 'x3 <= 1.59']\n",
      "['x2 <= 2.99']\n",
      "['3.0 <= x2 <= 4.99', 'x3 <= 1.59']\n",
      "['3.0 <= x2 <= 4.99', 'x3 <= 1.59']\n",
      "['3.0 <= x2 <= 4.99', 'x3 <= 1.59']\n",
      "['3.0 <= x2 <= 4.99', 'x3 <= 1.59']\n",
      "['3.0 <= x2 <= 4.99', 'x3 <= 1.59']\n",
      "['1.8 <= x3']\n",
      "['x2 <= 2.99']\n",
      "['x2 <= 2.99']\n"
     ]
    }
   ],
   "source": [
    "for i in range(X_test.shape[0]):\n",
    "    print(explainer.explain_range(X_test.values[i], reorder=\"asc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_correct_explanation(exp, explainer):\n",
    "    opt = Optimize()\n",
    "\n",
    "    exprange_z3 = []\n",
    "    exptokens = []\n",
    "    for item in exp:\n",
    "        item = str(item)\n",
    "        if \"<=\" in item:\n",
    "            tokens = item.split(\" <= \")\n",
    "            exprange_z3.append((tokens[0]) <= Real(tokens[1]))\n",
    "            exprange_z3.append(Real(tokens[1]) <= (tokens[2]))\n",
    "            exptokens.append(tokens[1])\n",
    "        else:\n",
    "            tokens = item.split(\" == \")\n",
    "            exprange_z3.append(Real(tokens[0]) == (tokens[1]))\n",
    "            exptokens.append(tokens[0])\n",
    "    opt.add(exprange_z3)\n",
    "\n",
    "    inst = explainer.I\n",
    "    deltaexp = []\n",
    "    for item in inst:\n",
    "        item = str(item)\n",
    "        tokens = item.split(\" == \")\n",
    "        if tokens[0] not in exptokens:\n",
    "            if tokens[0] in explainer.categoric_features:\n",
    "                deltaexp.append(Real(tokens[0]) == (tokens[1]))\n",
    "            else:\n",
    "                deltaexp.append(Real(tokens[0]) >= (tokens[1]) - Real(\"delta\"))\n",
    "                deltaexp.append(Real(tokens[0]) <= (tokens[1]) + Real(\"delta\"))\n",
    "    opt.add(deltaexp)\n",
    "\n",
    "    opt.add(explainer.T_model)\n",
    "\n",
    "    opt.add(Not(explainer.D))\n",
    "\n",
    "    opt.add(Real(\"delta\") >= 0)\n",
    "\n",
    "    delta = Real(\"delta\")\n",
    "    expmin = opt.minimize(delta)\n",
    "\n",
    "    printlist = []\n",
    "    if opt.check() == sat:\n",
    "        for var in opt.model():\n",
    "            if str(var) in explainer.columns:\n",
    "                printlist.append(f\"{var} = {opt.model()[var]}\")\n",
    "        printlist.append(f\"delta = {opt.model().eval(delta)}\")\n",
    "    else:\n",
    "        printlist.append(\"unsat == correct\")\n",
    "    #   print(printlist)\n",
    "    value = str(expmin.value())\n",
    "    #   print(value)\n",
    "    return printlist, exprange_z3, deltaexp, explainer.T, Not(explainer.D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# explanationstest = []\n",
    "# lista_results = []\n",
    "# for i in range(0, len(X)):\n",
    "#     exprange = explainer.explain_range(X.values[i])\n",
    "#     explanationstest.append(exprange)\n",
    "#     ans, ansrange, ansdelta, anst, ansnotd = check_correct_explanation(\n",
    "#         exprange, explainer\n",
    "#     )\n",
    "#     if ans[0] == (\"unsat == correct\"):\n",
    "#         count += 1\n",
    "#     else:\n",
    "#         lista_results.append([i, ans])\n",
    "#         print(exprange)\n",
    "#         print(i, ans)\n",
    "# count, len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[x3 == 1.8]"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explainer.explain(X.values[70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def fazer_predicoes(xgbc, X, lista_results):\n",
    "    for i, features in lista_results:\n",
    "        # Extrai os valores das features ignorando 'delta'\n",
    "        valores_dict = {\n",
    "            f.split(\" = \")[0]: float(f.split(\" = \")[1])\n",
    "            for f in features\n",
    "            if not f.startswith(\"delta\")\n",
    "        }\n",
    "\n",
    "        # Ordena corretamente em [x0, x1, x2, x3]\n",
    "        valores = np.array(\n",
    "            [\n",
    "                [\n",
    "                    valores_dict[\"x0\"],\n",
    "                    valores_dict[\"x1\"],\n",
    "                    valores_dict[\"x2\"],\n",
    "                    valores_dict[\"x3\"],\n",
    "                ]\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Faz as previsões\n",
    "        pred1 = xgbc.predict(X.values[i].reshape(1, -1))[0]  # Do dataset original\n",
    "        pred2 = xgbc.predict(valores)[0]  # Dos valores extraídos e organizados\n",
    "\n",
    "        # Print do resultado lado a lado\n",
    "        print(\n",
    "            f\"Índice {i}: Predição original = {pred1}, Predição valores extraídos = {pred2}\"\n",
    "        )\n",
    "\n",
    "\n",
    "# Exemplo de chamada da função (supondo que 'xgbc' e 'X' já estejam definidos)\n",
    "fazer_predicoes(xgbc, X, lista_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
