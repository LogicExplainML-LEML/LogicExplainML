{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from anchor import utils\n",
    "from anchor import anchor_tabular\n",
    "import sklearn\n",
    "from sklearn.datasets import load_iris, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from pmlb import fetch_data\n",
    "from z3 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_constraints_expression(X):\n",
    "    constraints = []\n",
    "\n",
    "    for i in range(X.shape[1]):\n",
    "        feature_values = X[:, i]\n",
    "        min_val, max_val = feature_values.min(), feature_values.max()\n",
    "\n",
    "        x = Real(f'x{i}')\n",
    "        min = RealVal(min_val)\n",
    "        max = RealVal(max_val)\n",
    "\n",
    "        constraint = And(min <= x, x <= max)\n",
    "        constraints.append(constraint)\n",
    "\n",
    "    return And(*constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_paths_expression(tree, tree_index, class_index):\n",
    "    tree_ = tree.tree_\n",
    "    feature = tree_.feature\n",
    "    threshold = tree_.threshold\n",
    "    value = tree_.value\n",
    "\n",
    "    paths = []\n",
    "    o = Real(f'o_{tree_index}_{class_index}')\n",
    "\n",
    "    def traverse(node, path_conditions):\n",
    "\n",
    "        if feature[node] == -2:\n",
    "            leaf_value = value[node][0][0]\n",
    "            path_formula = And(path_conditions)\n",
    "            implication = Implies(path_formula, o == leaf_value)\n",
    "            paths.append(implication)\n",
    "        else:\n",
    "\n",
    "            x = Real(f'x{feature[node]}')\n",
    "            left_condition = x <= threshold[node]\n",
    "            right_condition = x > threshold[node]\n",
    "            traverse(tree_.children_left[node],\n",
    "                     path_conditions + [left_condition])\n",
    "            traverse(tree_.children_right[node],\n",
    "                     path_conditions + [right_condition])\n",
    "\n",
    "    traverse(0, [])\n",
    "    return And(*paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_trees_expression(model):\n",
    "    formulas = []\n",
    "    for i, estimators in enumerate(model.estimators_):\n",
    "        for class_index, estimator in enumerate(estimators):\n",
    "            formula = tree_paths_expression(estimator, i, class_index)\n",
    "            formulas.append(formula)\n",
    "    return And(*formulas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_function_expression(model, x):\n",
    "    learning_rate = model.learning_rate\n",
    "    estimators = model.estimators_\n",
    "    n_classes = 1 if model.n_classes_ <= 2 else model.n_classes_\n",
    "\n",
    "    decision = model.decision_function(x)\n",
    "    predicted_class = model.predict(x)[0]\n",
    "\n",
    "    estimator_results = []\n",
    "    for estimator in estimators:\n",
    "        class_predictions = [tree.predict(x) for tree in estimator]\n",
    "        estimator_results.append(class_predictions)\n",
    "\n",
    "    estimator_sum = np.sum(estimator_results, axis=0) * learning_rate\n",
    "    init_value = decision - estimator_sum.T\n",
    "\n",
    "    equation_list = []\n",
    "    for class_number in range(n_classes):\n",
    "        estimator_list = []\n",
    "        for estimator_number in range(len(estimators)):\n",
    "            o = Real(f\"o_{estimator_number}_{class_number}\")\n",
    "            estimator_list.append(o)\n",
    "        equation_o = Sum(estimator_list) * learning_rate + init_value[0][class_number]\n",
    "        equation_list.append(equation_o)\n",
    "\n",
    "    if n_classes <= 2:\n",
    "        if predicted_class == 0:\n",
    "            final_equation = equation_list[0] < 0\n",
    "        else:\n",
    "            final_equation = equation_list[0] > 0\n",
    "    else:\n",
    "        compare_equation = []\n",
    "        for class_number in range(n_classes):\n",
    "            if predicted_class != class_number:\n",
    "                compare_equation.append(\n",
    "                    equation_list[predicted_class] > equation_list[class_number]\n",
    "                )\n",
    "        final_equation = compare_equation\n",
    "\n",
    "    return And(final_equation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExplainerCompleter():\n",
    "  def __init__(self, model, data, round = None):\n",
    "    self.model = model\n",
    "\n",
    "    # model\n",
    "    # T\n",
    "    self.T_constraints = feature_constraints_expression(data)\n",
    "    self.T_model = model_trees_expression(self.model)\n",
    "    self.T = And(self.T_model, self.T_constraints)\n",
    "\n",
    "  def explain_instance(self, instance, exp, verbose=False):\n",
    "    opt = Optimize()\n",
    "    self.exp = exp\n",
    "\n",
    "    # anchor matrix > expressions\n",
    "    anchor_matrix = []\n",
    "    for name in self.exp.names():\n",
    "      tokens = name.split(' ')\n",
    "      for operator in ['<=', '>=', '==', '<', '>']:\n",
    "        if operator in name:\n",
    "          parts = name.split(operator)\n",
    "          if len(parts) == 2:\n",
    "            anchor_matrix.append([parts[0].strip(), operator, parts[1].strip()])\n",
    "            break\n",
    "    # unir com o código de cima para simplificar\n",
    "    anchor_expressions = []\n",
    "    for row in anchor_matrix:\n",
    "      feature = Real(row[0])\n",
    "      if row[1] == '<=':\n",
    "        expression = feature <= float(row[2])\n",
    "      elif row[1] == '>=':\n",
    "        expression = feature >= float(row[2])\n",
    "      elif row[1] == '<':\n",
    "        expression = feature < float(row[2])\n",
    "      elif row[1] == '>':\n",
    "        expression = feature > float(row[2])\n",
    "      anchor_expressions.append(expression)\n",
    "    # print(anchor_expressions, len(anchor_expressions) == len(anchor_matrix))\n",
    "    self.anchor_expressions = anchor_expressions\n",
    "    opt.add(anchor_expressions)\n",
    "\n",
    "    # delta\n",
    "    # delta >= 0\n",
    "    # todas as features que não estao no anchor > fazer as igualdades delta\n",
    "    anchor_variables = []\n",
    "    for formula in anchor_expressions:\n",
    "      anchor_variables.append(str(formula.arg(0)))\n",
    "\n",
    "    feature_names = [f'x{i}' for i in range(instance.shape[0])]\n",
    "    delta = Real('delta')\n",
    "    opt.add(delta >= 0)\n",
    "    for i, var in enumerate(feature_names):\n",
    "      if var not in anchor_variables: # and importance_dic[var] != 0:\n",
    "        z3_var = Real(var)\n",
    "        opt.add((instance[i]) - delta <= z3_var, z3_var <= (instance[i]) + delta)\n",
    "        # print(f'{instance[i]} - {delta} <= {var}, {var} <= {instance[i]} + {delta}')\n",
    "\n",
    "    # not D\n",
    "    self.D = decision_function_expression(self.model, [instance])\n",
    "\n",
    "    # model\n",
    "    opt.add(self.T)\n",
    "    opt.add(Not(self.D))\n",
    "\n",
    "    # minimize delta\n",
    "    opt.minimize(delta)\n",
    "    if opt.check() == sat:\n",
    "      if verbose:\n",
    "        for var in opt.model():\n",
    "          print(var, '=', opt.model()[var])\n",
    "      print('delta =', opt.model().eval(delta))\n",
    "    else:\n",
    "      print(\"(unsat == correct)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_option(rational_to_decimal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_iris = GradientBoostingClassifier(n_estimators=100, max_depth=3, random_state = 101)\n",
    "\n",
    "iris = load_iris()\n",
    "X_iris, y_iris = iris.data, iris.target\n",
    "\n",
    "X_iris_train, X_iris_test, y_iris_train, y_iris_test = train_test_split(\n",
    "    X_iris, y_iris, test_size=0.2, random_state=101)\n",
    "\n",
    "gb_iris.fit(X_iris_train, y_iris_train)\n",
    "y_pred = gb_iris.predict(X_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainercomp = ExplainerCompleter(gb_iris, X_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(unsat == correct)\n",
      "(unsat == correct)\n",
      "(unsat == correct)\n",
      "(unsat == correct)\n",
      "(unsat == correct)\n",
      "delta = 0\n",
      "(unsat == correct)\n",
      "(unsat == correct)\n",
      "(unsat == correct)\n",
      "(unsat == correct)\n"
     ]
    }
   ],
   "source": [
    "iris_features_x = [f'x{i}' for i in range(len(iris.feature_names))]\n",
    "\n",
    "anchor_explainer = anchor_tabular.AnchorTabularExplainer(\n",
    "    gb_iris.classes_,\n",
    "    iris_features_x,\n",
    "    X_iris_train,\n",
    "    categorical_names={})\n",
    "\n",
    "for i in range(10):\n",
    "  exp = anchor_explainer.explain_instance(X_iris[i], gb_iris.predict, threshold=0.95)\n",
    "  # print(exp.names())\n",
    "  explainercomp.explain_instance(X_iris[i], exp)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
